{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5iGtfzRLDk7V",
    "outputId": "8919c54f-2d68-40b5-91c3-45666bbc0735"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Oct  9 05:23:18 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.74       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   35C    P8    26W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# Check GPU\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NSTUXucs_dnd",
    "outputId": "5a46c863-cb01-4975-9c7e-9273938798e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "CsVpdTi9_ex9"
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 110
    },
    "id": "XlB4Jd4q_0WJ",
    "outputId": "9970feab-a642-4eed-d2c4-c253e27d6ea2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/content/drive/MyDrive/object_detection/data/t...</td>\n",
       "      <td>846</td>\n",
       "      <td>145</td>\n",
       "      <td>992</td>\n",
       "      <td>622</td>\n",
       "      <td>person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/content/drive/MyDrive/object_detection/data/t...</td>\n",
       "      <td>848</td>\n",
       "      <td>216</td>\n",
       "      <td>1023</td>\n",
       "      <td>767</td>\n",
       "      <td>person</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0    1  ...    4       5\n",
       "0  /content/drive/MyDrive/object_detection/data/t...  846  ...  622  person\n",
       "1  /content/drive/MyDrive/object_detection/data/t...  848  ...  767  person\n",
       "\n",
       "[2 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_annots = pd.read_csv('/content/drive/MyDrive/object_detection/data/train_annots_v2.csv', header=None)\n",
    "train_annots.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hmLHb9t_BNfU"
   },
   "source": [
    "# Training the Object Detection Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "MUmJKHZdBrZ4"
   },
   "outputs": [],
   "source": [
    "os.chdir('/content/drive/MyDrive/object_detection/src/pytorch-retinanet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1NcRR-vmBMTU",
    "outputId": "b8922e10-ed93-4b09-d01f-80b36e4d884a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
      "Epoch: 0 | Iteration: 504 | Classification loss: 0.50369 | Regression loss: 0.94188 | Running loss: 1.43745\n",
      "Epoch: 0 | Iteration: 505 | Classification loss: 0.34098 | Regression loss: 0.68063 | Running loss: 1.43533\n",
      "Epoch: 0 | Iteration: 506 | Classification loss: 0.52925 | Regression loss: 0.92148 | Running loss: 1.43419\n",
      "Epoch: 0 | Iteration: 507 | Classification loss: 0.48733 | Regression loss: 0.89721 | Running loss: 1.43282\n",
      "Epoch: 0 | Iteration: 508 | Classification loss: 0.48605 | Regression loss: 0.80761 | Running loss: 1.43145\n",
      "Epoch: 0 | Iteration: 509 | Classification loss: 0.49509 | Regression loss: 0.76864 | Running loss: 1.43001\n",
      "Epoch: 0 | Iteration: 510 | Classification loss: 0.52206 | Regression loss: 0.84095 | Running loss: 1.42900\n",
      "Epoch: 0 | Iteration: 511 | Classification loss: 0.55601 | Regression loss: 0.88282 | Running loss: 1.42822\n",
      "Epoch: 0 | Iteration: 512 | Classification loss: 0.45612 | Regression loss: 0.81115 | Running loss: 1.42704\n",
      "Epoch: 0 | Iteration: 513 | Classification loss: 0.43533 | Regression loss: 0.86604 | Running loss: 1.42544\n",
      "Epoch: 0 | Iteration: 514 | Classification loss: 0.36517 | Regression loss: 0.77397 | Running loss: 1.42414\n",
      "Epoch: 0 | Iteration: 515 | Classification loss: 0.41926 | Regression loss: 0.83478 | Running loss: 1.42077\n",
      "Epoch: 0 | Iteration: 516 | Classification loss: 0.56291 | Regression loss: 0.68061 | Running loss: 1.41942\n",
      "Epoch: 0 | Iteration: 517 | Classification loss: 0.54801 | Regression loss: 0.91601 | Running loss: 1.41842\n",
      "Epoch: 0 | Iteration: 518 | Classification loss: 2.17688 | Regression loss: 0.68487 | Running loss: 1.42052\n",
      "Epoch: 0 | Iteration: 519 | Classification loss: 0.41751 | Regression loss: 0.75675 | Running loss: 1.41936\n",
      "Epoch: 0 | Iteration: 520 | Classification loss: 0.37933 | Regression loss: 0.83262 | Running loss: 1.41850\n",
      "Epoch: 0 | Iteration: 521 | Classification loss: 0.52902 | Regression loss: 0.82605 | Running loss: 1.41773\n",
      "Epoch: 0 | Iteration: 522 | Classification loss: 0.41426 | Regression loss: 0.86233 | Running loss: 1.41671\n",
      "Epoch: 0 | Iteration: 523 | Classification loss: 0.45845 | Regression loss: 0.89139 | Running loss: 1.41607\n",
      "Epoch: 0 | Iteration: 524 | Classification loss: 0.37329 | Regression loss: 0.79870 | Running loss: 1.41486\n",
      "Epoch: 0 | Iteration: 525 | Classification loss: 0.42631 | Regression loss: 0.68942 | Running loss: 1.41379\n",
      "Epoch: 0 | Iteration: 526 | Classification loss: 0.40213 | Regression loss: 0.75714 | Running loss: 1.41243\n",
      "Epoch: 0 | Iteration: 527 | Classification loss: 0.48622 | Regression loss: 0.86816 | Running loss: 1.41174\n",
      "Epoch: 0 | Iteration: 528 | Classification loss: 0.38470 | Regression loss: 0.82999 | Running loss: 1.41050\n",
      "Epoch: 0 | Iteration: 529 | Classification loss: 0.36238 | Regression loss: 0.66527 | Running loss: 1.40881\n",
      "Epoch: 0 | Iteration: 530 | Classification loss: 0.33197 | Regression loss: 0.70047 | Running loss: 1.40739\n",
      "Epoch: 0 | Iteration: 531 | Classification loss: 0.40019 | Regression loss: 0.92865 | Running loss: 1.40672\n",
      "Epoch: 0 | Iteration: 532 | Classification loss: 0.40500 | Regression loss: 0.81883 | Running loss: 1.40571\n",
      "Epoch: 0 | Iteration: 533 | Classification loss: 0.47671 | Regression loss: 0.54624 | Running loss: 1.40431\n",
      "Epoch: 0 | Iteration: 534 | Classification loss: 0.39317 | Regression loss: 0.85406 | Running loss: 1.40359\n",
      "Epoch: 0 | Iteration: 535 | Classification loss: 0.43729 | Regression loss: 0.87285 | Running loss: 1.40269\n",
      "Epoch: 0 | Iteration: 536 | Classification loss: 0.40489 | Regression loss: 0.80680 | Running loss: 1.40160\n",
      "Epoch: 0 | Iteration: 537 | Classification loss: 0.32629 | Regression loss: 0.83644 | Running loss: 1.40068\n",
      "Epoch: 0 | Iteration: 538 | Classification loss: 0.42378 | Regression loss: 0.87238 | Running loss: 1.40003\n",
      "Epoch: 0 | Iteration: 539 | Classification loss: 0.50870 | Regression loss: 0.82030 | Running loss: 1.39939\n",
      "Epoch: 0 | Iteration: 540 | Classification loss: 0.26681 | Regression loss: 0.68022 | Running loss: 1.39800\n",
      "Epoch: 0 | Iteration: 541 | Classification loss: 0.46628 | Regression loss: 0.92151 | Running loss: 1.39724\n",
      "Epoch: 0 | Iteration: 542 | Classification loss: 0.18753 | Regression loss: 0.51281 | Running loss: 1.39565\n",
      "Epoch: 0 | Iteration: 543 | Classification loss: 0.44499 | Regression loss: 0.86231 | Running loss: 1.39498\n",
      "Epoch: 0 | Iteration: 544 | Classification loss: 0.46690 | Regression loss: 0.85302 | Running loss: 1.39435\n",
      "Epoch: 0 | Iteration: 545 | Classification loss: 0.39563 | Regression loss: 0.84276 | Running loss: 1.39357\n",
      "Epoch: 0 | Iteration: 546 | Classification loss: 0.51563 | Regression loss: 0.89073 | Running loss: 1.39285\n",
      "Epoch: 0 | Iteration: 547 | Classification loss: 0.34989 | Regression loss: 0.80325 | Running loss: 1.39197\n",
      "Epoch: 0 | Iteration: 548 | Classification loss: 0.52583 | Regression loss: 0.96952 | Running loss: 1.39132\n",
      "Epoch: 0 | Iteration: 549 | Classification loss: 0.43420 | Regression loss: 0.85543 | Running loss: 1.39062\n",
      "Epoch: 0 | Iteration: 550 | Classification loss: 0.46288 | Regression loss: 0.91409 | Running loss: 1.39019\n",
      "Epoch: 0 | Iteration: 551 | Classification loss: 0.40311 | Regression loss: 0.86296 | Running loss: 1.38957\n",
      "Epoch: 0 | Iteration: 552 | Classification loss: 0.44247 | Regression loss: 0.83362 | Running loss: 1.38846\n",
      "Epoch: 0 | Iteration: 553 | Classification loss: 0.49782 | Regression loss: 0.77679 | Running loss: 1.38771\n",
      "Epoch: 0 | Iteration: 554 | Classification loss: 0.49107 | Regression loss: 0.88307 | Running loss: 1.38723\n",
      "Epoch: 0 | Iteration: 555 | Classification loss: 0.51003 | Regression loss: 0.84386 | Running loss: 1.38645\n",
      "Epoch: 0 | Iteration: 556 | Classification loss: 0.36947 | Regression loss: 0.76715 | Running loss: 1.38549\n",
      "Epoch: 0 | Iteration: 557 | Classification loss: 0.43880 | Regression loss: 0.92406 | Running loss: 1.38501\n",
      "Epoch: 0 | Iteration: 558 | Classification loss: 0.73139 | Regression loss: 1.00635 | Running loss: 1.38519\n",
      "Epoch: 0 | Iteration: 559 | Classification loss: 0.36698 | Regression loss: 0.66204 | Running loss: 1.38425\n",
      "Epoch: 0 | Iteration: 560 | Classification loss: 0.36984 | Regression loss: 0.80367 | Running loss: 1.38328\n",
      "Epoch: 0 | Iteration: 561 | Classification loss: 0.47332 | Regression loss: 0.93212 | Running loss: 1.38290\n",
      "Epoch: 0 | Iteration: 562 | Classification loss: 0.40659 | Regression loss: 0.84095 | Running loss: 1.38222\n",
      "Epoch: 0 | Iteration: 563 | Classification loss: 0.38574 | Regression loss: 0.79455 | Running loss: 1.38117\n",
      "Epoch: 0 | Iteration: 564 | Classification loss: 0.28124 | Regression loss: 0.67036 | Running loss: 1.37954\n",
      "Epoch: 0 | Iteration: 565 | Classification loss: 0.34162 | Regression loss: 0.76812 | Running loss: 1.37668\n",
      "Epoch: 0 | Iteration: 566 | Classification loss: 0.41908 | Regression loss: 0.83395 | Running loss: 1.37586\n",
      "Epoch: 0 | Iteration: 567 | Classification loss: 0.40645 | Regression loss: 0.86529 | Running loss: 1.37528\n",
      "Epoch: 0 | Iteration: 568 | Classification loss: 0.40342 | Regression loss: 0.78832 | Running loss: 1.37450\n",
      "Epoch: 0 | Iteration: 569 | Classification loss: 0.41820 | Regression loss: 0.87694 | Running loss: 1.37359\n",
      "Epoch: 0 | Iteration: 570 | Classification loss: 0.46145 | Regression loss: 0.87320 | Running loss: 1.37326\n",
      "Epoch: 0 | Iteration: 571 | Classification loss: 0.32387 | Regression loss: 0.84736 | Running loss: 1.37190\n",
      "Epoch: 0 | Iteration: 572 | Classification loss: 0.32045 | Regression loss: 0.64486 | Running loss: 1.37065\n",
      "Epoch: 0 | Iteration: 573 | Classification loss: 0.51390 | Regression loss: 0.73530 | Running loss: 1.36960\n",
      "Epoch: 0 | Iteration: 574 | Classification loss: 0.39198 | Regression loss: 0.77135 | Running loss: 1.36868\n",
      "Epoch: 0 | Iteration: 575 | Classification loss: 0.37901 | Regression loss: 0.83955 | Running loss: 1.36795\n",
      "Epoch: 0 | Iteration: 576 | Classification loss: 0.61225 | Regression loss: 0.91562 | Running loss: 1.36797\n",
      "Epoch: 0 | Iteration: 577 | Classification loss: 0.45797 | Regression loss: 0.86157 | Running loss: 1.36727\n",
      "Epoch: 0 | Iteration: 578 | Classification loss: 0.35097 | Regression loss: 0.74006 | Running loss: 1.36628\n",
      "Epoch: 0 | Iteration: 579 | Classification loss: 0.38233 | Regression loss: 0.79533 | Running loss: 1.36527\n",
      "Epoch: 0 | Iteration: 580 | Classification loss: 0.32031 | Regression loss: 0.79999 | Running loss: 1.36425\n",
      "Epoch: 0 | Iteration: 581 | Classification loss: 0.57441 | Regression loss: 0.98986 | Running loss: 1.36373\n",
      "Epoch: 0 | Iteration: 582 | Classification loss: 0.38619 | Regression loss: 0.80348 | Running loss: 1.36284\n",
      "Epoch: 0 | Iteration: 583 | Classification loss: 0.38703 | Regression loss: 0.80200 | Running loss: 1.36214\n",
      "Epoch: 0 | Iteration: 584 | Classification loss: 0.28607 | Regression loss: 0.66525 | Running loss: 1.36093\n",
      "Epoch: 0 | Iteration: 585 | Classification loss: 0.41193 | Regression loss: 0.85795 | Running loss: 1.36025\n",
      "Epoch: 0 | Iteration: 586 | Classification loss: 0.41792 | Regression loss: 0.83419 | Running loss: 1.35981\n",
      "Epoch: 0 | Iteration: 587 | Classification loss: 0.45583 | Regression loss: 0.81377 | Running loss: 1.35944\n",
      "Epoch: 0 | Iteration: 588 | Classification loss: 0.55383 | Regression loss: 0.95321 | Running loss: 1.35908\n",
      "Epoch: 0 | Iteration: 589 | Classification loss: 0.48918 | Regression loss: 0.87218 | Running loss: 1.35852\n",
      "Epoch: 0 | Iteration: 590 | Classification loss: 0.39799 | Regression loss: 0.81533 | Running loss: 1.35782\n",
      "Epoch: 0 | Iteration: 591 | Classification loss: 0.33921 | Regression loss: 0.80303 | Running loss: 1.35696\n",
      "Epoch: 0 | Iteration: 592 | Classification loss: 0.35267 | Regression loss: 0.83345 | Running loss: 1.35603\n",
      "Epoch: 0 | Iteration: 593 | Classification loss: 0.67622 | Regression loss: 0.67793 | Running loss: 1.35562\n",
      "Epoch: 0 | Iteration: 594 | Classification loss: 0.45582 | Regression loss: 0.77056 | Running loss: 1.35496\n",
      "Epoch: 0 | Iteration: 595 | Classification loss: 0.28760 | Regression loss: 0.67684 | Running loss: 1.35389\n",
      "Epoch: 0 | Iteration: 596 | Classification loss: 0.48792 | Regression loss: 0.91151 | Running loss: 1.35368\n",
      "Epoch: 0 | Iteration: 597 | Classification loss: 0.38409 | Regression loss: 0.73953 | Running loss: 1.35291\n",
      "Epoch: 0 | Iteration: 598 | Classification loss: 0.52074 | Regression loss: 0.87590 | Running loss: 1.35235\n",
      "Epoch: 0 | Iteration: 599 | Classification loss: 0.43405 | Regression loss: 0.80098 | Running loss: 1.35183\n",
      "Epoch: 0 | Iteration: 600 | Classification loss: 0.48005 | Regression loss: 0.71281 | Running loss: 1.35084\n",
      "Epoch: 0 | Iteration: 601 | Classification loss: 0.39902 | Regression loss: 0.85853 | Running loss: 1.35036\n",
      "Epoch: 0 | Iteration: 602 | Classification loss: 0.38886 | Regression loss: 0.84238 | Running loss: 1.34984\n",
      "Epoch: 0 | Iteration: 603 | Classification loss: 0.31548 | Regression loss: 0.59514 | Running loss: 1.34859\n",
      "Epoch: 0 | Iteration: 604 | Classification loss: 0.49232 | Regression loss: 0.79505 | Running loss: 1.34796\n",
      "Epoch: 0 | Iteration: 605 | Classification loss: 0.25453 | Regression loss: 0.64127 | Running loss: 1.34654\n",
      "Epoch: 0 | Iteration: 606 | Classification loss: 0.45768 | Regression loss: 0.60518 | Running loss: 1.34555\n",
      "Epoch: 0 | Iteration: 607 | Classification loss: 0.49056 | Regression loss: 0.85718 | Running loss: 1.34508\n",
      "Epoch: 0 | Iteration: 608 | Classification loss: 0.52297 | Regression loss: 0.84930 | Running loss: 1.34467\n",
      "Epoch: 0 | Iteration: 609 | Classification loss: 0.40702 | Regression loss: 0.88838 | Running loss: 1.34435\n",
      "Epoch: 0 | Iteration: 610 | Classification loss: 0.39267 | Regression loss: 0.60693 | Running loss: 1.34311\n",
      "Epoch: 0 | Iteration: 611 | Classification loss: 0.50443 | Regression loss: 0.81527 | Running loss: 1.34259\n",
      "Epoch: 0 | Iteration: 612 | Classification loss: 0.53933 | Regression loss: 0.77131 | Running loss: 1.34207\n",
      "Epoch: 0 | Iteration: 613 | Classification loss: 0.37684 | Regression loss: 0.59967 | Running loss: 1.34044\n",
      "Epoch: 0 | Iteration: 614 | Classification loss: 0.45667 | Regression loss: 0.82319 | Running loss: 1.33993\n",
      "Epoch: 0 | Iteration: 615 | Classification loss: 0.42017 | Regression loss: 0.79038 | Running loss: 1.33930\n",
      "Epoch: 0 | Iteration: 616 | Classification loss: 0.36399 | Regression loss: 0.71652 | Running loss: 1.33852\n",
      "Epoch: 0 | Iteration: 617 | Classification loss: 0.42837 | Regression loss: 0.90840 | Running loss: 1.33823\n",
      "Epoch: 0 | Iteration: 618 | Classification loss: 0.37442 | Regression loss: 0.83256 | Running loss: 1.33774\n",
      "Epoch: 0 | Iteration: 619 | Classification loss: 0.47889 | Regression loss: 0.84365 | Running loss: 1.33742\n",
      "Epoch: 0 | Iteration: 620 | Classification loss: 0.40543 | Regression loss: 0.81687 | Running loss: 1.33724\n",
      "Epoch: 0 | Iteration: 621 | Classification loss: 0.63996 | Regression loss: 0.94881 | Running loss: 1.33736\n",
      "Epoch: 0 | Iteration: 622 | Classification loss: 0.39371 | Regression loss: 0.81696 | Running loss: 1.33674\n",
      "Epoch: 0 | Iteration: 623 | Classification loss: 0.49923 | Regression loss: 0.94414 | Running loss: 1.33627\n",
      "Epoch: 0 | Iteration: 624 | Classification loss: 0.34544 | Regression loss: 0.80360 | Running loss: 1.33538\n",
      "Epoch: 0 | Iteration: 625 | Classification loss: 0.43710 | Regression loss: 0.88297 | Running loss: 1.33500\n",
      "Epoch: 0 | Iteration: 626 | Classification loss: 0.34783 | Regression loss: 0.87902 | Running loss: 1.33441\n",
      "Epoch: 0 | Iteration: 627 | Classification loss: 0.62923 | Regression loss: 0.95641 | Running loss: 1.33455\n",
      "Epoch: 0 | Iteration: 628 | Classification loss: 0.43901 | Regression loss: 0.93554 | Running loss: 1.33430\n",
      "Epoch: 0 | Iteration: 629 | Classification loss: 0.45049 | Regression loss: 0.83462 | Running loss: 1.33413\n",
      "Epoch: 0 | Iteration: 630 | Classification loss: 0.37176 | Regression loss: 0.88816 | Running loss: 1.33380\n",
      "Epoch: 0 | Iteration: 631 | Classification loss: 0.47432 | Regression loss: 0.81639 | Running loss: 1.33386\n",
      "Epoch: 0 | Iteration: 632 | Classification loss: 0.40505 | Regression loss: 0.73101 | Running loss: 1.33326\n",
      "Epoch: 0 | Iteration: 633 | Classification loss: 0.37908 | Regression loss: 0.77668 | Running loss: 1.33268\n",
      "Epoch: 0 | Iteration: 634 | Classification loss: 0.43817 | Regression loss: 0.89422 | Running loss: 1.33264\n",
      "Epoch: 0 | Iteration: 635 | Classification loss: 0.52781 | Regression loss: 0.91798 | Running loss: 1.33255\n",
      "Epoch: 0 | Iteration: 636 | Classification loss: 0.36763 | Regression loss: 0.77484 | Running loss: 1.33156\n",
      "Epoch: 0 | Iteration: 637 | Classification loss: 0.44101 | Regression loss: 0.73484 | Running loss: 1.33086\n",
      "Epoch: 0 | Iteration: 638 | Classification loss: 0.42780 | Regression loss: 0.87519 | Running loss: 1.33052\n",
      "Epoch: 0 | Iteration: 639 | Classification loss: 0.54750 | Regression loss: 0.82803 | Running loss: 1.33082\n",
      "Epoch: 0 | Iteration: 640 | Classification loss: 0.41402 | Regression loss: 0.68067 | Running loss: 1.33022\n",
      "Epoch: 0 | Iteration: 641 | Classification loss: 0.36743 | Regression loss: 0.72681 | Running loss: 1.32948\n",
      "Epoch: 0 | Iteration: 642 | Classification loss: 0.49741 | Regression loss: 0.91808 | Running loss: 1.32942\n",
      "Epoch: 0 | Iteration: 643 | Classification loss: 0.35865 | Regression loss: 0.83841 | Running loss: 1.32876\n",
      "Epoch: 0 | Iteration: 644 | Classification loss: 0.47046 | Regression loss: 0.84996 | Running loss: 1.32848\n",
      "Epoch: 0 | Iteration: 645 | Classification loss: 0.59372 | Regression loss: 0.86596 | Running loss: 1.32797\n",
      "Epoch: 0 | Iteration: 646 | Classification loss: 0.46843 | Regression loss: 0.88428 | Running loss: 1.32800\n",
      "Epoch: 0 | Iteration: 647 | Classification loss: 0.42401 | Regression loss: 0.80243 | Running loss: 1.32748\n",
      "Epoch: 0 | Iteration: 648 | Classification loss: 0.40161 | Regression loss: 0.88431 | Running loss: 1.32712\n",
      "Epoch: 0 | Iteration: 649 | Classification loss: 0.48147 | Regression loss: 0.92139 | Running loss: 1.32717\n",
      "Epoch: 0 | Iteration: 650 | Classification loss: 0.46160 | Regression loss: 0.84450 | Running loss: 1.32664\n",
      "Epoch: 0 | Iteration: 651 | Classification loss: 0.40163 | Regression loss: 0.86434 | Running loss: 1.32573\n",
      "Epoch: 0 | Iteration: 652 | Classification loss: 0.36094 | Regression loss: 0.76745 | Running loss: 1.32506\n",
      "Epoch: 0 | Iteration: 653 | Classification loss: 0.40835 | Regression loss: 0.79215 | Running loss: 1.32450\n",
      "Epoch: 0 | Iteration: 654 | Classification loss: 0.39509 | Regression loss: 0.59647 | Running loss: 1.32373\n",
      "Epoch: 0 | Iteration: 655 | Classification loss: 0.38053 | Regression loss: 0.79229 | Running loss: 1.32336\n",
      "Epoch: 0 | Iteration: 656 | Classification loss: 0.38920 | Regression loss: 0.75008 | Running loss: 1.32233\n",
      "Epoch: 0 | Iteration: 657 | Classification loss: 0.44343 | Regression loss: 0.76026 | Running loss: 1.32192\n",
      "Epoch: 0 | Iteration: 658 | Classification loss: 0.39968 | Regression loss: 0.90479 | Running loss: 1.32156\n",
      "Epoch: 0 | Iteration: 659 | Classification loss: 0.36617 | Regression loss: 0.73100 | Running loss: 1.32090\n",
      "Epoch: 0 | Iteration: 660 | Classification loss: 0.47793 | Regression loss: 0.86349 | Running loss: 1.32027\n",
      "Epoch: 0 | Iteration: 661 | Classification loss: 0.38839 | Regression loss: 0.83181 | Running loss: 1.31946\n",
      "Epoch: 0 | Iteration: 662 | Classification loss: 0.31980 | Regression loss: 0.74024 | Running loss: 1.31836\n",
      "Epoch: 0 | Iteration: 663 | Classification loss: 0.46504 | Regression loss: 0.94497 | Running loss: 1.31848\n",
      "Epoch: 0 | Iteration: 664 | Classification loss: 0.37884 | Regression loss: 0.79985 | Running loss: 1.31774\n",
      "Epoch: 0 | Iteration: 665 | Classification loss: 0.47543 | Regression loss: 0.90657 | Running loss: 1.31779\n",
      "Epoch: 0 | Iteration: 666 | Classification loss: 0.52433 | Regression loss: 0.86291 | Running loss: 1.31767\n",
      "Epoch: 0 | Iteration: 667 | Classification loss: 0.36658 | Regression loss: 0.88656 | Running loss: 1.31741\n",
      "Epoch: 0 | Iteration: 668 | Classification loss: 0.52591 | Regression loss: 0.79707 | Running loss: 1.31739\n",
      "Epoch: 0 | Iteration: 669 | Classification loss: 0.46736 | Regression loss: 0.83036 | Running loss: 1.31712\n",
      "Epoch: 0 | Iteration: 670 | Classification loss: 0.36813 | Regression loss: 0.62047 | Running loss: 1.31613\n",
      "Epoch: 0 | Iteration: 671 | Classification loss: 0.31568 | Regression loss: 0.76411 | Running loss: 1.31543\n",
      "Epoch: 0 | Iteration: 672 | Classification loss: 0.37310 | Regression loss: 0.79350 | Running loss: 1.31482\n",
      "Epoch: 0 | Iteration: 673 | Classification loss: 0.38746 | Regression loss: 0.69340 | Running loss: 1.31437\n",
      "Epoch: 0 | Iteration: 674 | Classification loss: 0.34145 | Regression loss: 0.75406 | Running loss: 1.31346\n",
      "Epoch: 0 | Iteration: 675 | Classification loss: 0.49658 | Regression loss: 0.87513 | Running loss: 1.31328\n",
      "Epoch: 0 | Iteration: 676 | Classification loss: 0.38625 | Regression loss: 0.74143 | Running loss: 1.31219\n",
      "Epoch: 0 | Iteration: 677 | Classification loss: 0.26848 | Regression loss: 0.74549 | Running loss: 1.31154\n",
      "Epoch: 0 | Iteration: 678 | Classification loss: 0.46480 | Regression loss: 0.64614 | Running loss: 1.31100\n",
      "Epoch: 0 | Iteration: 679 | Classification loss: 0.38014 | Regression loss: 0.86822 | Running loss: 1.31060\n",
      "Epoch: 0 | Iteration: 680 | Classification loss: 0.48827 | Regression loss: 0.84152 | Running loss: 1.31059\n",
      "Epoch: 0 | Iteration: 681 | Classification loss: 0.43827 | Regression loss: 0.82654 | Running loss: 1.31023\n",
      "Epoch: 0 | Iteration: 682 | Classification loss: 0.42624 | Regression loss: 0.79468 | Running loss: 1.30959\n",
      "Epoch: 0 | Iteration: 683 | Classification loss: 0.36307 | Regression loss: 0.83366 | Running loss: 1.30918\n",
      "Epoch: 0 | Iteration: 684 | Classification loss: 0.40381 | Regression loss: 0.69420 | Running loss: 1.30868\n",
      "Epoch: 0 | Iteration: 685 | Classification loss: 0.50474 | Regression loss: 0.86457 | Running loss: 1.30853\n",
      "Epoch: 0 | Iteration: 686 | Classification loss: 0.36247 | Regression loss: 0.87075 | Running loss: 1.30771\n",
      "Epoch: 0 | Iteration: 687 | Classification loss: 0.37738 | Regression loss: 0.79782 | Running loss: 1.30718\n",
      "Epoch: 0 | Iteration: 688 | Classification loss: 0.51587 | Regression loss: 0.90201 | Running loss: 1.30750\n",
      "Epoch: 0 | Iteration: 689 | Classification loss: 0.49836 | Regression loss: 0.87001 | Running loss: 1.30720\n",
      "Epoch: 0 | Iteration: 690 | Classification loss: 0.45231 | Regression loss: 0.81197 | Running loss: 1.30672\n",
      "Epoch: 0 | Iteration: 691 | Classification loss: 0.27326 | Regression loss: 0.67251 | Running loss: 1.30566\n",
      "Epoch: 0 | Iteration: 692 | Classification loss: 0.37164 | Regression loss: 0.80633 | Running loss: 1.30499\n",
      "Epoch: 0 | Iteration: 693 | Classification loss: 0.46014 | Regression loss: 0.79434 | Running loss: 1.30448\n",
      "Epoch: 0 | Iteration: 694 | Classification loss: 0.48131 | Regression loss: 0.85253 | Running loss: 1.30453\n",
      "Epoch: 0 | Iteration: 695 | Classification loss: 0.45935 | Regression loss: 0.88059 | Running loss: 1.30426\n",
      "Epoch: 0 | Iteration: 696 | Classification loss: 0.35479 | Regression loss: 0.72501 | Running loss: 1.30366\n",
      "Epoch: 0 | Iteration: 697 | Classification loss: 0.35450 | Regression loss: 0.74316 | Running loss: 1.30290\n",
      "Epoch: 0 | Iteration: 698 | Classification loss: 0.40743 | Regression loss: 0.81336 | Running loss: 1.30254\n",
      "Epoch: 0 | Iteration: 699 | Classification loss: 0.39534 | Regression loss: 0.77986 | Running loss: 1.30190\n",
      "Epoch: 0 | Iteration: 700 | Classification loss: 0.37294 | Regression loss: 0.79810 | Running loss: 1.30081\n",
      "Epoch: 0 | Iteration: 701 | Classification loss: 0.37181 | Regression loss: 0.78967 | Running loss: 1.30013\n",
      "Epoch: 0 | Iteration: 702 | Classification loss: 0.51594 | Regression loss: 0.84704 | Running loss: 1.29988\n",
      "Epoch: 0 | Iteration: 703 | Classification loss: 0.42943 | Regression loss: 0.83743 | Running loss: 1.29960\n",
      "Epoch: 0 | Iteration: 704 | Classification loss: 0.38984 | Regression loss: 0.83374 | Running loss: 1.29902\n",
      "Epoch: 0 | Iteration: 705 | Classification loss: 0.35806 | Regression loss: 0.79344 | Running loss: 1.29852\n",
      "Epoch: 0 | Iteration: 706 | Classification loss: 0.38347 | Regression loss: 0.80947 | Running loss: 1.29818\n",
      "Epoch: 0 | Iteration: 707 | Classification loss: 0.32256 | Regression loss: 0.75062 | Running loss: 1.29768\n",
      "Epoch: 0 | Iteration: 708 | Classification loss: 0.38850 | Regression loss: 0.74919 | Running loss: 1.29710\n",
      "Epoch: 0 | Iteration: 709 | Classification loss: 0.35435 | Regression loss: 0.80871 | Running loss: 1.29626\n",
      "Epoch: 0 | Iteration: 710 | Classification loss: 0.37282 | Regression loss: 0.59490 | Running loss: 1.29527\n",
      "Epoch: 0 | Iteration: 711 | Classification loss: 0.33541 | Regression loss: 0.73850 | Running loss: 1.29439\n",
      "Epoch: 0 | Iteration: 712 | Classification loss: 0.33398 | Regression loss: 0.75316 | Running loss: 1.29396\n",
      "Epoch: 0 | Iteration: 713 | Classification loss: 0.35575 | Regression loss: 0.80889 | Running loss: 1.29322\n",
      "Epoch: 0 | Iteration: 714 | Classification loss: 0.57173 | Regression loss: 0.94894 | Running loss: 1.29314\n",
      "Epoch: 0 | Iteration: 715 | Classification loss: 0.45183 | Regression loss: 0.75546 | Running loss: 1.29290\n",
      "Epoch: 0 | Iteration: 716 | Classification loss: 0.42169 | Regression loss: 0.88162 | Running loss: 1.29267\n",
      "Epoch: 0 | Iteration: 717 | Classification loss: 0.35828 | Regression loss: 0.82572 | Running loss: 1.29224\n",
      "Epoch: 0 | Iteration: 718 | Classification loss: 0.40855 | Regression loss: 0.84408 | Running loss: 1.29190\n",
      "Epoch: 0 | Iteration: 719 | Classification loss: 0.42134 | Regression loss: 0.77784 | Running loss: 1.29122\n",
      "Epoch: 0 | Iteration: 720 | Classification loss: 0.36413 | Regression loss: 0.81182 | Running loss: 1.29089\n",
      "Epoch: 0 | Iteration: 721 | Classification loss: 0.36885 | Regression loss: 0.72405 | Running loss: 1.29016\n",
      "Epoch: 0 | Iteration: 722 | Classification loss: 0.50966 | Regression loss: 0.85194 | Running loss: 1.29011\n",
      "Epoch: 0 | Iteration: 723 | Classification loss: 0.32209 | Regression loss: 0.83229 | Running loss: 1.28943\n",
      "Epoch: 0 | Iteration: 724 | Classification loss: 0.31093 | Regression loss: 0.74595 | Running loss: 1.28863\n",
      "Epoch: 0 | Iteration: 725 | Classification loss: 0.47769 | Regression loss: 0.91839 | Running loss: 1.28895\n",
      "Epoch: 0 | Iteration: 726 | Classification loss: 0.37648 | Regression loss: 0.82538 | Running loss: 1.28870\n",
      "Epoch: 0 | Iteration: 727 | Classification loss: 0.45421 | Regression loss: 0.78544 | Running loss: 1.28844\n",
      "Epoch: 0 | Iteration: 728 | Classification loss: 0.39299 | Regression loss: 0.81565 | Running loss: 1.28787\n",
      "Epoch: 0 | Iteration: 729 | Classification loss: 0.44843 | Regression loss: 0.80168 | Running loss: 1.28745\n",
      "Epoch: 0 | Iteration: 730 | Classification loss: 0.54850 | Regression loss: 0.77819 | Running loss: 1.28724\n",
      "Epoch: 0 | Iteration: 731 | Classification loss: 0.33211 | Regression loss: 0.82830 | Running loss: 1.28676\n",
      "Epoch: 0 | Iteration: 732 | Classification loss: 0.46192 | Regression loss: 0.90984 | Running loss: 1.28618\n",
      "Epoch: 0 | Iteration: 733 | Classification loss: 0.41144 | Regression loss: 0.77773 | Running loss: 1.28587\n",
      "Epoch: 0 | Iteration: 734 | Classification loss: 0.42661 | Regression loss: 0.84983 | Running loss: 1.28558\n",
      "Epoch: 0 | Iteration: 735 | Classification loss: 0.25052 | Regression loss: 0.71479 | Running loss: 1.28453\n",
      "Epoch: 0 | Iteration: 736 | Classification loss: 0.47616 | Regression loss: 0.85296 | Running loss: 1.28433\n",
      "Epoch: 0 | Iteration: 737 | Classification loss: 0.43199 | Regression loss: 0.85194 | Running loss: 1.28416\n",
      "Epoch: 0 | Iteration: 738 | Classification loss: 0.38670 | Regression loss: 0.82081 | Running loss: 1.28430\n",
      "Epoch: 0 | Iteration: 739 | Classification loss: 0.40427 | Regression loss: 0.83266 | Running loss: 1.28397\n",
      "Epoch: 0 | Iteration: 740 | Classification loss: 0.42165 | Regression loss: 0.87050 | Running loss: 1.28396\n",
      "Epoch: 0 | Iteration: 741 | Classification loss: 0.32324 | Regression loss: 0.75838 | Running loss: 1.28335\n",
      "Epoch: 0 | Iteration: 742 | Classification loss: 0.34853 | Regression loss: 0.79107 | Running loss: 1.28286\n",
      "Epoch: 0 | Iteration: 743 | Classification loss: 0.39486 | Regression loss: 0.76541 | Running loss: 1.28254\n",
      "Epoch: 0 | Iteration: 744 | Classification loss: 0.36633 | Regression loss: 0.81774 | Running loss: 1.28215\n",
      "Epoch: 0 | Iteration: 745 | Classification loss: 0.37143 | Regression loss: 0.76119 | Running loss: 1.28251\n",
      "Epoch: 0 | Iteration: 746 | Classification loss: 0.30174 | Regression loss: 0.74243 | Running loss: 1.28222\n",
      "Epoch: 0 | Iteration: 747 | Classification loss: 0.49779 | Regression loss: 0.90375 | Running loss: 1.28265\n",
      "Epoch: 0 | Iteration: 748 | Classification loss: 0.44350 | Regression loss: 0.80949 | Running loss: 1.28225\n",
      "Epoch: 0 | Iteration: 749 | Classification loss: 0.32692 | Regression loss: 0.79965 | Running loss: 1.28206\n",
      "Epoch: 0 | Iteration: 750 | Classification loss: 0.26295 | Regression loss: 0.59197 | Running loss: 1.28064\n",
      "Epoch: 0 | Iteration: 751 | Classification loss: 0.33042 | Regression loss: 0.76325 | Running loss: 1.28004\n",
      "Epoch: 0 | Iteration: 752 | Classification loss: 0.42782 | Regression loss: 0.75017 | Running loss: 1.27940\n",
      "Epoch: 0 | Iteration: 753 | Classification loss: 0.72799 | Regression loss: 0.82903 | Running loss: 1.27990\n",
      "Epoch: 0 | Iteration: 754 | Classification loss: 0.39687 | Regression loss: 0.86148 | Running loss: 1.28009\n",
      "Epoch: 0 | Iteration: 755 | Classification loss: 0.38228 | Regression loss: 0.86724 | Running loss: 1.28001\n",
      "Epoch: 0 | Iteration: 756 | Classification loss: 0.38741 | Regression loss: 0.78090 | Running loss: 1.27948\n",
      "Epoch: 0 | Iteration: 757 | Classification loss: 0.39461 | Regression loss: 0.80852 | Running loss: 1.27918\n",
      "Epoch: 0 | Iteration: 758 | Classification loss: 0.48374 | Regression loss: 0.79970 | Running loss: 1.27942\n",
      "Epoch: 0 | Iteration: 759 | Classification loss: 0.32853 | Regression loss: 0.64481 | Running loss: 1.27849\n",
      "Epoch: 0 | Iteration: 760 | Classification loss: 0.33243 | Regression loss: 0.73791 | Running loss: 1.27786\n",
      "Epoch: 0 | Iteration: 761 | Classification loss: 0.43131 | Regression loss: 0.74651 | Running loss: 1.27756\n",
      "Epoch: 0 | Iteration: 762 | Classification loss: 0.38532 | Regression loss: 0.77946 | Running loss: 1.27719\n",
      "Epoch: 0 | Iteration: 763 | Classification loss: 0.34453 | Regression loss: 0.72987 | Running loss: 1.27697\n",
      "Epoch: 0 | Iteration: 764 | Classification loss: 0.44123 | Regression loss: 0.85576 | Running loss: 1.27667\n",
      "Epoch: 0 | Iteration: 765 | Classification loss: 0.37537 | Regression loss: 0.77374 | Running loss: 1.27589\n",
      "Epoch: 0 | Iteration: 766 | Classification loss: 0.40862 | Regression loss: 0.80535 | Running loss: 1.27553\n",
      "Epoch: 0 | Iteration: 767 | Classification loss: 0.32339 | Regression loss: 0.71711 | Running loss: 1.27504\n",
      "Epoch: 0 | Iteration: 768 | Classification loss: 0.32037 | Regression loss: 0.75359 | Running loss: 1.27445\n",
      "Epoch: 0 | Iteration: 769 | Classification loss: 0.40045 | Regression loss: 0.84197 | Running loss: 1.27415\n",
      "Epoch: 0 | Iteration: 770 | Classification loss: 0.43039 | Regression loss: 0.88539 | Running loss: 1.27438\n",
      "Epoch: 0 | Iteration: 771 | Classification loss: 0.42084 | Regression loss: 0.80506 | Running loss: 1.27446\n",
      "Epoch: 0 | Iteration: 772 | Classification loss: 0.45553 | Regression loss: 0.90091 | Running loss: 1.27485\n",
      "Epoch: 0 | Iteration: 773 | Classification loss: 0.37468 | Regression loss: 0.80413 | Running loss: 1.27423\n",
      "Epoch: 0 | Iteration: 774 | Classification loss: 0.46082 | Regression loss: 0.82144 | Running loss: 1.27428\n",
      "Epoch: 0 | Iteration: 775 | Classification loss: 0.37033 | Regression loss: 0.79137 | Running loss: 1.27370\n",
      "Epoch: 0 | Iteration: 776 | Classification loss: 0.43349 | Regression loss: 0.89101 | Running loss: 1.27352\n",
      "Epoch: 0 | Iteration: 777 | Classification loss: 0.55502 | Regression loss: 0.53190 | Running loss: 1.27251\n",
      "Epoch: 0 | Iteration: 778 | Classification loss: 0.65400 | Regression loss: 0.89617 | Running loss: 1.27279\n",
      "Epoch: 0 | Iteration: 779 | Classification loss: 0.37340 | Regression loss: 0.83584 | Running loss: 1.27291\n",
      "Epoch: 0 | Iteration: 780 | Classification loss: 0.43329 | Regression loss: 0.81451 | Running loss: 1.27328\n",
      "Epoch: 0 | Iteration: 781 | Classification loss: 0.27353 | Regression loss: 0.65502 | Running loss: 1.27230\n",
      "Epoch: 0 | Iteration: 782 | Classification loss: 0.43951 | Regression loss: 0.83020 | Running loss: 1.27180\n",
      "Epoch: 0 | Iteration: 783 | Classification loss: 0.41929 | Regression loss: 0.79730 | Running loss: 1.27124\n",
      "Evaluating dataset\n",
      "\n",
      "mAP:\n",
      "person: 0.21678071651407266\n",
      "Precision:  0.04340190667335675\n",
      "Recall:  0.6876774559909142\n",
      "car: 0.3421337257411356\n",
      "Precision:  0.04340190667335675\n",
      "Recall:  0.6876774559909142\n",
      "Epoch: 1 | Iteration: 0 | Classification loss: 0.55889 | Regression loss: 0.81459 | Running loss: 1.27101\n",
      "Epoch: 1 | Iteration: 1 | Classification loss: 0.36474 | Regression loss: 0.82973 | Running loss: 1.27039\n",
      "Epoch: 1 | Iteration: 2 | Classification loss: 0.38415 | Regression loss: 0.71387 | Running loss: 1.26990\n",
      "Epoch: 1 | Iteration: 3 | Classification loss: 0.37856 | Regression loss: 0.80024 | Running loss: 1.26956\n",
      "Epoch: 1 | Iteration: 4 | Classification loss: 0.36907 | Regression loss: 0.75506 | Running loss: 1.26915\n",
      "Epoch: 1 | Iteration: 5 | Classification loss: 0.25624 | Regression loss: 0.69001 | Running loss: 1.26894\n",
      "Epoch: 1 | Iteration: 6 | Classification loss: 0.43203 | Regression loss: 0.81881 | Running loss: 1.26859\n",
      "Epoch: 1 | Iteration: 7 | Classification loss: 0.31836 | Regression loss: 0.72066 | Running loss: 1.26764\n",
      "Epoch: 1 | Iteration: 8 | Classification loss: 0.39836 | Regression loss: 0.77394 | Running loss: 1.26724\n",
      "Epoch: 1 | Iteration: 9 | Classification loss: 0.33041 | Regression loss: 0.82683 | Running loss: 1.26694\n",
      "Epoch: 1 | Iteration: 10 | Classification loss: 0.51111 | Regression loss: 0.78867 | Running loss: 1.26689\n",
      "Epoch: 1 | Iteration: 11 | Classification loss: 0.34632 | Regression loss: 0.72915 | Running loss: 1.26650\n",
      "Epoch: 1 | Iteration: 12 | Classification loss: 0.48048 | Regression loss: 0.83996 | Running loss: 1.26582\n",
      "Epoch: 1 | Iteration: 13 | Classification loss: 0.34579 | Regression loss: 0.75382 | Running loss: 1.26512\n",
      "Epoch: 1 | Iteration: 14 | Classification loss: 0.34730 | Regression loss: 0.77951 | Running loss: 1.26491\n",
      "Epoch: 1 | Iteration: 15 | Classification loss: 0.40874 | Regression loss: 0.80333 | Running loss: 1.26476\n",
      "Epoch: 1 | Iteration: 16 | Classification loss: 0.40711 | Regression loss: 0.84034 | Running loss: 1.26476\n",
      "Epoch: 1 | Iteration: 17 | Classification loss: 0.32055 | Regression loss: 0.67036 | Running loss: 1.26408\n",
      "Epoch: 1 | Iteration: 18 | Classification loss: 0.45163 | Regression loss: 0.85029 | Running loss: 1.26398\n",
      "Epoch: 1 | Iteration: 19 | Classification loss: 0.37904 | Regression loss: 0.82738 | Running loss: 1.26371\n",
      "Epoch: 1 | Iteration: 20 | Classification loss: 0.46357 | Regression loss: 0.80315 | Running loss: 1.26322\n",
      "Epoch: 1 | Iteration: 21 | Classification loss: 0.53206 | Regression loss: 0.86670 | Running loss: 1.26331\n",
      "Epoch: 1 | Iteration: 22 | Classification loss: 0.42719 | Regression loss: 0.79058 | Running loss: 1.26298\n",
      "Epoch: 1 | Iteration: 23 | Classification loss: 0.43985 | Regression loss: 0.64150 | Running loss: 1.26214\n",
      "Epoch: 1 | Iteration: 24 | Classification loss: 0.55523 | Regression loss: 0.80521 | Running loss: 1.26255\n",
      "Epoch: 1 | Iteration: 25 | Classification loss: 0.36818 | Regression loss: 0.80759 | Running loss: 1.26201\n",
      "Epoch: 1 | Iteration: 26 | Classification loss: 0.39135 | Regression loss: 0.85854 | Running loss: 1.26174\n",
      "Epoch: 1 | Iteration: 27 | Classification loss: 0.35477 | Regression loss: 0.81026 | Running loss: 1.26112\n",
      "Epoch: 1 | Iteration: 28 | Classification loss: 0.24081 | Regression loss: 0.68126 | Running loss: 1.26043\n",
      "Epoch: 1 | Iteration: 29 | Classification loss: 0.40016 | Regression loss: 0.78812 | Running loss: 1.25965\n",
      "Epoch: 1 | Iteration: 30 | Classification loss: 0.36120 | Regression loss: 0.84473 | Running loss: 1.25908\n",
      "Epoch: 1 | Iteration: 31 | Classification loss: 0.36950 | Regression loss: 0.76704 | Running loss: 1.25867\n",
      "Epoch: 1 | Iteration: 32 | Classification loss: 0.32289 | Regression loss: 0.74077 | Running loss: 1.25826\n",
      "Epoch: 1 | Iteration: 33 | Classification loss: 0.34598 | Regression loss: 0.81551 | Running loss: 1.25805\n",
      "Epoch: 1 | Iteration: 34 | Classification loss: 0.27027 | Regression loss: 0.58475 | Running loss: 1.25677\n",
      "Epoch: 1 | Iteration: 35 | Classification loss: 0.38811 | Regression loss: 0.79400 | Running loss: 1.25678\n",
      "Epoch: 1 | Iteration: 36 | Classification loss: 0.31913 | Regression loss: 0.75460 | Running loss: 1.25646\n",
      "Epoch: 1 | Iteration: 37 | Classification loss: 0.30032 | Regression loss: 0.66103 | Running loss: 1.25501\n",
      "Epoch: 1 | Iteration: 38 | Classification loss: 0.27377 | Regression loss: 0.68918 | Running loss: 1.25422\n",
      "Epoch: 1 | Iteration: 39 | Classification loss: 0.35470 | Regression loss: 0.79756 | Running loss: 1.25366\n",
      "Epoch: 1 | Iteration: 40 | Classification loss: 0.28264 | Regression loss: 0.73733 | Running loss: 1.25296\n",
      "Epoch: 1 | Iteration: 41 | Classification loss: 0.31351 | Regression loss: 0.65552 | Running loss: 1.25200\n",
      "Epoch: 1 | Iteration: 42 | Classification loss: 0.69668 | Regression loss: 0.57008 | Running loss: 1.25200\n",
      "Epoch: 1 | Iteration: 43 | Classification loss: 0.36540 | Regression loss: 0.72203 | Running loss: 1.25156\n",
      "Epoch: 1 | Iteration: 44 | Classification loss: 0.32511 | Regression loss: 0.79713 | Running loss: 1.25043\n",
      "Epoch: 1 | Iteration: 45 | Classification loss: 0.28432 | Regression loss: 0.61854 | Running loss: 1.24944\n",
      "Epoch: 1 | Iteration: 46 | Classification loss: 0.44524 | Regression loss: 0.81041 | Running loss: 1.24916\n",
      "Epoch: 1 | Iteration: 47 | Classification loss: 0.48154 | Regression loss: 0.78595 | Running loss: 1.24847\n",
      "Epoch: 1 | Iteration: 48 | Classification loss: 0.32731 | Regression loss: 0.70791 | Running loss: 1.24778\n",
      "Epoch: 1 | Iteration: 49 | Classification loss: 0.40575 | Regression loss: 0.85095 | Running loss: 1.24760\n",
      "Epoch: 1 | Iteration: 50 | Classification loss: 0.32182 | Regression loss: 0.64503 | Running loss: 1.24645\n",
      "Epoch: 1 | Iteration: 51 | Classification loss: 0.48765 | Regression loss: 0.79975 | Running loss: 1.24611\n",
      "Epoch: 1 | Iteration: 52 | Classification loss: 0.42911 | Regression loss: 0.84946 | Running loss: 1.24625\n",
      "Epoch: 1 | Iteration: 53 | Classification loss: 0.40160 | Regression loss: 0.73163 | Running loss: 1.24659\n",
      "Epoch: 1 | Iteration: 54 | Classification loss: 0.40762 | Regression loss: 0.82647 | Running loss: 1.24643\n",
      "Epoch: 1 | Iteration: 55 | Classification loss: 0.37217 | Regression loss: 0.76788 | Running loss: 1.24608\n",
      "Epoch: 1 | Iteration: 56 | Classification loss: 0.42151 | Regression loss: 0.87500 | Running loss: 1.24606\n",
      "Epoch: 1 | Iteration: 57 | Classification loss: 0.34933 | Regression loss: 0.69234 | Running loss: 1.24543\n",
      "Epoch: 1 | Iteration: 58 | Classification loss: 0.58225 | Regression loss: 0.76125 | Running loss: 1.24517\n",
      "Epoch: 1 | Iteration: 59 | Classification loss: 0.52734 | Regression loss: 0.72627 | Running loss: 1.24519\n",
      "Epoch: 1 | Iteration: 60 | Classification loss: 0.31593 | Regression loss: 0.71214 | Running loss: 1.24471\n",
      "Epoch: 1 | Iteration: 61 | Classification loss: 0.29377 | Regression loss: 0.68774 | Running loss: 1.24420\n",
      "Epoch: 1 | Iteration: 62 | Classification loss: 0.41042 | Regression loss: 0.84746 | Running loss: 1.24389\n",
      "Epoch: 1 | Iteration: 63 | Classification loss: 0.64049 | Regression loss: 0.83068 | Running loss: 1.24393\n",
      "Epoch: 1 | Iteration: 64 | Classification loss: 0.42347 | Regression loss: 0.65509 | Running loss: 1.24314\n",
      "Epoch: 1 | Iteration: 65 | Classification loss: 0.48174 | Regression loss: 0.88114 | Running loss: 1.24315\n",
      "Epoch: 1 | Iteration: 66 | Classification loss: 0.43432 | Regression loss: 0.79449 | Running loss: 1.24316\n",
      "Epoch: 1 | Iteration: 67 | Classification loss: 0.39625 | Regression loss: 0.69107 | Running loss: 1.24262\n",
      "Epoch: 1 | Iteration: 68 | Classification loss: 0.45411 | Regression loss: 0.69492 | Running loss: 1.24185\n",
      "Epoch: 1 | Iteration: 69 | Classification loss: 0.36372 | Regression loss: 0.84104 | Running loss: 1.24137\n",
      "Epoch: 1 | Iteration: 70 | Classification loss: 0.41352 | Regression loss: 0.85517 | Running loss: 1.24134\n",
      "Epoch: 1 | Iteration: 71 | Classification loss: 0.52427 | Regression loss: 0.86416 | Running loss: 1.24164\n",
      "Epoch: 1 | Iteration: 72 | Classification loss: 0.40292 | Regression loss: 0.81165 | Running loss: 1.24116\n",
      "Epoch: 1 | Iteration: 73 | Classification loss: 0.46816 | Regression loss: 0.77982 | Running loss: 1.24107\n",
      "Epoch: 1 | Iteration: 74 | Classification loss: 0.35348 | Regression loss: 0.64741 | Running loss: 1.24075\n",
      "Epoch: 1 | Iteration: 75 | Classification loss: 0.35786 | Regression loss: 0.79025 | Running loss: 1.24030\n",
      "Epoch: 1 | Iteration: 76 | Classification loss: 0.34431 | Regression loss: 0.67259 | Running loss: 1.23936\n",
      "Epoch: 1 | Iteration: 77 | Classification loss: 0.31465 | Regression loss: 0.65500 | Running loss: 1.23866\n",
      "Epoch: 1 | Iteration: 78 | Classification loss: 0.44586 | Regression loss: 0.53671 | Running loss: 1.23780\n",
      "Epoch: 1 | Iteration: 79 | Classification loss: 0.33782 | Regression loss: 0.70106 | Running loss: 1.23788\n",
      "Epoch: 1 | Iteration: 80 | Classification loss: 0.30441 | Regression loss: 0.83022 | Running loss: 1.23795\n",
      "Epoch: 1 | Iteration: 81 | Classification loss: 0.41937 | Regression loss: 0.79752 | Running loss: 1.23774\n",
      "Epoch: 1 | Iteration: 82 | Classification loss: 0.29166 | Regression loss: 0.72987 | Running loss: 1.23701\n",
      "Epoch: 1 | Iteration: 83 | Classification loss: 0.35574 | Regression loss: 0.71161 | Running loss: 1.23682\n",
      "Epoch: 1 | Iteration: 84 | Classification loss: 0.39276 | Regression loss: 0.62710 | Running loss: 1.23482\n",
      "Epoch: 1 | Iteration: 85 | Classification loss: 0.40365 | Regression loss: 0.75069 | Running loss: 1.23486\n",
      "Epoch: 1 | Iteration: 86 | Classification loss: 0.41662 | Regression loss: 0.73297 | Running loss: 1.23459\n",
      "Epoch: 1 | Iteration: 87 | Classification loss: 0.40034 | Regression loss: 0.86552 | Running loss: 1.23443\n",
      "Epoch: 1 | Iteration: 88 | Classification loss: 0.50822 | Regression loss: 0.89038 | Running loss: 1.23473\n",
      "Epoch: 1 | Iteration: 89 | Classification loss: 0.37285 | Regression loss: 0.67562 | Running loss: 1.23427\n",
      "Epoch: 1 | Iteration: 90 | Classification loss: 0.44201 | Regression loss: 0.85485 | Running loss: 1.23402\n",
      "Epoch: 1 | Iteration: 91 | Classification loss: 0.47277 | Regression loss: 0.80259 | Running loss: 1.23376\n",
      "Epoch: 1 | Iteration: 92 | Classification loss: 0.30635 | Regression loss: 0.76341 | Running loss: 1.23304\n",
      "Epoch: 1 | Iteration: 93 | Classification loss: 0.41560 | Regression loss: 0.88088 | Running loss: 1.23345\n",
      "Epoch: 1 | Iteration: 94 | Classification loss: 0.35418 | Regression loss: 0.76346 | Running loss: 1.23302\n",
      "Epoch: 1 | Iteration: 95 | Classification loss: 0.49944 | Regression loss: 0.91859 | Running loss: 1.23303\n",
      "Epoch: 1 | Iteration: 96 | Classification loss: 0.36570 | Regression loss: 0.76289 | Running loss: 1.23326\n",
      "Epoch: 1 | Iteration: 97 | Classification loss: 0.32629 | Regression loss: 0.63323 | Running loss: 1.23209\n",
      "Epoch: 1 | Iteration: 98 | Classification loss: 0.41138 | Regression loss: 0.66693 | Running loss: 1.23167\n",
      "Epoch: 1 | Iteration: 99 | Classification loss: 0.35566 | Regression loss: 0.77089 | Running loss: 1.23160\n",
      "Epoch: 1 | Iteration: 100 | Classification loss: 0.31649 | Regression loss: 0.72518 | Running loss: 1.23100\n",
      "Epoch: 1 | Iteration: 101 | Classification loss: 0.32220 | Regression loss: 0.74558 | Running loss: 1.23103\n",
      "Epoch: 1 | Iteration: 102 | Classification loss: 0.36065 | Regression loss: 0.81317 | Running loss: 1.23085\n",
      "Epoch: 1 | Iteration: 103 | Classification loss: 0.38984 | Regression loss: 0.87584 | Running loss: 1.23081\n",
      "Epoch: 1 | Iteration: 104 | Classification loss: 0.59018 | Regression loss: 0.79865 | Running loss: 1.23071\n",
      "Epoch: 1 | Iteration: 105 | Classification loss: 0.35485 | Regression loss: 0.76722 | Running loss: 1.23022\n",
      "Epoch: 1 | Iteration: 106 | Classification loss: 0.29009 | Regression loss: 0.72863 | Running loss: 1.22986\n",
      "Epoch: 1 | Iteration: 107 | Classification loss: 0.27789 | Regression loss: 0.56846 | Running loss: 1.22886\n",
      "Epoch: 1 | Iteration: 108 | Classification loss: 0.38189 | Regression loss: 0.72322 | Running loss: 1.22818\n",
      "Epoch: 1 | Iteration: 109 | Classification loss: 0.37360 | Regression loss: 0.83922 | Running loss: 1.22796\n",
      "Epoch: 1 | Iteration: 110 | Classification loss: 0.36008 | Regression loss: 0.83221 | Running loss: 1.22770\n",
      "Epoch: 1 | Iteration: 111 | Classification loss: 0.43807 | Regression loss: 0.75654 | Running loss: 1.22765\n",
      "Epoch: 1 | Iteration: 112 | Classification loss: 0.38802 | Regression loss: 0.64740 | Running loss: 1.22691\n",
      "Epoch: 1 | Iteration: 113 | Classification loss: 0.44304 | Regression loss: 0.81816 | Running loss: 1.22708\n",
      "Epoch: 1 | Iteration: 114 | Classification loss: 0.36477 | Regression loss: 0.67962 | Running loss: 1.22668\n",
      "Epoch: 1 | Iteration: 115 | Classification loss: 0.32835 | Regression loss: 0.68009 | Running loss: 1.22625\n",
      "Epoch: 1 | Iteration: 116 | Classification loss: 0.47131 | Regression loss: 0.76012 | Running loss: 1.22627\n",
      "Epoch: 1 | Iteration: 117 | Classification loss: 0.53530 | Regression loss: 0.84215 | Running loss: 1.22643\n",
      "Epoch: 1 | Iteration: 118 | Classification loss: 0.26140 | Regression loss: 0.67535 | Running loss: 1.22548\n",
      "Epoch: 1 | Iteration: 119 | Classification loss: 0.43168 | Regression loss: 0.93100 | Running loss: 1.22533\n",
      "Epoch: 1 | Iteration: 120 | Classification loss: 0.32481 | Regression loss: 0.73012 | Running loss: 1.22498\n",
      "Epoch: 1 | Iteration: 121 | Classification loss: 0.43177 | Regression loss: 0.76299 | Running loss: 1.22479\n",
      "Epoch: 1 | Iteration: 122 | Classification loss: 0.32542 | Regression loss: 0.68076 | Running loss: 1.22433\n",
      "Epoch: 1 | Iteration: 123 | Classification loss: 0.37812 | Regression loss: 0.75373 | Running loss: 1.22400\n",
      "Epoch: 1 | Iteration: 124 | Classification loss: 0.49374 | Regression loss: 0.72475 | Running loss: 1.22389\n",
      "Epoch: 1 | Iteration: 125 | Classification loss: 0.30409 | Regression loss: 0.67857 | Running loss: 1.22314\n",
      "Epoch: 1 | Iteration: 126 | Classification loss: 0.45620 | Regression loss: 0.72791 | Running loss: 1.22321\n",
      "Epoch: 1 | Iteration: 127 | Classification loss: 0.38643 | Regression loss: 0.81733 | Running loss: 1.22303\n",
      "Epoch: 1 | Iteration: 128 | Classification loss: 0.35163 | Regression loss: 0.80787 | Running loss: 1.22207\n",
      "Epoch: 1 | Iteration: 129 | Classification loss: 0.32657 | Regression loss: 0.73954 | Running loss: 1.22136\n",
      "Epoch: 1 | Iteration: 130 | Classification loss: 0.25554 | Regression loss: 0.65824 | Running loss: 1.22086\n",
      "Epoch: 1 | Iteration: 131 | Classification loss: 0.24876 | Regression loss: 0.57875 | Running loss: 1.21995\n",
      "Epoch: 1 | Iteration: 132 | Classification loss: 0.31003 | Regression loss: 0.74162 | Running loss: 1.21979\n",
      "Epoch: 1 | Iteration: 133 | Classification loss: 0.38227 | Regression loss: 0.70564 | Running loss: 1.21946\n",
      "Epoch: 1 | Iteration: 134 | Classification loss: 0.34578 | Regression loss: 0.59441 | Running loss: 1.21894\n",
      "Epoch: 1 | Iteration: 135 | Classification loss: 0.27318 | Regression loss: 0.60361 | Running loss: 1.21767\n",
      "Epoch: 1 | Iteration: 136 | Classification loss: 0.29728 | Regression loss: 0.67118 | Running loss: 1.21690\n",
      "Epoch: 1 | Iteration: 137 | Classification loss: 0.34751 | Regression loss: 0.81713 | Running loss: 1.21657\n",
      "Epoch: 1 | Iteration: 138 | Classification loss: 0.33118 | Regression loss: 0.70634 | Running loss: 1.21595\n",
      "Epoch: 1 | Iteration: 139 | Classification loss: 0.33131 | Regression loss: 0.80015 | Running loss: 1.21564\n",
      "Epoch: 1 | Iteration: 140 | Classification loss: 0.35142 | Regression loss: 0.85468 | Running loss: 1.21579\n",
      "Epoch: 1 | Iteration: 141 | Classification loss: 0.35130 | Regression loss: 0.85316 | Running loss: 1.21554\n",
      "Epoch: 1 | Iteration: 142 | Classification loss: 0.31264 | Regression loss: 0.74831 | Running loss: 1.21477\n",
      "Epoch: 1 | Iteration: 143 | Classification loss: 0.46228 | Regression loss: 0.78554 | Running loss: 1.21424\n",
      "Epoch: 1 | Iteration: 144 | Classification loss: 0.29046 | Regression loss: 0.67915 | Running loss: 1.21353\n",
      "Epoch: 1 | Iteration: 145 | Classification loss: 0.32102 | Regression loss: 0.78448 | Running loss: 1.21326\n",
      "Epoch: 1 | Iteration: 146 | Classification loss: 0.30577 | Regression loss: 0.69580 | Running loss: 1.21237\n",
      "Epoch: 1 | Iteration: 147 | Classification loss: 0.34974 | Regression loss: 0.81151 | Running loss: 1.21252\n",
      "Epoch: 1 | Iteration: 148 | Classification loss: 0.50820 | Regression loss: 0.88136 | Running loss: 1.21250\n",
      "Epoch: 1 | Iteration: 149 | Classification loss: 0.25062 | Regression loss: 0.54414 | Running loss: 1.21164\n",
      "Epoch: 1 | Iteration: 150 | Classification loss: 0.60915 | Regression loss: 0.83443 | Running loss: 1.21187\n",
      "Epoch: 1 | Iteration: 151 | Classification loss: 0.40032 | Regression loss: 0.71065 | Running loss: 1.21093\n",
      "Epoch: 1 | Iteration: 152 | Classification loss: 0.38077 | Regression loss: 0.80187 | Running loss: 1.21106\n",
      "Epoch: 1 | Iteration: 153 | Classification loss: 0.45408 | Regression loss: 0.71038 | Running loss: 1.21112\n",
      "Epoch: 1 | Iteration: 154 | Classification loss: 0.31773 | Regression loss: 0.81197 | Running loss: 1.21100\n",
      "Epoch: 1 | Iteration: 155 | Classification loss: 0.42081 | Regression loss: 0.87363 | Running loss: 1.21133\n",
      "Epoch: 1 | Iteration: 156 | Classification loss: 0.30616 | Regression loss: 0.67365 | Running loss: 1.21111\n",
      "Epoch: 1 | Iteration: 157 | Classification loss: 0.35982 | Regression loss: 0.77684 | Running loss: 1.21094\n",
      "Epoch: 1 | Iteration: 158 | Classification loss: 0.36533 | Regression loss: 0.86485 | Running loss: 1.21083\n",
      "Epoch: 1 | Iteration: 159 | Classification loss: 0.26698 | Regression loss: 0.58467 | Running loss: 1.20941\n",
      "Epoch: 1 | Iteration: 160 | Classification loss: 0.44654 | Regression loss: 0.76025 | Running loss: 1.20883\n",
      "Epoch: 1 | Iteration: 161 | Classification loss: 0.48293 | Regression loss: 0.71099 | Running loss: 1.20865\n",
      "Epoch: 1 | Iteration: 162 | Classification loss: 0.33245 | Regression loss: 0.73837 | Running loss: 1.20798\n",
      "Epoch: 1 | Iteration: 163 | Classification loss: 0.38025 | Regression loss: 0.81139 | Running loss: 1.20801\n",
      "Epoch: 1 | Iteration: 164 | Classification loss: 0.35257 | Regression loss: 0.64594 | Running loss: 1.20768\n",
      "Epoch: 1 | Iteration: 165 | Classification loss: 0.46760 | Regression loss: 0.46032 | Running loss: 1.20691\n",
      "Epoch: 1 | Iteration: 166 | Classification loss: 0.29255 | Regression loss: 0.71201 | Running loss: 1.20626\n",
      "Epoch: 1 | Iteration: 167 | Classification loss: 0.31480 | Regression loss: 0.71783 | Running loss: 1.20596\n",
      "Epoch: 1 | Iteration: 168 | Classification loss: 0.33805 | Regression loss: 0.58366 | Running loss: 1.20541\n",
      "Epoch: 1 | Iteration: 169 | Classification loss: 0.32348 | Regression loss: 0.80676 | Running loss: 1.20500\n",
      "Epoch: 1 | Iteration: 170 | Classification loss: 0.40576 | Regression loss: 0.75064 | Running loss: 1.20519\n",
      "Epoch: 1 | Iteration: 171 | Classification loss: 0.43141 | Regression loss: 0.79870 | Running loss: 1.20518\n",
      "Epoch: 1 | Iteration: 172 | Classification loss: 0.34551 | Regression loss: 0.76496 | Running loss: 1.20481\n",
      "Epoch: 1 | Iteration: 173 | Classification loss: 0.39557 | Regression loss: 0.73942 | Running loss: 1.20438\n",
      "Epoch: 1 | Iteration: 174 | Classification loss: 0.28782 | Regression loss: 0.65442 | Running loss: 1.20386\n",
      "Epoch: 1 | Iteration: 175 | Classification loss: 0.43954 | Regression loss: 0.79732 | Running loss: 1.20375\n",
      "Epoch: 1 | Iteration: 176 | Classification loss: 0.35440 | Regression loss: 0.80253 | Running loss: 1.20365\n",
      "Epoch: 1 | Iteration: 177 | Classification loss: 0.34939 | Regression loss: 0.64675 | Running loss: 1.20322\n",
      "Epoch: 1 | Iteration: 178 | Classification loss: 0.33518 | Regression loss: 0.78647 | Running loss: 1.20207\n",
      "Epoch: 1 | Iteration: 179 | Classification loss: 0.43088 | Regression loss: 0.82846 | Running loss: 1.20207\n",
      "Epoch: 1 | Iteration: 180 | Classification loss: 0.52135 | Regression loss: 0.71984 | Running loss: 1.20235\n",
      "Epoch: 1 | Iteration: 181 | Classification loss: 0.31472 | Regression loss: 0.49922 | Running loss: 1.20160\n",
      "Epoch: 1 | Iteration: 182 | Classification loss: 0.32412 | Regression loss: 0.64444 | Running loss: 1.20087\n",
      "Epoch: 1 | Iteration: 183 | Classification loss: 0.33542 | Regression loss: 0.71706 | Running loss: 1.20032\n",
      "Epoch: 1 | Iteration: 184 | Classification loss: 0.34082 | Regression loss: 0.79017 | Running loss: 1.20004\n",
      "Epoch: 1 | Iteration: 185 | Classification loss: 0.41236 | Regression loss: 0.80381 | Running loss: 1.19994\n",
      "Epoch: 1 | Iteration: 186 | Classification loss: 0.34459 | Regression loss: 0.77147 | Running loss: 1.19955\n",
      "Epoch: 1 | Iteration: 187 | Classification loss: 0.33251 | Regression loss: 0.62922 | Running loss: 1.19911\n",
      "Epoch: 1 | Iteration: 188 | Classification loss: 0.33725 | Regression loss: 0.74359 | Running loss: 1.19895\n",
      "Epoch: 1 | Iteration: 189 | Classification loss: 0.34546 | Regression loss: 0.75186 | Running loss: 1.19852\n",
      "Epoch: 1 | Iteration: 190 | Classification loss: 0.49379 | Regression loss: 0.84938 | Running loss: 1.19842\n",
      "Epoch: 1 | Iteration: 191 | Classification loss: 0.25591 | Regression loss: 0.58960 | Running loss: 1.19730\n",
      "Epoch: 1 | Iteration: 192 | Classification loss: 0.41528 | Regression loss: 0.77315 | Running loss: 1.19731\n",
      "Epoch: 1 | Iteration: 193 | Classification loss: 0.50171 | Regression loss: 0.82197 | Running loss: 1.19767\n",
      "Epoch: 1 | Iteration: 194 | Classification loss: 0.31268 | Regression loss: 0.70393 | Running loss: 1.19734\n",
      "Epoch: 1 | Iteration: 195 | Classification loss: 0.47342 | Regression loss: 0.82513 | Running loss: 1.19723\n",
      "Epoch: 1 | Iteration: 196 | Classification loss: 0.40053 | Regression loss: 0.77463 | Running loss: 1.19713\n",
      "Epoch: 1 | Iteration: 197 | Classification loss: 0.42558 | Regression loss: 0.77405 | Running loss: 1.19656\n",
      "Epoch: 1 | Iteration: 198 | Classification loss: 0.34518 | Regression loss: 0.66407 | Running loss: 1.19627\n",
      "Epoch: 1 | Iteration: 199 | Classification loss: 0.43974 | Regression loss: 0.76487 | Running loss: 1.19605\n",
      "Epoch: 1 | Iteration: 200 | Classification loss: 0.40233 | Regression loss: 0.82225 | Running loss: 1.19603\n",
      "Epoch: 1 | Iteration: 201 | Classification loss: 0.37573 | Regression loss: 0.81058 | Running loss: 1.19546\n",
      "Epoch: 1 | Iteration: 202 | Classification loss: 0.33644 | Regression loss: 0.70966 | Running loss: 1.19467\n",
      "Epoch: 1 | Iteration: 203 | Classification loss: 0.44674 | Regression loss: 0.74106 | Running loss: 1.19443\n",
      "Epoch: 1 | Iteration: 204 | Classification loss: 0.43803 | Regression loss: 0.81296 | Running loss: 1.19439\n",
      "Epoch: 1 | Iteration: 205 | Classification loss: 0.31559 | Regression loss: 0.68169 | Running loss: 1.19408\n",
      "Epoch: 1 | Iteration: 206 | Classification loss: 0.28487 | Regression loss: 0.56910 | Running loss: 1.19381\n",
      "Epoch: 1 | Iteration: 207 | Classification loss: 0.35214 | Regression loss: 0.78045 | Running loss: 1.19404\n",
      "Epoch: 1 | Iteration: 208 | Classification loss: 0.39181 | Regression loss: 0.77770 | Running loss: 1.19339\n",
      "Epoch: 1 | Iteration: 209 | Classification loss: 0.27324 | Regression loss: 0.60299 | Running loss: 1.19251\n",
      "Epoch: 1 | Iteration: 210 | Classification loss: 0.43401 | Regression loss: 0.87964 | Running loss: 1.19252\n",
      "Epoch: 1 | Iteration: 211 | Classification loss: 0.35205 | Regression loss: 0.85596 | Running loss: 1.19236\n",
      "Epoch: 1 | Iteration: 212 | Classification loss: 0.35161 | Regression loss: 0.75631 | Running loss: 1.19158\n",
      "Epoch: 1 | Iteration: 213 | Classification loss: 0.38863 | Regression loss: 0.76155 | Running loss: 1.19121\n",
      "Epoch: 1 | Iteration: 214 | Classification loss: 1.48420 | Regression loss: 0.93514 | Running loss: 1.19304\n",
      "Epoch: 1 | Iteration: 215 | Classification loss: 0.34230 | Regression loss: 0.72718 | Running loss: 1.19292\n",
      "Epoch: 1 | Iteration: 216 | Classification loss: 0.41598 | Regression loss: 0.79834 | Running loss: 1.19260\n",
      "Epoch: 1 | Iteration: 217 | Classification loss: 0.31939 | Regression loss: 0.70119 | Running loss: 1.19262\n",
      "Epoch: 1 | Iteration: 218 | Classification loss: 0.33344 | Regression loss: 0.68054 | Running loss: 1.19203\n",
      "Epoch: 1 | Iteration: 219 | Classification loss: 0.38886 | Regression loss: 0.67059 | Running loss: 1.19167\n",
      "Epoch: 1 | Iteration: 220 | Classification loss: 0.36238 | Regression loss: 0.72417 | Running loss: 1.19095\n",
      "Epoch: 1 | Iteration: 221 | Classification loss: 0.43484 | Regression loss: 0.73133 | Running loss: 1.19124\n",
      "Epoch: 1 | Iteration: 222 | Classification loss: 0.33017 | Regression loss: 0.77318 | Running loss: 1.19054\n",
      "Epoch: 1 | Iteration: 223 | Classification loss: 0.43024 | Regression loss: 0.77576 | Running loss: 1.19019\n",
      "Epoch: 1 | Iteration: 224 | Classification loss: 0.37995 | Regression loss: 0.80344 | Running loss: 1.18997\n",
      "Epoch: 1 | Iteration: 225 | Classification loss: 0.38766 | Regression loss: 0.82989 | Running loss: 1.18988\n",
      "Epoch: 1 | Iteration: 226 | Classification loss: 0.44972 | Regression loss: 0.81376 | Running loss: 1.18968\n",
      "Epoch: 1 | Iteration: 227 | Classification loss: 0.41844 | Regression loss: 0.65435 | Running loss: 1.18894\n",
      "Epoch: 1 | Iteration: 228 | Classification loss: 0.38059 | Regression loss: 0.78097 | Running loss: 1.18873\n",
      "Epoch: 1 | Iteration: 229 | Classification loss: 0.27543 | Regression loss: 0.66426 | Running loss: 1.18801\n",
      "Epoch: 1 | Iteration: 230 | Classification loss: 0.38176 | Regression loss: 0.72645 | Running loss: 1.18795\n",
      "Epoch: 1 | Iteration: 231 | Classification loss: 0.43459 | Regression loss: 0.69391 | Running loss: 1.18770\n",
      "Epoch: 1 | Iteration: 232 | Classification loss: 0.30661 | Regression loss: 0.70666 | Running loss: 1.18724\n",
      "Epoch: 1 | Iteration: 233 | Classification loss: 0.33047 | Regression loss: 0.65159 | Running loss: 1.18627\n",
      "Epoch: 1 | Iteration: 234 | Classification loss: 0.36425 | Regression loss: 0.82854 | Running loss: 1.18293\n",
      "Epoch: 1 | Iteration: 235 | Classification loss: 0.40858 | Regression loss: 0.78256 | Running loss: 1.18297\n",
      "Epoch: 1 | Iteration: 236 | Classification loss: 0.24488 | Regression loss: 0.58639 | Running loss: 1.18221\n",
      "Epoch: 1 | Iteration: 237 | Classification loss: 0.52022 | Regression loss: 0.87389 | Running loss: 1.18228\n",
      "Epoch: 1 | Iteration: 238 | Classification loss: 0.22821 | Regression loss: 0.60692 | Running loss: 1.18140\n",
      "Epoch: 1 | Iteration: 239 | Classification loss: 0.48313 | Regression loss: 0.84061 | Running loss: 1.18135\n",
      "Epoch: 1 | Iteration: 240 | Classification loss: 0.36611 | Regression loss: 0.76297 | Running loss: 1.18126\n",
      "Epoch: 1 | Iteration: 241 | Classification loss: 0.31279 | Regression loss: 0.66025 | Running loss: 1.18098\n",
      "Epoch: 1 | Iteration: 242 | Classification loss: 0.30926 | Regression loss: 0.83850 | Running loss: 1.18095\n",
      "Epoch: 1 | Iteration: 243 | Classification loss: 0.40394 | Regression loss: 0.66014 | Running loss: 1.18037\n",
      "Epoch: 1 | Iteration: 244 | Classification loss: 0.39123 | Regression loss: 0.86836 | Running loss: 1.18046\n",
      "Epoch: 1 | Iteration: 245 | Classification loss: 0.41263 | Regression loss: 0.73920 | Running loss: 1.18071\n",
      "Epoch: 1 | Iteration: 246 | Classification loss: 0.37188 | Regression loss: 0.65728 | Running loss: 1.18071\n",
      "Epoch: 1 | Iteration: 247 | Classification loss: 0.31103 | Regression loss: 0.61913 | Running loss: 1.17991\n",
      "Epoch: 1 | Iteration: 248 | Classification loss: 0.39028 | Regression loss: 0.80179 | Running loss: 1.17985\n",
      "Epoch: 1 | Iteration: 249 | Classification loss: 0.82850 | Regression loss: 0.90618 | Running loss: 1.18127\n",
      "Epoch: 1 | Iteration: 250 | Classification loss: 0.34022 | Regression loss: 0.80497 | Running loss: 1.18106\n",
      "Epoch: 1 | Iteration: 251 | Classification loss: 0.38804 | Regression loss: 0.81468 | Running loss: 1.18085\n",
      "Epoch: 1 | Iteration: 252 | Classification loss: 0.45409 | Regression loss: 0.76565 | Running loss: 1.18087\n",
      "Epoch: 1 | Iteration: 253 | Classification loss: 0.35274 | Regression loss: 0.76150 | Running loss: 1.18077\n",
      "Epoch: 1 | Iteration: 254 | Classification loss: 0.46953 | Regression loss: 0.85677 | Running loss: 1.18083\n",
      "Epoch: 1 | Iteration: 255 | Classification loss: 0.46241 | Regression loss: 0.55644 | Running loss: 1.18021\n",
      "Epoch: 1 | Iteration: 256 | Classification loss: 0.34766 | Regression loss: 0.82603 | Running loss: 1.18066\n",
      "Epoch: 1 | Iteration: 257 | Classification loss: 0.37284 | Regression loss: 0.81909 | Running loss: 1.18027\n",
      "Epoch: 1 | Iteration: 258 | Classification loss: 0.48605 | Regression loss: 0.86999 | Running loss: 1.18158\n",
      "Epoch: 1 | Iteration: 259 | Classification loss: 0.37347 | Regression loss: 0.81664 | Running loss: 1.18135\n",
      "Epoch: 1 | Iteration: 260 | Classification loss: 0.36490 | Regression loss: 0.76393 | Running loss: 1.18097\n",
      "Epoch: 1 | Iteration: 261 | Classification loss: 0.29417 | Regression loss: 0.65004 | Running loss: 1.18038\n",
      "Epoch: 1 | Iteration: 262 | Classification loss: 0.36308 | Regression loss: 0.73906 | Running loss: 1.17977\n",
      "Epoch: 1 | Iteration: 263 | Classification loss: 0.29428 | Regression loss: 0.81040 | Running loss: 1.17967\n",
      "Epoch: 1 | Iteration: 264 | Classification loss: 0.31736 | Regression loss: 0.64839 | Running loss: 1.17861\n",
      "Epoch: 1 | Iteration: 265 | Classification loss: 0.39033 | Regression loss: 0.80638 | Running loss: 1.17843\n",
      "Epoch: 1 | Iteration: 266 | Classification loss: 0.48828 | Regression loss: 0.87766 | Running loss: 1.17840\n",
      "Epoch: 1 | Iteration: 267 | Classification loss: 0.41980 | Regression loss: 0.70242 | Running loss: 1.17812\n",
      "Epoch: 1 | Iteration: 268 | Classification loss: 0.37234 | Regression loss: 0.76469 | Running loss: 1.17784\n",
      "Epoch: 1 | Iteration: 269 | Classification loss: 0.32155 | Regression loss: 0.82093 | Running loss: 1.17757\n",
      "Epoch: 1 | Iteration: 270 | Classification loss: 0.33541 | Regression loss: 0.70037 | Running loss: 1.17690\n",
      "Epoch: 1 | Iteration: 271 | Classification loss: 0.32617 | Regression loss: 0.72487 | Running loss: 1.17629\n",
      "Epoch: 1 | Iteration: 272 | Classification loss: 0.18787 | Regression loss: 0.53468 | Running loss: 1.17546\n",
      "Epoch: 1 | Iteration: 273 | Classification loss: 0.34635 | Regression loss: 0.73718 | Running loss: 1.17491\n",
      "Epoch: 1 | Iteration: 274 | Classification loss: 0.34924 | Regression loss: 0.65054 | Running loss: 1.17343\n",
      "Epoch: 1 | Iteration: 275 | Classification loss: 0.37292 | Regression loss: 0.76041 | Running loss: 1.17364\n",
      "Epoch: 1 | Iteration: 276 | Classification loss: 0.31587 | Regression loss: 0.78735 | Running loss: 1.17350\n",
      "Epoch: 1 | Iteration: 277 | Classification loss: 0.55855 | Regression loss: 0.94032 | Running loss: 1.17368\n",
      "Epoch: 1 | Iteration: 278 | Classification loss: 0.50383 | Regression loss: 0.83310 | Running loss: 1.17386\n",
      "Epoch: 1 | Iteration: 279 | Classification loss: 0.26981 | Regression loss: 0.50298 | Running loss: 1.17305\n",
      "Epoch: 1 | Iteration: 280 | Classification loss: 0.38219 | Regression loss: 0.80846 | Running loss: 1.17353\n",
      "Epoch: 1 | Iteration: 281 | Classification loss: 0.37252 | Regression loss: 0.77283 | Running loss: 1.17360\n",
      "Epoch: 1 | Iteration: 282 | Classification loss: 0.37968 | Regression loss: 0.78025 | Running loss: 1.17341\n",
      "Epoch: 1 | Iteration: 283 | Classification loss: 0.31487 | Regression loss: 0.75856 | Running loss: 1.17301\n",
      "Epoch: 1 | Iteration: 284 | Classification loss: 0.43892 | Regression loss: 0.84382 | Running loss: 1.17320\n",
      "Epoch: 1 | Iteration: 285 | Classification loss: 0.39479 | Regression loss: 0.90128 | Running loss: 1.17320\n",
      "Epoch: 1 | Iteration: 286 | Classification loss: 0.44417 | Regression loss: 0.80004 | Running loss: 1.17302\n",
      "Epoch: 1 | Iteration: 287 | Classification loss: 0.37878 | Regression loss: 0.74185 | Running loss: 1.17292\n",
      "Epoch: 1 | Iteration: 288 | Classification loss: 0.29158 | Regression loss: 0.66819 | Running loss: 1.17290\n",
      "Epoch: 1 | Iteration: 289 | Classification loss: 0.27014 | Regression loss: 0.70455 | Running loss: 1.17236\n",
      "Epoch: 1 | Iteration: 290 | Classification loss: 0.52430 | Regression loss: 0.76769 | Running loss: 1.17261\n",
      "Epoch: 1 | Iteration: 291 | Classification loss: 0.48459 | Regression loss: 0.75156 | Running loss: 1.17265\n",
      "Epoch: 1 | Iteration: 292 | Classification loss: 0.37663 | Regression loss: 0.71932 | Running loss: 1.17178\n",
      "Epoch: 1 | Iteration: 293 | Classification loss: 0.39492 | Regression loss: 0.80804 | Running loss: 1.17155\n",
      "Epoch: 1 | Iteration: 294 | Classification loss: 0.42579 | Regression loss: 0.69106 | Running loss: 1.17160\n",
      "Epoch: 1 | Iteration: 295 | Classification loss: 0.53197 | Regression loss: 0.80493 | Running loss: 1.17192\n",
      "Epoch: 1 | Iteration: 296 | Classification loss: 0.30527 | Regression loss: 0.69765 | Running loss: 1.17169\n",
      "Epoch: 1 | Iteration: 297 | Classification loss: 0.46778 | Regression loss: 0.84197 | Running loss: 1.17118\n",
      "Epoch: 1 | Iteration: 298 | Classification loss: 0.43228 | Regression loss: 0.81539 | Running loss: 1.17129\n",
      "Epoch: 1 | Iteration: 299 | Classification loss: 0.49499 | Regression loss: 0.81353 | Running loss: 1.17153\n",
      "Epoch: 1 | Iteration: 300 | Classification loss: 0.59153 | Regression loss: 0.88936 | Running loss: 1.17259\n",
      "Epoch: 1 | Iteration: 301 | Classification loss: 0.38406 | Regression loss: 0.84601 | Running loss: 1.17251\n",
      "Epoch: 1 | Iteration: 302 | Classification loss: 0.35526 | Regression loss: 0.67271 | Running loss: 1.17206\n",
      "Epoch: 1 | Iteration: 303 | Classification loss: 0.34971 | Regression loss: 0.78079 | Running loss: 1.17179\n",
      "Epoch: 1 | Iteration: 304 | Classification loss: 0.30001 | Regression loss: 0.75600 | Running loss: 1.17088\n",
      "Epoch: 1 | Iteration: 305 | Classification loss: 0.27144 | Regression loss: 0.60617 | Running loss: 1.16992\n",
      "Epoch: 1 | Iteration: 306 | Classification loss: 0.41053 | Regression loss: 0.82968 | Running loss: 1.16997\n",
      "Epoch: 1 | Iteration: 307 | Classification loss: 0.38241 | Regression loss: 0.75151 | Running loss: 1.16995\n",
      "Epoch: 1 | Iteration: 308 | Classification loss: 0.29901 | Regression loss: 0.73732 | Running loss: 1.16965\n",
      "Epoch: 1 | Iteration: 309 | Classification loss: 0.31225 | Regression loss: 0.78673 | Running loss: 1.16914\n",
      "Epoch: 1 | Iteration: 310 | Classification loss: 0.40989 | Regression loss: 0.81157 | Running loss: 1.16913\n",
      "Epoch: 1 | Iteration: 311 | Classification loss: 0.38038 | Regression loss: 0.81378 | Running loss: 1.16959\n",
      "Epoch: 1 | Iteration: 312 | Classification loss: 0.38682 | Regression loss: 0.82849 | Running loss: 1.16922\n",
      "Epoch: 1 | Iteration: 313 | Classification loss: 0.35069 | Regression loss: 0.60223 | Running loss: 1.16888\n",
      "Epoch: 1 | Iteration: 314 | Classification loss: 0.31825 | Regression loss: 0.66290 | Running loss: 1.16805\n",
      "Epoch: 1 | Iteration: 315 | Classification loss: 0.28415 | Regression loss: 0.64487 | Running loss: 1.16744\n",
      "Epoch: 1 | Iteration: 316 | Classification loss: 0.33115 | Regression loss: 0.76800 | Running loss: 1.16725\n",
      "Epoch: 1 | Iteration: 317 | Classification loss: 0.35394 | Regression loss: 0.73877 | Running loss: 1.16692\n",
      "Epoch: 1 | Iteration: 318 | Classification loss: 0.30848 | Regression loss: 0.73217 | Running loss: 1.16654\n",
      "Epoch: 1 | Iteration: 319 | Classification loss: 0.39697 | Regression loss: 0.86108 | Running loss: 1.16724\n",
      "Epoch: 1 | Iteration: 320 | Classification loss: 0.42623 | Regression loss: 0.68271 | Running loss: 1.16688\n",
      "Epoch: 1 | Iteration: 321 | Classification loss: 0.28434 | Regression loss: 0.75167 | Running loss: 1.16716\n",
      "Epoch: 1 | Iteration: 322 | Classification loss: 0.38518 | Regression loss: 0.78643 | Running loss: 1.16738\n",
      "Epoch: 1 | Iteration: 323 | Classification loss: 0.30210 | Regression loss: 0.69129 | Running loss: 1.16667\n",
      "Epoch: 1 | Iteration: 324 | Classification loss: 0.33344 | Regression loss: 0.79504 | Running loss: 1.16618\n",
      "Epoch: 1 | Iteration: 325 | Classification loss: 0.38311 | Regression loss: 0.78023 | Running loss: 1.16592\n",
      "Epoch: 1 | Iteration: 326 | Classification loss: 0.45979 | Regression loss: 0.75696 | Running loss: 1.16635\n",
      "Epoch: 1 | Iteration: 327 | Classification loss: 0.45015 | Regression loss: 0.73339 | Running loss: 1.16608\n",
      "Epoch: 1 | Iteration: 328 | Classification loss: 0.39836 | Regression loss: 0.70062 | Running loss: 1.16566\n",
      "Epoch: 1 | Iteration: 329 | Classification loss: 0.22892 | Regression loss: 0.67602 | Running loss: 1.16551\n",
      "Epoch: 1 | Iteration: 330 | Classification loss: 0.29968 | Regression loss: 0.60875 | Running loss: 1.16477\n",
      "Epoch: 1 | Iteration: 331 | Classification loss: 0.36863 | Regression loss: 0.81310 | Running loss: 1.16471\n",
      "Epoch: 1 | Iteration: 332 | Classification loss: 0.46519 | Regression loss: 0.80585 | Running loss: 1.16509\n",
      "Epoch: 1 | Iteration: 333 | Classification loss: 0.34950 | Regression loss: 0.71382 | Running loss: 1.16455\n",
      "Epoch: 1 | Iteration: 334 | Classification loss: 0.34943 | Regression loss: 0.66481 | Running loss: 1.16416\n",
      "Epoch: 1 | Iteration: 335 | Classification loss: 0.45665 | Regression loss: 0.77273 | Running loss: 1.16398\n",
      "Epoch: 1 | Iteration: 336 | Classification loss: 0.34154 | Regression loss: 0.77843 | Running loss: 1.16377\n",
      "Epoch: 1 | Iteration: 337 | Classification loss: 0.48812 | Regression loss: 0.81657 | Running loss: 1.16320\n",
      "Epoch: 1 | Iteration: 338 | Classification loss: 0.28992 | Regression loss: 0.67892 | Running loss: 1.16272\n",
      "Epoch: 1 | Iteration: 339 | Classification loss: 0.36311 | Regression loss: 0.78699 | Running loss: 1.16213\n",
      "Epoch: 1 | Iteration: 340 | Classification loss: 0.37170 | Regression loss: 0.68688 | Running loss: 1.16195\n",
      "Epoch: 1 | Iteration: 341 | Classification loss: 0.39877 | Regression loss: 0.76687 | Running loss: 1.16164\n",
      "Epoch: 1 | Iteration: 342 | Classification loss: 0.44496 | Regression loss: 0.87814 | Running loss: 1.16183\n",
      "Epoch: 1 | Iteration: 343 | Classification loss: 0.46431 | Regression loss: 0.78609 | Running loss: 1.16116\n",
      "Epoch: 1 | Iteration: 344 | Classification loss: 0.36937 | Regression loss: 0.70077 | Running loss: 1.16056\n",
      "Epoch: 1 | Iteration: 345 | Classification loss: 0.32086 | Regression loss: 0.81131 | Running loss: 1.16025\n",
      "Epoch: 1 | Iteration: 346 | Classification loss: 0.32062 | Regression loss: 0.79724 | Running loss: 1.15997\n",
      "Epoch: 1 | Iteration: 347 | Classification loss: 0.41832 | Regression loss: 0.91228 | Running loss: 1.16005\n",
      "Epoch: 1 | Iteration: 348 | Classification loss: 0.36374 | Regression loss: 0.68717 | Running loss: 1.15988\n",
      "Epoch: 1 | Iteration: 349 | Classification loss: 0.46097 | Regression loss: 0.84217 | Running loss: 1.16017\n",
      "Epoch: 1 | Iteration: 350 | Classification loss: 0.33898 | Regression loss: 0.65333 | Running loss: 1.15949\n",
      "Epoch: 1 | Iteration: 351 | Classification loss: 0.36211 | Regression loss: 0.66780 | Running loss: 1.15866\n",
      "Epoch: 1 | Iteration: 352 | Classification loss: 0.40906 | Regression loss: 0.72642 | Running loss: 1.15864\n",
      "Epoch: 1 | Iteration: 353 | Classification loss: 0.37268 | Regression loss: 0.89396 | Running loss: 1.15883\n",
      "Epoch: 1 | Iteration: 354 | Classification loss: 0.36371 | Regression loss: 0.86179 | Running loss: 1.15867\n",
      "Epoch: 1 | Iteration: 355 | Classification loss: 0.31982 | Regression loss: 0.67409 | Running loss: 1.15791\n",
      "Epoch: 1 | Iteration: 356 | Classification loss: 0.42383 | Regression loss: 0.82468 | Running loss: 1.15821\n",
      "Epoch: 1 | Iteration: 357 | Classification loss: 0.32773 | Regression loss: 0.86790 | Running loss: 1.15842\n",
      "Epoch: 1 | Iteration: 358 | Classification loss: 0.36535 | Regression loss: 0.80115 | Running loss: 1.15792\n",
      "Epoch: 1 | Iteration: 359 | Classification loss: 0.27283 | Regression loss: 0.58888 | Running loss: 1.15725\n",
      "Epoch: 1 | Iteration: 360 | Classification loss: 0.41687 | Regression loss: 0.71486 | Running loss: 1.15687\n",
      "Epoch: 1 | Iteration: 361 | Classification loss: 0.37629 | Regression loss: 0.73352 | Running loss: 1.15617\n",
      "Epoch: 1 | Iteration: 362 | Classification loss: 0.35488 | Regression loss: 0.75212 | Running loss: 1.15568\n",
      "Epoch: 1 | Iteration: 363 | Classification loss: 0.39712 | Regression loss: 0.54978 | Running loss: 1.15512\n",
      "Epoch: 1 | Iteration: 364 | Classification loss: 0.25319 | Regression loss: 0.74752 | Running loss: 1.15455\n",
      "Epoch: 1 | Iteration: 365 | Classification loss: 0.29850 | Regression loss: 0.65198 | Running loss: 1.15365\n",
      "Epoch: 1 | Iteration: 366 | Classification loss: 0.42698 | Regression loss: 0.73522 | Running loss: 1.15336\n",
      "Epoch: 1 | Iteration: 367 | Classification loss: 0.26606 | Regression loss: 0.57067 | Running loss: 1.15250\n",
      "Epoch: 1 | Iteration: 368 | Classification loss: 0.40703 | Regression loss: 0.85483 | Running loss: 1.15277\n",
      "Epoch: 1 | Iteration: 369 | Classification loss: 0.27003 | Regression loss: 0.73468 | Running loss: 1.15238\n",
      "Epoch: 1 | Iteration: 370 | Classification loss: 0.36724 | Regression loss: 0.72517 | Running loss: 1.15258\n",
      "Epoch: 1 | Iteration: 371 | Classification loss: 0.31237 | Regression loss: 0.64605 | Running loss: 1.15215\n",
      "Epoch: 1 | Iteration: 372 | Classification loss: 0.37662 | Regression loss: 0.82541 | Running loss: 1.15227\n",
      "Epoch: 1 | Iteration: 373 | Classification loss: 0.28863 | Regression loss: 0.61705 | Running loss: 1.15168\n",
      "Epoch: 1 | Iteration: 374 | Classification loss: 0.38964 | Regression loss: 0.79169 | Running loss: 1.15143\n",
      "Epoch: 1 | Iteration: 375 | Classification loss: 0.25709 | Regression loss: 0.63645 | Running loss: 1.15102\n",
      "Epoch: 1 | Iteration: 376 | Classification loss: 0.28489 | Regression loss: 0.68286 | Running loss: 1.15028\n",
      "Epoch: 1 | Iteration: 377 | Classification loss: 0.33899 | Regression loss: 0.65554 | Running loss: 1.14983\n",
      "Epoch: 1 | Iteration: 378 | Classification loss: 0.39192 | Regression loss: 0.75713 | Running loss: 1.15000\n",
      "Epoch: 1 | Iteration: 379 | Classification loss: 0.72619 | Regression loss: 0.73540 | Running loss: 1.15011\n",
      "Epoch: 1 | Iteration: 380 | Classification loss: 0.40459 | Regression loss: 0.83925 | Running loss: 1.15024\n",
      "Epoch: 1 | Iteration: 381 | Classification loss: 0.43477 | Regression loss: 0.77167 | Running loss: 1.14989\n",
      "Epoch: 1 | Iteration: 382 | Classification loss: 0.42387 | Regression loss: 0.86625 | Running loss: 1.14969\n",
      "Epoch: 1 | Iteration: 383 | Classification loss: 0.45190 | Regression loss: 0.88803 | Running loss: 1.14987\n",
      "Epoch: 1 | Iteration: 384 | Classification loss: 0.35348 | Regression loss: 0.80288 | Running loss: 1.14953\n",
      "Epoch: 1 | Iteration: 385 | Classification loss: 0.33885 | Regression loss: 0.72796 | Running loss: 1.14907\n",
      "Epoch: 1 | Iteration: 386 | Classification loss: 0.27807 | Regression loss: 0.54550 | Running loss: 1.14874\n",
      "Epoch: 1 | Iteration: 387 | Classification loss: 0.39747 | Regression loss: 0.78524 | Running loss: 1.14895\n",
      "Epoch: 1 | Iteration: 388 | Classification loss: 0.34099 | Regression loss: 0.78261 | Running loss: 1.14886\n",
      "Epoch: 1 | Iteration: 389 | Classification loss: 0.30308 | Regression loss: 0.65681 | Running loss: 1.14862\n",
      "Epoch: 1 | Iteration: 390 | Classification loss: 0.30560 | Regression loss: 0.67286 | Running loss: 1.14838\n",
      "Epoch: 1 | Iteration: 391 | Classification loss: 0.41868 | Regression loss: 0.67835 | Running loss: 1.14783\n",
      "Epoch: 1 | Iteration: 392 | Classification loss: 0.30155 | Regression loss: 0.72864 | Running loss: 1.14764\n",
      "Epoch: 1 | Iteration: 393 | Classification loss: 0.48306 | Regression loss: 0.81937 | Running loss: 1.14822\n",
      "Epoch: 1 | Iteration: 394 | Classification loss: 0.34037 | Regression loss: 0.68284 | Running loss: 1.14804\n",
      "Epoch: 1 | Iteration: 395 | Classification loss: 0.38791 | Regression loss: 0.73660 | Running loss: 1.14779\n",
      "Epoch: 1 | Iteration: 396 | Classification loss: 0.40495 | Regression loss: 0.83909 | Running loss: 1.14762\n",
      "Epoch: 1 | Iteration: 397 | Classification loss: 0.36029 | Regression loss: 0.71708 | Running loss: 1.14725\n",
      "Epoch: 1 | Iteration: 398 | Classification loss: 0.56520 | Regression loss: 0.66415 | Running loss: 1.14726\n",
      "Epoch: 1 | Iteration: 399 | Classification loss: 0.26856 | Regression loss: 0.53264 | Running loss: 1.14647\n",
      "Epoch: 1 | Iteration: 400 | Classification loss: 0.29389 | Regression loss: 0.62557 | Running loss: 1.14612\n",
      "Epoch: 1 | Iteration: 401 | Classification loss: 0.25315 | Regression loss: 0.65822 | Running loss: 1.14520\n",
      "Epoch: 1 | Iteration: 402 | Classification loss: 0.40071 | Regression loss: 0.85404 | Running loss: 1.14524\n",
      "Epoch: 1 | Iteration: 403 | Classification loss: 0.33445 | Regression loss: 0.74219 | Running loss: 1.14505\n",
      "Epoch: 1 | Iteration: 404 | Classification loss: 0.22562 | Regression loss: 0.63090 | Running loss: 1.14392\n",
      "Epoch: 1 | Iteration: 405 | Classification loss: 0.36745 | Regression loss: 0.77665 | Running loss: 1.14347\n",
      "Epoch: 1 | Iteration: 406 | Classification loss: 0.34770 | Regression loss: 0.74834 | Running loss: 1.14314\n",
      "Epoch: 1 | Iteration: 407 | Classification loss: 0.39796 | Regression loss: 0.81164 | Running loss: 1.14367\n",
      "Epoch: 1 | Iteration: 408 | Classification loss: 0.36484 | Regression loss: 0.68891 | Running loss: 1.14342\n",
      "Epoch: 1 | Iteration: 409 | Classification loss: 0.34103 | Regression loss: 0.59531 | Running loss: 1.14278\n",
      "Epoch: 1 | Iteration: 410 | Classification loss: 0.42521 | Regression loss: 0.77409 | Running loss: 1.14251\n",
      "Epoch: 1 | Iteration: 411 | Classification loss: 0.34719 | Regression loss: 0.62567 | Running loss: 1.14178\n",
      "Epoch: 1 | Iteration: 412 | Classification loss: 0.34374 | Regression loss: 0.84992 | Running loss: 1.14201\n",
      "Epoch: 1 | Iteration: 413 | Classification loss: 0.30015 | Regression loss: 0.71276 | Running loss: 1.14184\n",
      "Epoch: 1 | Iteration: 414 | Classification loss: 0.38652 | Regression loss: 0.77970 | Running loss: 1.14173\n",
      "Epoch: 1 | Iteration: 415 | Classification loss: 0.37242 | Regression loss: 0.74789 | Running loss: 1.14162\n",
      "Epoch: 1 | Iteration: 416 | Classification loss: 0.30911 | Regression loss: 0.74868 | Running loss: 1.14139\n",
      "Epoch: 1 | Iteration: 417 | Classification loss: 0.38624 | Regression loss: 0.82857 | Running loss: 1.14150\n",
      "Epoch: 1 | Iteration: 418 | Classification loss: 0.31684 | Regression loss: 0.75518 | Running loss: 1.14092\n",
      "Epoch: 1 | Iteration: 419 | Classification loss: 0.34682 | Regression loss: 0.77029 | Running loss: 1.14062\n",
      "Epoch: 1 | Iteration: 420 | Classification loss: 0.34859 | Regression loss: 0.73455 | Running loss: 1.14033\n",
      "Epoch: 1 | Iteration: 421 | Classification loss: 0.37014 | Regression loss: 0.70912 | Running loss: 1.14019\n",
      "Epoch: 1 | Iteration: 422 | Classification loss: 0.39485 | Regression loss: 0.76706 | Running loss: 1.14013\n",
      "Epoch: 1 | Iteration: 423 | Classification loss: 0.43549 | Regression loss: 0.81026 | Running loss: 1.14047\n",
      "Epoch: 1 | Iteration: 424 | Classification loss: 0.20843 | Regression loss: 0.57149 | Running loss: 1.13976\n",
      "Epoch: 1 | Iteration: 425 | Classification loss: 0.33941 | Regression loss: 0.79727 | Running loss: 1.13971\n",
      "Epoch: 1 | Iteration: 426 | Classification loss: 0.28112 | Regression loss: 0.69909 | Running loss: 1.13973\n",
      "Epoch: 1 | Iteration: 427 | Classification loss: 0.29269 | Regression loss: 0.68640 | Running loss: 1.13954\n",
      "Epoch: 1 | Iteration: 428 | Classification loss: 0.21068 | Regression loss: 0.47738 | Running loss: 1.13874\n",
      "Epoch: 1 | Iteration: 429 | Classification loss: 0.38058 | Regression loss: 0.68016 | Running loss: 1.13853\n",
      "Epoch: 1 | Iteration: 430 | Classification loss: 0.55301 | Regression loss: 0.78836 | Running loss: 1.13818\n",
      "Epoch: 1 | Iteration: 431 | Classification loss: 0.40297 | Regression loss: 0.85215 | Running loss: 1.13827\n",
      "Epoch: 1 | Iteration: 432 | Classification loss: 0.35244 | Regression loss: 0.78472 | Running loss: 1.13794\n",
      "Epoch: 1 | Iteration: 433 | Classification loss: 0.31499 | Regression loss: 0.70252 | Running loss: 1.13761\n",
      "Epoch: 1 | Iteration: 434 | Classification loss: 0.48358 | Regression loss: 0.86414 | Running loss: 1.13780\n",
      "Epoch: 1 | Iteration: 435 | Classification loss: 0.31229 | Regression loss: 0.60718 | Running loss: 1.13724\n",
      "Epoch: 1 | Iteration: 436 | Classification loss: 0.35490 | Regression loss: 0.84542 | Running loss: 1.13729\n",
      "Epoch: 1 | Iteration: 437 | Classification loss: 0.49545 | Regression loss: 0.89159 | Running loss: 1.13787\n",
      "Epoch: 1 | Iteration: 438 | Classification loss: 0.35540 | Regression loss: 0.70402 | Running loss: 1.13727\n",
      "Epoch: 1 | Iteration: 439 | Classification loss: 0.38326 | Regression loss: 0.79981 | Running loss: 1.13733\n",
      "Epoch: 1 | Iteration: 440 | Classification loss: 0.36438 | Regression loss: 0.77976 | Running loss: 1.13750\n",
      "Epoch: 1 | Iteration: 441 | Classification loss: 0.40892 | Regression loss: 0.56046 | Running loss: 1.13665\n",
      "Epoch: 1 | Iteration: 442 | Classification loss: 0.30438 | Regression loss: 0.74995 | Running loss: 1.13635\n",
      "Epoch: 1 | Iteration: 443 | Classification loss: 0.42034 | Regression loss: 0.76538 | Running loss: 1.13625\n",
      "Epoch: 1 | Iteration: 444 | Classification loss: 0.42313 | Regression loss: 0.83774 | Running loss: 1.13635\n",
      "Epoch: 1 | Iteration: 445 | Classification loss: 0.34877 | Regression loss: 0.84156 | Running loss: 1.13623\n",
      "Epoch: 1 | Iteration: 446 | Classification loss: 0.32478 | Regression loss: 0.72144 | Running loss: 1.13567\n",
      "Epoch: 1 | Iteration: 447 | Classification loss: 0.27300 | Regression loss: 0.70189 | Running loss: 1.13530\n",
      "Epoch: 1 | Iteration: 448 | Classification loss: 0.32877 | Regression loss: 0.72552 | Running loss: 1.13466\n",
      "Epoch: 1 | Iteration: 449 | Classification loss: 0.34568 | Regression loss: 0.66467 | Running loss: 1.13431\n",
      "Epoch: 1 | Iteration: 450 | Classification loss: 0.39117 | Regression loss: 0.74295 | Running loss: 1.13402\n",
      "Epoch: 1 | Iteration: 451 | Classification loss: 0.37863 | Regression loss: 0.67734 | Running loss: 1.13420\n",
      "Epoch: 1 | Iteration: 452 | Classification loss: 0.43547 | Regression loss: 0.76405 | Running loss: 1.13394\n",
      "Epoch: 1 | Iteration: 453 | Classification loss: 0.44733 | Regression loss: 0.85769 | Running loss: 1.13399\n",
      "Epoch: 1 | Iteration: 454 | Classification loss: 0.41345 | Regression loss: 0.71434 | Running loss: 1.13383\n",
      "Epoch: 1 | Iteration: 455 | Classification loss: 0.42652 | Regression loss: 0.70946 | Running loss: 1.13362\n",
      "Epoch: 1 | Iteration: 456 | Classification loss: 0.29508 | Regression loss: 0.58367 | Running loss: 1.13280\n",
      "Epoch: 1 | Iteration: 457 | Classification loss: 0.36075 | Regression loss: 0.73254 | Running loss: 1.13282\n",
      "Epoch: 1 | Iteration: 458 | Classification loss: 0.41287 | Regression loss: 0.81379 | Running loss: 1.13299\n",
      "Epoch: 1 | Iteration: 459 | Classification loss: 0.35590 | Regression loss: 0.61923 | Running loss: 1.13262\n",
      "Epoch: 1 | Iteration: 460 | Classification loss: 0.37325 | Regression loss: 0.80798 | Running loss: 1.13262\n",
      "Epoch: 1 | Iteration: 461 | Classification loss: 0.35112 | Regression loss: 0.75861 | Running loss: 1.13257\n",
      "Epoch: 1 | Iteration: 462 | Classification loss: 0.51296 | Regression loss: 0.64706 | Running loss: 1.13280\n",
      "Epoch: 1 | Iteration: 463 | Classification loss: 0.25197 | Regression loss: 0.69400 | Running loss: 1.13189\n",
      "Epoch: 1 | Iteration: 464 | Classification loss: 0.39013 | Regression loss: 0.73745 | Running loss: 1.13164\n",
      "Epoch: 1 | Iteration: 465 | Classification loss: 0.34056 | Regression loss: 0.68777 | Running loss: 1.13145\n",
      "Epoch: 1 | Iteration: 466 | Classification loss: 0.40379 | Regression loss: 0.79786 | Running loss: 1.13214\n",
      "Epoch: 1 | Iteration: 467 | Classification loss: 0.36913 | Regression loss: 0.80550 | Running loss: 1.13230\n",
      "Epoch: 1 | Iteration: 468 | Classification loss: 0.32913 | Regression loss: 0.73341 | Running loss: 1.13207\n",
      "Epoch: 1 | Iteration: 469 | Classification loss: 0.39698 | Regression loss: 0.86484 | Running loss: 1.13148\n",
      "Epoch: 1 | Iteration: 470 | Classification loss: 0.47467 | Regression loss: 0.87958 | Running loss: 1.13167\n",
      "Epoch: 1 | Iteration: 471 | Classification loss: 0.69138 | Regression loss: 0.61947 | Running loss: 1.13179\n",
      "Epoch: 1 | Iteration: 472 | Classification loss: 0.30602 | Regression loss: 0.61252 | Running loss: 1.13130\n",
      "Epoch: 1 | Iteration: 473 | Classification loss: 0.43168 | Regression loss: 0.84790 | Running loss: 1.13145\n",
      "Epoch: 1 | Iteration: 474 | Classification loss: 0.36048 | Regression loss: 0.72788 | Running loss: 1.13106\n",
      "Epoch: 1 | Iteration: 475 | Classification loss: 0.29332 | Regression loss: 0.57223 | Running loss: 1.13084\n",
      "Epoch: 1 | Iteration: 476 | Classification loss: 0.36343 | Regression loss: 0.67474 | Running loss: 1.13078\n",
      "Epoch: 1 | Iteration: 477 | Classification loss: 0.27523 | Regression loss: 0.69879 | Running loss: 1.13037\n",
      "Epoch: 1 | Iteration: 478 | Classification loss: 0.42011 | Regression loss: 0.81395 | Running loss: 1.13051\n",
      "Epoch: 1 | Iteration: 479 | Classification loss: 0.39199 | Regression loss: 0.81075 | Running loss: 1.13077\n",
      "Epoch: 1 | Iteration: 480 | Classification loss: 0.26867 | Regression loss: 0.57005 | Running loss: 1.12985\n",
      "Epoch: 1 | Iteration: 481 | Classification loss: 0.50963 | Regression loss: 0.77660 | Running loss: 1.13012\n",
      "Epoch: 1 | Iteration: 482 | Classification loss: 0.40040 | Regression loss: 0.78062 | Running loss: 1.13006\n",
      "Epoch: 1 | Iteration: 483 | Classification loss: 0.38473 | Regression loss: 0.69203 | Running loss: 1.13013\n",
      "Epoch: 1 | Iteration: 484 | Classification loss: 0.33572 | Regression loss: 0.77530 | Running loss: 1.13020\n",
      "Epoch: 1 | Iteration: 485 | Classification loss: 0.33658 | Regression loss: 0.74343 | Running loss: 1.12988\n",
      "Epoch: 1 | Iteration: 486 | Classification loss: 0.36004 | Regression loss: 0.72330 | Running loss: 1.12941\n",
      "Epoch: 1 | Iteration: 487 | Classification loss: 0.36544 | Regression loss: 0.79604 | Running loss: 1.12929\n",
      "Epoch: 1 | Iteration: 488 | Classification loss: 0.32760 | Regression loss: 0.78028 | Running loss: 1.12879\n",
      "Epoch: 1 | Iteration: 489 | Classification loss: 0.43909 | Regression loss: 0.74685 | Running loss: 1.12880\n",
      "Epoch: 1 | Iteration: 490 | Classification loss: 0.36640 | Regression loss: 0.74797 | Running loss: 1.12847\n",
      "Epoch: 1 | Iteration: 491 | Classification loss: 0.36501 | Regression loss: 0.74955 | Running loss: 1.12837\n",
      "Epoch: 1 | Iteration: 492 | Classification loss: 0.23060 | Regression loss: 0.54812 | Running loss: 1.12728\n",
      "Epoch: 1 | Iteration: 493 | Classification loss: 0.38413 | Regression loss: 0.68177 | Running loss: 1.12724\n",
      "Epoch: 1 | Iteration: 494 | Classification loss: 0.33344 | Regression loss: 0.73018 | Running loss: 1.12627\n",
      "Epoch: 1 | Iteration: 495 | Classification loss: 0.42333 | Regression loss: 0.83359 | Running loss: 1.12636\n",
      "Epoch: 1 | Iteration: 496 | Classification loss: 0.34300 | Regression loss: 0.75930 | Running loss: 1.12607\n",
      "Epoch: 1 | Iteration: 497 | Classification loss: 0.34619 | Regression loss: 0.67785 | Running loss: 1.12626\n",
      "Epoch: 1 | Iteration: 498 | Classification loss: 0.28308 | Regression loss: 0.72627 | Running loss: 1.12574\n",
      "Epoch: 1 | Iteration: 499 | Classification loss: 0.80212 | Regression loss: 0.55747 | Running loss: 1.12603\n",
      "Epoch: 1 | Iteration: 500 | Classification loss: 0.41965 | Regression loss: 0.93448 | Running loss: 1.12599\n",
      "Epoch: 1 | Iteration: 501 | Classification loss: 0.30943 | Regression loss: 0.51912 | Running loss: 1.12526\n",
      "Epoch: 1 | Iteration: 502 | Classification loss: 0.50902 | Regression loss: 0.90549 | Running loss: 1.12589\n",
      "Epoch: 1 | Iteration: 503 | Classification loss: 0.35093 | Regression loss: 0.80240 | Running loss: 1.12584\n",
      "Epoch: 1 | Iteration: 504 | Classification loss: 0.29213 | Regression loss: 0.74866 | Running loss: 1.12567\n",
      "Epoch: 1 | Iteration: 505 | Classification loss: 0.32648 | Regression loss: 0.70572 | Running loss: 1.12584\n",
      "Epoch: 1 | Iteration: 506 | Classification loss: 0.27775 | Regression loss: 0.52589 | Running loss: 1.12495\n",
      "Epoch: 1 | Iteration: 507 | Classification loss: 0.44353 | Regression loss: 0.76867 | Running loss: 1.12530\n",
      "Epoch: 1 | Iteration: 508 | Classification loss: 0.33629 | Regression loss: 0.74986 | Running loss: 1.12512\n",
      "Epoch: 1 | Iteration: 509 | Classification loss: 0.29690 | Regression loss: 0.69704 | Running loss: 1.12480\n",
      "Epoch: 1 | Iteration: 510 | Classification loss: 0.31393 | Regression loss: 0.62933 | Running loss: 1.12408\n",
      "Epoch: 1 | Iteration: 511 | Classification loss: 0.36531 | Regression loss: 0.74098 | Running loss: 1.12414\n",
      "Epoch: 1 | Iteration: 512 | Classification loss: 0.37738 | Regression loss: 0.79270 | Running loss: 1.12384\n",
      "Epoch: 1 | Iteration: 513 | Classification loss: 0.31036 | Regression loss: 0.74279 | Running loss: 1.12375\n",
      "Epoch: 1 | Iteration: 514 | Classification loss: 0.46558 | Regression loss: 0.80525 | Running loss: 1.12404\n",
      "Epoch: 1 | Iteration: 515 | Classification loss: 0.36964 | Regression loss: 0.78750 | Running loss: 1.12393\n",
      "Epoch: 1 | Iteration: 516 | Classification loss: 0.40352 | Regression loss: 0.73705 | Running loss: 1.12372\n",
      "Epoch: 1 | Iteration: 517 | Classification loss: 0.48866 | Regression loss: 0.88508 | Running loss: 1.12448\n",
      "Epoch: 1 | Iteration: 518 | Classification loss: 0.44301 | Regression loss: 0.86961 | Running loss: 1.12450\n",
      "Epoch: 1 | Iteration: 519 | Classification loss: 0.32124 | Regression loss: 0.73687 | Running loss: 1.12421\n",
      "Epoch: 1 | Iteration: 520 | Classification loss: 0.45053 | Regression loss: 0.78310 | Running loss: 1.12414\n",
      "Epoch: 1 | Iteration: 521 | Classification loss: 0.37954 | Regression loss: 0.82108 | Running loss: 1.12374\n",
      "Epoch: 1 | Iteration: 522 | Classification loss: 0.35546 | Regression loss: 0.70443 | Running loss: 1.12343\n",
      "Epoch: 1 | Iteration: 523 | Classification loss: 0.34258 | Regression loss: 0.78509 | Running loss: 1.12352\n",
      "Epoch: 1 | Iteration: 524 | Classification loss: 0.32081 | Regression loss: 0.68949 | Running loss: 1.12282\n",
      "Epoch: 1 | Iteration: 525 | Classification loss: 0.23433 | Regression loss: 0.50826 | Running loss: 1.12195\n",
      "Epoch: 1 | Iteration: 526 | Classification loss: 0.34052 | Regression loss: 0.75125 | Running loss: 1.12164\n",
      "Epoch: 1 | Iteration: 527 | Classification loss: 0.29052 | Regression loss: 0.67411 | Running loss: 1.12124\n",
      "Epoch: 1 | Iteration: 528 | Classification loss: 0.32725 | Regression loss: 0.62087 | Running loss: 1.12129\n",
      "Epoch: 1 | Iteration: 529 | Classification loss: 0.31702 | Regression loss: 0.71862 | Running loss: 1.12098\n",
      "Epoch: 1 | Iteration: 530 | Classification loss: 0.36410 | Regression loss: 0.73708 | Running loss: 1.12077\n",
      "Epoch: 1 | Iteration: 531 | Classification loss: 0.37357 | Regression loss: 0.66996 | Running loss: 1.12059\n",
      "Epoch: 1 | Iteration: 532 | Classification loss: 0.28332 | Regression loss: 0.64734 | Running loss: 1.12032\n",
      "Epoch: 1 | Iteration: 533 | Classification loss: 0.39249 | Regression loss: 0.67136 | Running loss: 1.12013\n",
      "Epoch: 1 | Iteration: 534 | Classification loss: 0.30486 | Regression loss: 0.62329 | Running loss: 1.12027\n",
      "Epoch: 1 | Iteration: 535 | Classification loss: 0.60739 | Regression loss: 0.81594 | Running loss: 1.12076\n",
      "Epoch: 1 | Iteration: 536 | Classification loss: 0.34593 | Regression loss: 0.75287 | Running loss: 1.12081\n",
      "Epoch: 1 | Iteration: 537 | Classification loss: 0.34435 | Regression loss: 0.75846 | Running loss: 1.12109\n",
      "Epoch: 1 | Iteration: 538 | Classification loss: 0.42198 | Regression loss: 0.82622 | Running loss: 1.12166\n",
      "Epoch: 1 | Iteration: 539 | Classification loss: 0.33097 | Regression loss: 0.76356 | Running loss: 1.12154\n",
      "Epoch: 1 | Iteration: 540 | Classification loss: 0.41025 | Regression loss: 0.78616 | Running loss: 1.12190\n",
      "Epoch: 1 | Iteration: 541 | Classification loss: 0.46812 | Regression loss: 0.76405 | Running loss: 1.12242\n",
      "Epoch: 1 | Iteration: 542 | Classification loss: 0.53320 | Regression loss: 0.84589 | Running loss: 1.12265\n",
      "Epoch: 1 | Iteration: 543 | Classification loss: 0.33479 | Regression loss: 0.74592 | Running loss: 1.12263\n",
      "Epoch: 1 | Iteration: 544 | Classification loss: 0.36307 | Regression loss: 0.67510 | Running loss: 1.12247\n",
      "Epoch: 1 | Iteration: 545 | Classification loss: 0.42691 | Regression loss: 0.80419 | Running loss: 1.12312\n",
      "Epoch: 1 | Iteration: 546 | Classification loss: 0.37696 | Regression loss: 0.71797 | Running loss: 1.12280\n",
      "Epoch: 1 | Iteration: 547 | Classification loss: 0.38633 | Regression loss: 0.75074 | Running loss: 1.12254\n",
      "Epoch: 1 | Iteration: 548 | Classification loss: 0.35469 | Regression loss: 0.64818 | Running loss: 1.12248\n",
      "Epoch: 1 | Iteration: 549 | Classification loss: 0.31629 | Regression loss: 0.78092 | Running loss: 1.12216\n",
      "Epoch: 1 | Iteration: 550 | Classification loss: 0.40236 | Regression loss: 0.75407 | Running loss: 1.12254\n",
      "Epoch: 1 | Iteration: 551 | Classification loss: 0.36116 | Regression loss: 0.73873 | Running loss: 1.12216\n",
      "Epoch: 1 | Iteration: 552 | Classification loss: 0.34061 | Regression loss: 0.70171 | Running loss: 1.12169\n",
      "Epoch: 1 | Iteration: 553 | Classification loss: 0.24882 | Regression loss: 0.62500 | Running loss: 1.12117\n",
      "Epoch: 1 | Iteration: 554 | Classification loss: 0.31170 | Regression loss: 0.58687 | Running loss: 1.12050\n",
      "Epoch: 1 | Iteration: 555 | Classification loss: 0.41504 | Regression loss: 0.75383 | Running loss: 1.12056\n",
      "Epoch: 1 | Iteration: 556 | Classification loss: 0.32721 | Regression loss: 0.64018 | Running loss: 1.11990\n",
      "Epoch: 1 | Iteration: 557 | Classification loss: 0.28259 | Regression loss: 0.68177 | Running loss: 1.11974\n",
      "Epoch: 1 | Iteration: 558 | Classification loss: 0.27422 | Regression loss: 0.60373 | Running loss: 1.11881\n",
      "Epoch: 1 | Iteration: 559 | Classification loss: 0.33014 | Regression loss: 0.76219 | Running loss: 1.11849\n",
      "Epoch: 1 | Iteration: 560 | Classification loss: 0.31787 | Regression loss: 0.67969 | Running loss: 1.11843\n",
      "Epoch: 1 | Iteration: 561 | Classification loss: 0.44832 | Regression loss: 0.89794 | Running loss: 1.11916\n",
      "Epoch: 1 | Iteration: 562 | Classification loss: 0.42829 | Regression loss: 0.77715 | Running loss: 1.11905\n",
      "Epoch: 1 | Iteration: 563 | Classification loss: 0.41624 | Regression loss: 0.84839 | Running loss: 1.11864\n",
      "Epoch: 1 | Iteration: 564 | Classification loss: 0.22697 | Regression loss: 0.62028 | Running loss: 1.11818\n",
      "Epoch: 1 | Iteration: 565 | Classification loss: 0.45847 | Regression loss: 0.79562 | Running loss: 1.11796\n",
      "Epoch: 1 | Iteration: 566 | Classification loss: 0.36606 | Regression loss: 0.73805 | Running loss: 1.11771\n",
      "Epoch: 1 | Iteration: 567 | Classification loss: 0.44907 | Regression loss: 0.91081 | Running loss: 1.11826\n",
      "Epoch: 1 | Iteration: 568 | Classification loss: 0.29275 | Regression loss: 0.72355 | Running loss: 1.11799\n",
      "Epoch: 1 | Iteration: 569 | Classification loss: 0.39479 | Regression loss: 0.82472 | Running loss: 1.11802\n",
      "Epoch: 1 | Iteration: 570 | Classification loss: 0.33059 | Regression loss: 0.84964 | Running loss: 1.11784\n",
      "Epoch: 1 | Iteration: 571 | Classification loss: 0.28899 | Regression loss: 0.67978 | Running loss: 1.11700\n",
      "Epoch: 1 | Iteration: 572 | Classification loss: 0.42522 | Regression loss: 0.82594 | Running loss: 1.11708\n",
      "Epoch: 1 | Iteration: 573 | Classification loss: 0.28573 | Regression loss: 0.65681 | Running loss: 1.11647\n",
      "Epoch: 1 | Iteration: 574 | Classification loss: 0.23311 | Regression loss: 0.64602 | Running loss: 1.11622\n",
      "Epoch: 1 | Iteration: 575 | Classification loss: 0.42627 | Regression loss: 0.82351 | Running loss: 1.11643\n",
      "Epoch: 1 | Iteration: 576 | Classification loss: 0.36977 | Regression loss: 0.77720 | Running loss: 1.11669\n",
      "Epoch: 1 | Iteration: 577 | Classification loss: 0.35864 | Regression loss: 0.59834 | Running loss: 1.11666\n",
      "Epoch: 1 | Iteration: 578 | Classification loss: 0.46932 | Regression loss: 0.87274 | Running loss: 1.11738\n",
      "Epoch: 1 | Iteration: 579 | Classification loss: 0.32038 | Regression loss: 0.64528 | Running loss: 1.11723\n",
      "Epoch: 1 | Iteration: 580 | Classification loss: 0.33823 | Regression loss: 0.73248 | Running loss: 1.11710\n",
      "Epoch: 1 | Iteration: 581 | Classification loss: 0.42703 | Regression loss: 0.81574 | Running loss: 1.11716\n",
      "Epoch: 1 | Iteration: 582 | Classification loss: 0.33228 | Regression loss: 0.65404 | Running loss: 1.11709\n",
      "Epoch: 1 | Iteration: 583 | Classification loss: 0.32907 | Regression loss: 0.80990 | Running loss: 1.11723\n",
      "Epoch: 1 | Iteration: 584 | Classification loss: 0.25682 | Regression loss: 0.64338 | Running loss: 1.11699\n",
      "Epoch: 1 | Iteration: 585 | Classification loss: 0.44403 | Regression loss: 0.74847 | Running loss: 1.11707\n",
      "Epoch: 1 | Iteration: 586 | Classification loss: 0.32441 | Regression loss: 0.85143 | Running loss: 1.11712\n",
      "Epoch: 1 | Iteration: 587 | Classification loss: 0.30951 | Regression loss: 0.83917 | Running loss: 1.11688\n",
      "Epoch: 1 | Iteration: 588 | Classification loss: 0.37516 | Regression loss: 0.74319 | Running loss: 1.11632\n",
      "Epoch: 1 | Iteration: 589 | Classification loss: 0.27106 | Regression loss: 0.61789 | Running loss: 1.11600\n",
      "Epoch: 1 | Iteration: 590 | Classification loss: 0.33465 | Regression loss: 0.57328 | Running loss: 1.11523\n",
      "Epoch: 1 | Iteration: 591 | Classification loss: 0.33438 | Regression loss: 0.70488 | Running loss: 1.11475\n",
      "Epoch: 1 | Iteration: 592 | Classification loss: 0.26999 | Regression loss: 0.59320 | Running loss: 1.11434\n",
      "Epoch: 1 | Iteration: 593 | Classification loss: 0.28764 | Regression loss: 0.62896 | Running loss: 1.11358\n",
      "Epoch: 1 | Iteration: 594 | Classification loss: 0.43157 | Regression loss: 0.73501 | Running loss: 1.11368\n",
      "Epoch: 1 | Iteration: 595 | Classification loss: 0.41729 | Regression loss: 0.75790 | Running loss: 1.11319\n",
      "Epoch: 1 | Iteration: 596 | Classification loss: 0.39316 | Regression loss: 0.80206 | Running loss: 1.11333\n",
      "Epoch: 1 | Iteration: 597 | Classification loss: 0.33076 | Regression loss: 0.76196 | Running loss: 1.11359\n",
      "Epoch: 1 | Iteration: 598 | Classification loss: 0.34976 | Regression loss: 0.72402 | Running loss: 1.11358\n",
      "Epoch: 1 | Iteration: 599 | Classification loss: 0.27998 | Regression loss: 0.61567 | Running loss: 1.11312\n",
      "Epoch: 1 | Iteration: 600 | Classification loss: 0.28731 | Regression loss: 0.72160 | Running loss: 1.11306\n",
      "Epoch: 1 | Iteration: 601 | Classification loss: 0.31309 | Regression loss: 0.64239 | Running loss: 1.11283\n",
      "Epoch: 1 | Iteration: 602 | Classification loss: 0.34444 | Regression loss: 0.68472 | Running loss: 1.11254\n",
      "Epoch: 1 | Iteration: 603 | Classification loss: 0.32902 | Regression loss: 0.60078 | Running loss: 1.11187\n",
      "Epoch: 1 | Iteration: 604 | Classification loss: 0.37668 | Regression loss: 0.78932 | Running loss: 1.11143\n",
      "Epoch: 1 | Iteration: 605 | Classification loss: 0.33567 | Regression loss: 0.67068 | Running loss: 1.11119\n",
      "Epoch: 1 | Iteration: 606 | Classification loss: 0.39742 | Regression loss: 0.76932 | Running loss: 1.11149\n",
      "Epoch: 1 | Iteration: 607 | Classification loss: 0.46476 | Regression loss: 0.60373 | Running loss: 1.11194\n",
      "Epoch: 1 | Iteration: 608 | Classification loss: 0.50669 | Regression loss: 0.51508 | Running loss: 1.11177\n",
      "Epoch: 1 | Iteration: 609 | Classification loss: 0.37762 | Regression loss: 0.79087 | Running loss: 1.11168\n",
      "Epoch: 1 | Iteration: 610 | Classification loss: 0.41688 | Regression loss: 0.86239 | Running loss: 1.11185\n",
      "Epoch: 1 | Iteration: 611 | Classification loss: 0.36007 | Regression loss: 0.62732 | Running loss: 1.11144\n",
      "Epoch: 1 | Iteration: 612 | Classification loss: 0.35866 | Regression loss: 0.71580 | Running loss: 1.11152\n",
      "Epoch: 1 | Iteration: 613 | Classification loss: 0.38772 | Regression loss: 0.72235 | Running loss: 1.11121\n",
      "Epoch: 1 | Iteration: 614 | Classification loss: 0.36293 | Regression loss: 0.49277 | Running loss: 1.11084\n",
      "Epoch: 1 | Iteration: 615 | Classification loss: 0.34633 | Regression loss: 0.69999 | Running loss: 1.11091\n",
      "Epoch: 1 | Iteration: 616 | Classification loss: 0.34244 | Regression loss: 0.80863 | Running loss: 1.11075\n",
      "Epoch: 1 | Iteration: 617 | Classification loss: 0.45998 | Regression loss: 0.85735 | Running loss: 1.11063\n",
      "Epoch: 1 | Iteration: 618 | Classification loss: 0.44723 | Regression loss: 0.80359 | Running loss: 1.11126\n",
      "Epoch: 1 | Iteration: 619 | Classification loss: 0.40884 | Regression loss: 0.81629 | Running loss: 1.11099\n",
      "Epoch: 1 | Iteration: 620 | Classification loss: 0.26642 | Regression loss: 0.55998 | Running loss: 1.11053\n",
      "Epoch: 1 | Iteration: 621 | Classification loss: 0.34643 | Regression loss: 0.82353 | Running loss: 1.11048\n",
      "Epoch: 1 | Iteration: 622 | Classification loss: 0.40574 | Regression loss: 0.76461 | Running loss: 1.11081\n",
      "Epoch: 1 | Iteration: 623 | Classification loss: 0.46698 | Regression loss: 0.84585 | Running loss: 1.11117\n",
      "Epoch: 1 | Iteration: 624 | Classification loss: 0.44738 | Regression loss: 0.82233 | Running loss: 1.11127\n",
      "Epoch: 1 | Iteration: 625 | Classification loss: 0.42695 | Regression loss: 0.94005 | Running loss: 1.11204\n",
      "Epoch: 1 | Iteration: 626 | Classification loss: 0.23302 | Regression loss: 0.59735 | Running loss: 1.11133\n",
      "Epoch: 1 | Iteration: 627 | Classification loss: 0.25505 | Regression loss: 0.66939 | Running loss: 1.11077\n",
      "Epoch: 1 | Iteration: 628 | Classification loss: 0.42088 | Regression loss: 0.72383 | Running loss: 1.11074\n",
      "Epoch: 1 | Iteration: 629 | Classification loss: 0.21387 | Regression loss: 0.62460 | Running loss: 1.11029\n",
      "Epoch: 1 | Iteration: 630 | Classification loss: 0.24670 | Regression loss: 0.66734 | Running loss: 1.11029\n",
      "Epoch: 1 | Iteration: 631 | Classification loss: 0.40762 | Regression loss: 0.73006 | Running loss: 1.11091\n",
      "Epoch: 1 | Iteration: 632 | Classification loss: 0.19760 | Regression loss: 0.42988 | Running loss: 1.11006\n",
      "Epoch: 1 | Iteration: 633 | Classification loss: 0.27834 | Regression loss: 0.71893 | Running loss: 1.10988\n",
      "Epoch: 1 | Iteration: 634 | Classification loss: 0.43928 | Regression loss: 0.71339 | Running loss: 1.11031\n",
      "Epoch: 1 | Iteration: 635 | Classification loss: 0.39847 | Regression loss: 0.79262 | Running loss: 1.11093\n",
      "Epoch: 1 | Iteration: 636 | Classification loss: 0.32037 | Regression loss: 0.75282 | Running loss: 1.11114\n",
      "Epoch: 1 | Iteration: 637 | Classification loss: 0.37582 | Regression loss: 0.73015 | Running loss: 1.11103\n",
      "Epoch: 1 | Iteration: 638 | Classification loss: 0.34722 | Regression loss: 0.67728 | Running loss: 1.11100\n",
      "Epoch: 1 | Iteration: 639 | Classification loss: 0.19142 | Regression loss: 0.47015 | Running loss: 1.11006\n",
      "Epoch: 1 | Iteration: 640 | Classification loss: 0.35492 | Regression loss: 0.76146 | Running loss: 1.10988\n",
      "Epoch: 1 | Iteration: 641 | Classification loss: 0.24626 | Regression loss: 0.64627 | Running loss: 1.10926\n",
      "Epoch: 1 | Iteration: 642 | Classification loss: 0.50158 | Regression loss: 0.57835 | Running loss: 1.10929\n",
      "Epoch: 1 | Iteration: 643 | Classification loss: 0.43418 | Regression loss: 0.73348 | Running loss: 1.10913\n",
      "Epoch: 1 | Iteration: 644 | Classification loss: 0.37174 | Regression loss: 0.82883 | Running loss: 1.10960\n",
      "Epoch: 1 | Iteration: 645 | Classification loss: 0.24819 | Regression loss: 0.60651 | Running loss: 1.10909\n",
      "Epoch: 1 | Iteration: 646 | Classification loss: 0.37421 | Regression loss: 0.57298 | Running loss: 1.10899\n",
      "Epoch: 1 | Iteration: 647 | Classification loss: 0.25107 | Regression loss: 0.66473 | Running loss: 1.10850\n",
      "Epoch: 1 | Iteration: 648 | Classification loss: 0.34493 | Regression loss: 0.68341 | Running loss: 1.10777\n",
      "Epoch: 1 | Iteration: 649 | Classification loss: 0.38955 | Regression loss: 0.68935 | Running loss: 1.10834\n",
      "Epoch: 1 | Iteration: 650 | Classification loss: 0.43002 | Regression loss: 0.90388 | Running loss: 1.10812\n",
      "Epoch: 1 | Iteration: 651 | Classification loss: 0.30001 | Regression loss: 0.62005 | Running loss: 1.10774\n",
      "Epoch: 1 | Iteration: 652 | Classification loss: 0.33275 | Regression loss: 0.66592 | Running loss: 1.10737\n",
      "Epoch: 1 | Iteration: 653 | Classification loss: 0.41521 | Regression loss: 0.78177 | Running loss: 1.10744\n",
      "Epoch: 1 | Iteration: 654 | Classification loss: 0.54322 | Regression loss: 0.75999 | Running loss: 1.10778\n",
      "Epoch: 1 | Iteration: 655 | Classification loss: 0.40985 | Regression loss: 0.88976 | Running loss: 1.10779\n",
      "Epoch: 1 | Iteration: 656 | Classification loss: 0.32372 | Regression loss: 0.58535 | Running loss: 1.10765\n",
      "Epoch: 1 | Iteration: 657 | Classification loss: 0.33426 | Regression loss: 0.75577 | Running loss: 1.10756\n",
      "Epoch: 1 | Iteration: 658 | Classification loss: 0.33893 | Regression loss: 0.68639 | Running loss: 1.10715\n",
      "Epoch: 1 | Iteration: 659 | Classification loss: 0.33977 | Regression loss: 0.59793 | Running loss: 1.10732\n",
      "Epoch: 1 | Iteration: 660 | Classification loss: 0.33145 | Regression loss: 0.76347 | Running loss: 1.10710\n",
      "Epoch: 1 | Iteration: 661 | Classification loss: 0.37967 | Regression loss: 0.79761 | Running loss: 1.10706\n",
      "Epoch: 1 | Iteration: 662 | Classification loss: 0.32045 | Regression loss: 0.70692 | Running loss: 1.10698\n",
      "Epoch: 1 | Iteration: 663 | Classification loss: 0.47751 | Regression loss: 0.81192 | Running loss: 1.10717\n",
      "Epoch: 1 | Iteration: 664 | Classification loss: 0.41760 | Regression loss: 0.79248 | Running loss: 1.10760\n",
      "Epoch: 1 | Iteration: 665 | Classification loss: 0.28986 | Regression loss: 0.65571 | Running loss: 1.10763\n",
      "Epoch: 1 | Iteration: 666 | Classification loss: 0.27035 | Regression loss: 0.64519 | Running loss: 1.10745\n",
      "Epoch: 1 | Iteration: 667 | Classification loss: 0.26673 | Regression loss: 0.72042 | Running loss: 1.10736\n",
      "Epoch: 1 | Iteration: 668 | Classification loss: 0.39558 | Regression loss: 0.66823 | Running loss: 1.10765\n",
      "Epoch: 1 | Iteration: 669 | Classification loss: 0.23071 | Regression loss: 0.65587 | Running loss: 1.10716\n",
      "Epoch: 1 | Iteration: 670 | Classification loss: 0.39846 | Regression loss: 0.74377 | Running loss: 1.10713\n",
      "Epoch: 1 | Iteration: 671 | Classification loss: 0.28153 | Regression loss: 0.69015 | Running loss: 1.10661\n",
      "Epoch: 1 | Iteration: 672 | Classification loss: 0.32083 | Regression loss: 0.68749 | Running loss: 1.10641\n",
      "Epoch: 1 | Iteration: 673 | Classification loss: 0.31179 | Regression loss: 0.66579 | Running loss: 1.10610\n",
      "Epoch: 1 | Iteration: 674 | Classification loss: 0.46143 | Regression loss: 0.87686 | Running loss: 1.10689\n",
      "Epoch: 1 | Iteration: 675 | Classification loss: 0.38752 | Regression loss: 0.78473 | Running loss: 1.10676\n",
      "Epoch: 1 | Iteration: 676 | Classification loss: 0.33734 | Regression loss: 0.45494 | Running loss: 1.10603\n",
      "Epoch: 1 | Iteration: 677 | Classification loss: 0.35234 | Regression loss: 0.69265 | Running loss: 1.10613\n",
      "Epoch: 1 | Iteration: 678 | Classification loss: 0.30730 | Regression loss: 0.69801 | Running loss: 1.10589\n",
      "Epoch: 1 | Iteration: 679 | Classification loss: 0.40143 | Regression loss: 0.70471 | Running loss: 1.10559\n",
      "Epoch: 1 | Iteration: 680 | Classification loss: 0.37168 | Regression loss: 0.73030 | Running loss: 1.10531\n",
      "Epoch: 1 | Iteration: 681 | Classification loss: 0.37709 | Regression loss: 0.73273 | Running loss: 1.10590\n",
      "Epoch: 1 | Iteration: 682 | Classification loss: 0.28473 | Regression loss: 0.70274 | Running loss: 1.10594\n",
      "Epoch: 1 | Iteration: 683 | Classification loss: 0.25518 | Regression loss: 0.59237 | Running loss: 1.10553\n",
      "Epoch: 1 | Iteration: 684 | Classification loss: 0.27346 | Regression loss: 0.68710 | Running loss: 1.10519\n",
      "Epoch: 1 | Iteration: 685 | Classification loss: 0.27758 | Regression loss: 0.56253 | Running loss: 1.10444\n",
      "Epoch: 1 | Iteration: 686 | Classification loss: 0.31694 | Regression loss: 0.71931 | Running loss: 1.10428\n",
      "Epoch: 1 | Iteration: 687 | Classification loss: 0.30152 | Regression loss: 0.70088 | Running loss: 1.10436\n",
      "Epoch: 1 | Iteration: 688 | Classification loss: 0.35259 | Regression loss: 0.79593 | Running loss: 1.10449\n",
      "Epoch: 1 | Iteration: 689 | Classification loss: 0.31328 | Regression loss: 0.70177 | Running loss: 1.10433\n",
      "Epoch: 1 | Iteration: 690 | Classification loss: 0.32217 | Regression loss: 0.72165 | Running loss: 1.10373\n",
      "Epoch: 1 | Iteration: 691 | Classification loss: 0.36581 | Regression loss: 0.75806 | Running loss: 1.10429\n",
      "Epoch: 1 | Iteration: 692 | Classification loss: 0.35322 | Regression loss: 0.78048 | Running loss: 1.10418\n",
      "Epoch: 1 | Iteration: 693 | Classification loss: 0.42372 | Regression loss: 0.74377 | Running loss: 1.10386\n",
      "Epoch: 1 | Iteration: 694 | Classification loss: 0.58859 | Regression loss: 0.73374 | Running loss: 1.10448\n",
      "Epoch: 1 | Iteration: 695 | Classification loss: 0.49665 | Regression loss: 0.81305 | Running loss: 1.10450\n",
      "Epoch: 1 | Iteration: 696 | Classification loss: 0.44311 | Regression loss: 0.74194 | Running loss: 1.10452\n",
      "Epoch: 1 | Iteration: 697 | Classification loss: 0.36581 | Regression loss: 0.84007 | Running loss: 1.10453\n",
      "Epoch: 1 | Iteration: 698 | Classification loss: 0.30969 | Regression loss: 0.62692 | Running loss: 1.10439\n",
      "Epoch: 1 | Iteration: 699 | Classification loss: 0.26883 | Regression loss: 0.62728 | Running loss: 1.10377\n",
      "Epoch: 1 | Iteration: 700 | Classification loss: 0.28175 | Regression loss: 0.65560 | Running loss: 1.10319\n",
      "Epoch: 1 | Iteration: 701 | Classification loss: 0.41525 | Regression loss: 0.73942 | Running loss: 1.10313\n",
      "Epoch: 1 | Iteration: 702 | Classification loss: 0.42940 | Regression loss: 0.77908 | Running loss: 1.10346\n",
      "Epoch: 1 | Iteration: 703 | Classification loss: 0.35327 | Regression loss: 0.58875 | Running loss: 1.10296\n",
      "Epoch: 1 | Iteration: 704 | Classification loss: 0.46503 | Regression loss: 0.88628 | Running loss: 1.10316\n",
      "Epoch: 1 | Iteration: 705 | Classification loss: 0.42620 | Regression loss: 0.82539 | Running loss: 1.10367\n",
      "Epoch: 1 | Iteration: 706 | Classification loss: 0.31736 | Regression loss: 0.67705 | Running loss: 1.10395\n",
      "Epoch: 1 | Iteration: 707 | Classification loss: 0.26891 | Regression loss: 0.64604 | Running loss: 1.10352\n",
      "Epoch: 1 | Iteration: 708 | Classification loss: 0.44326 | Regression loss: 0.84889 | Running loss: 1.10376\n",
      "Epoch: 1 | Iteration: 709 | Classification loss: 0.32270 | Regression loss: 0.65134 | Running loss: 1.10396\n",
      "Epoch: 1 | Iteration: 710 | Classification loss: 0.22207 | Regression loss: 0.59172 | Running loss: 1.10296\n",
      "Epoch: 1 | Iteration: 711 | Classification loss: 0.33723 | Regression loss: 0.71118 | Running loss: 1.10264\n",
      "Epoch: 1 | Iteration: 712 | Classification loss: 0.25129 | Regression loss: 0.57698 | Running loss: 1.10208\n",
      "Epoch: 1 | Iteration: 713 | Classification loss: 0.29731 | Regression loss: 0.65590 | Running loss: 1.10169\n",
      "Epoch: 1 | Iteration: 714 | Classification loss: 0.39141 | Regression loss: 0.77861 | Running loss: 1.09919\n",
      "Epoch: 1 | Iteration: 715 | Classification loss: 0.33694 | Regression loss: 0.77108 | Running loss: 1.09927\n",
      "Epoch: 1 | Iteration: 716 | Classification loss: 0.32797 | Regression loss: 0.71027 | Running loss: 1.09891\n",
      "Epoch: 1 | Iteration: 717 | Classification loss: 0.37808 | Regression loss: 0.66720 | Running loss: 1.09896\n",
      "Epoch: 1 | Iteration: 718 | Classification loss: 0.41138 | Regression loss: 0.87139 | Running loss: 1.09950\n",
      "Epoch: 1 | Iteration: 719 | Classification loss: 0.33232 | Regression loss: 0.64844 | Running loss: 1.09934\n",
      "Epoch: 1 | Iteration: 720 | Classification loss: 0.56854 | Regression loss: 0.77065 | Running loss: 1.09985\n",
      "Epoch: 1 | Iteration: 721 | Classification loss: 0.32960 | Regression loss: 0.71246 | Running loss: 1.09960\n",
      "Epoch: 1 | Iteration: 722 | Classification loss: 0.29124 | Regression loss: 0.72189 | Running loss: 1.09942\n",
      "Epoch: 1 | Iteration: 723 | Classification loss: 0.41493 | Regression loss: 0.73054 | Running loss: 1.09930\n",
      "Epoch: 1 | Iteration: 724 | Classification loss: 0.46543 | Regression loss: 0.81755 | Running loss: 1.09950\n",
      "Epoch: 1 | Iteration: 725 | Classification loss: 0.39335 | Regression loss: 0.76118 | Running loss: 1.09937\n",
      "Epoch: 1 | Iteration: 726 | Classification loss: 0.46743 | Regression loss: 0.80267 | Running loss: 1.09939\n",
      "Epoch: 1 | Iteration: 727 | Classification loss: 0.35442 | Regression loss: 0.58172 | Running loss: 1.09911\n",
      "Epoch: 1 | Iteration: 728 | Classification loss: 0.44017 | Regression loss: 0.67563 | Running loss: 1.09902\n",
      "Epoch: 1 | Iteration: 729 | Classification loss: 0.34214 | Regression loss: 0.68750 | Running loss: 1.09920\n",
      "Epoch: 1 | Iteration: 730 | Classification loss: 0.38228 | Regression loss: 0.69042 | Running loss: 1.09913\n",
      "Epoch: 1 | Iteration: 731 | Classification loss: 0.30292 | Regression loss: 0.77181 | Running loss: 1.09902\n",
      "Epoch: 1 | Iteration: 732 | Classification loss: 0.32530 | Regression loss: 0.70228 | Running loss: 1.09905\n",
      "Epoch: 1 | Iteration: 733 | Classification loss: 0.37458 | Regression loss: 0.73062 | Running loss: 1.09930\n",
      "Epoch: 1 | Iteration: 734 | Classification loss: 0.36834 | Regression loss: 0.84417 | Running loss: 1.09934\n",
      "Epoch: 1 | Iteration: 735 | Classification loss: 0.25131 | Regression loss: 0.58044 | Running loss: 1.09862\n",
      "Epoch: 1 | Iteration: 736 | Classification loss: 0.32353 | Regression loss: 0.64480 | Running loss: 1.09889\n",
      "Epoch: 1 | Iteration: 737 | Classification loss: 0.33432 | Regression loss: 0.65037 | Running loss: 1.09807\n",
      "Epoch: 1 | Iteration: 738 | Classification loss: 0.23981 | Regression loss: 0.69708 | Running loss: 1.09828\n",
      "Epoch: 1 | Iteration: 739 | Classification loss: 0.34253 | Regression loss: 0.63657 | Running loss: 1.09759\n",
      "Epoch: 1 | Iteration: 740 | Classification loss: 0.30724 | Regression loss: 0.75635 | Running loss: 1.09746\n",
      "Epoch: 1 | Iteration: 741 | Classification loss: 0.36046 | Regression loss: 0.74311 | Running loss: 1.09772\n",
      "Epoch: 1 | Iteration: 742 | Classification loss: 0.33774 | Regression loss: 0.79653 | Running loss: 1.09769\n",
      "Epoch: 1 | Iteration: 743 | Classification loss: 0.49768 | Regression loss: 0.84307 | Running loss: 1.09824\n",
      "Epoch: 1 | Iteration: 744 | Classification loss: 0.44530 | Regression loss: 0.85418 | Running loss: 1.09832\n",
      "Epoch: 1 | Iteration: 745 | Classification loss: 0.31765 | Regression loss: 0.75946 | Running loss: 1.09817\n",
      "Epoch: 1 | Iteration: 746 | Classification loss: 0.39114 | Regression loss: 0.79178 | Running loss: 1.09848\n",
      "Epoch: 1 | Iteration: 747 | Classification loss: 0.44093 | Regression loss: 0.86288 | Running loss: 1.09923\n",
      "Epoch: 1 | Iteration: 748 | Classification loss: 0.47501 | Regression loss: 0.78724 | Running loss: 1.09937\n",
      "Epoch: 1 | Iteration: 749 | Classification loss: 0.38499 | Regression loss: 0.81399 | Running loss: 1.09830\n",
      "Epoch: 1 | Iteration: 750 | Classification loss: 0.33040 | Regression loss: 0.64423 | Running loss: 1.09796\n",
      "Epoch: 1 | Iteration: 751 | Classification loss: 0.27611 | Regression loss: 0.69322 | Running loss: 1.09749\n",
      "Epoch: 1 | Iteration: 752 | Classification loss: 0.49929 | Regression loss: 0.55639 | Running loss: 1.09716\n",
      "Epoch: 1 | Iteration: 753 | Classification loss: 0.29722 | Regression loss: 0.65894 | Running loss: 1.09685\n",
      "Epoch: 1 | Iteration: 754 | Classification loss: 0.30059 | Regression loss: 0.70736 | Running loss: 1.09621\n",
      "Epoch: 1 | Iteration: 755 | Classification loss: 0.40115 | Regression loss: 0.77309 | Running loss: 1.09652\n",
      "Epoch: 1 | Iteration: 756 | Classification loss: 0.32238 | Regression loss: 0.75745 | Running loss: 1.09633\n",
      "Epoch: 1 | Iteration: 757 | Classification loss: 0.18503 | Regression loss: 0.50061 | Running loss: 1.09532\n",
      "Epoch: 1 | Iteration: 758 | Classification loss: 0.33357 | Regression loss: 0.77895 | Running loss: 1.09483\n",
      "Epoch: 1 | Iteration: 759 | Classification loss: 0.26434 | Regression loss: 0.55816 | Running loss: 1.09410\n",
      "Epoch: 1 | Iteration: 760 | Classification loss: 0.43397 | Regression loss: 0.75044 | Running loss: 1.09421\n",
      "Epoch: 1 | Iteration: 761 | Classification loss: 0.32764 | Regression loss: 0.70081 | Running loss: 1.09438\n",
      "Epoch: 1 | Iteration: 762 | Classification loss: 0.44929 | Regression loss: 0.80233 | Running loss: 1.09468\n",
      "Epoch: 1 | Iteration: 763 | Classification loss: 0.35437 | Regression loss: 0.73440 | Running loss: 1.09464\n",
      "Epoch: 1 | Iteration: 764 | Classification loss: 1.10658 | Regression loss: 0.82889 | Running loss: 1.09658\n",
      "Epoch: 1 | Iteration: 765 | Classification loss: 0.27437 | Regression loss: 0.74236 | Running loss: 1.09622\n",
      "Epoch: 1 | Iteration: 766 | Classification loss: 0.42736 | Regression loss: 0.89357 | Running loss: 1.09613\n",
      "Epoch: 1 | Iteration: 767 | Classification loss: 0.40327 | Regression loss: 0.74992 | Running loss: 1.09620\n",
      "Epoch: 1 | Iteration: 768 | Classification loss: 0.31635 | Regression loss: 0.71046 | Running loss: 1.09597\n",
      "Epoch: 1 | Iteration: 769 | Classification loss: 0.42672 | Regression loss: 0.81577 | Running loss: 1.09617\n",
      "Epoch: 1 | Iteration: 770 | Classification loss: 0.32518 | Regression loss: 0.85933 | Running loss: 1.09647\n",
      "Epoch: 1 | Iteration: 771 | Classification loss: 0.27717 | Regression loss: 0.71492 | Running loss: 1.09635\n",
      "Epoch: 1 | Iteration: 772 | Classification loss: 0.26861 | Regression loss: 0.57722 | Running loss: 1.09660\n",
      "Epoch: 1 | Iteration: 773 | Classification loss: 0.32128 | Regression loss: 0.67669 | Running loss: 1.09643\n",
      "Epoch: 1 | Iteration: 774 | Classification loss: 0.33077 | Regression loss: 0.72625 | Running loss: 1.09654\n",
      "Epoch: 1 | Iteration: 775 | Classification loss: 0.40810 | Regression loss: 0.81818 | Running loss: 1.09673\n",
      "Epoch: 1 | Iteration: 776 | Classification loss: 0.36558 | Regression loss: 0.78008 | Running loss: 1.09682\n",
      "Epoch: 1 | Iteration: 777 | Classification loss: 0.32379 | Regression loss: 0.59294 | Running loss: 1.09565\n",
      "Epoch: 1 | Iteration: 778 | Classification loss: 0.31110 | Regression loss: 0.79671 | Running loss: 1.09519\n",
      "Epoch: 1 | Iteration: 779 | Classification loss: 0.43118 | Regression loss: 0.76409 | Running loss: 1.09604\n",
      "Epoch: 1 | Iteration: 780 | Classification loss: 0.42366 | Regression loss: 0.79700 | Running loss: 1.09610\n",
      "Epoch: 1 | Iteration: 781 | Classification loss: 0.47435 | Regression loss: 0.81401 | Running loss: 1.09638\n",
      "Epoch: 1 | Iteration: 782 | Classification loss: 0.35513 | Regression loss: 0.72330 | Running loss: 1.09622\n",
      "Epoch: 1 | Iteration: 783 | Classification loss: 0.42285 | Regression loss: 0.82917 | Running loss: 1.09658\n",
      "Evaluating dataset\n",
      "\n",
      "mAP:\n",
      "person: 0.3260425363621732\n",
      "Precision:  0.03866484528122587\n",
      "Recall:  0.7393526405451448\n",
      "car: 0.4254099925735383\n",
      "Precision:  0.03866484528122587\n",
      "Recall:  0.7393526405451448\n",
      "Epoch: 2 | Iteration: 0 | Classification loss: 0.25833 | Regression loss: 0.67060 | Running loss: 1.09587\n",
      "Epoch: 2 | Iteration: 1 | Classification loss: 0.38220 | Regression loss: 0.71763 | Running loss: 1.09548\n",
      "Epoch: 2 | Iteration: 2 | Classification loss: 0.31975 | Regression loss: 0.56896 | Running loss: 1.09477\n",
      "Epoch: 2 | Iteration: 3 | Classification loss: 0.35162 | Regression loss: 0.71523 | Running loss: 1.09466\n",
      "Epoch: 2 | Iteration: 4 | Classification loss: 0.33705 | Regression loss: 0.52714 | Running loss: 1.09447\n",
      "Epoch: 2 | Iteration: 5 | Classification loss: 0.32670 | Regression loss: 0.51598 | Running loss: 1.09420\n",
      "Epoch: 2 | Iteration: 6 | Classification loss: 0.37731 | Regression loss: 0.67531 | Running loss: 1.09373\n",
      "Epoch: 2 | Iteration: 7 | Classification loss: 0.34403 | Regression loss: 0.76655 | Running loss: 1.09347\n",
      "Epoch: 2 | Iteration: 8 | Classification loss: 0.33066 | Regression loss: 0.74506 | Running loss: 1.09343\n",
      "Epoch: 2 | Iteration: 9 | Classification loss: 0.29158 | Regression loss: 0.74097 | Running loss: 1.09309\n",
      "Epoch: 2 | Iteration: 10 | Classification loss: 0.27156 | Regression loss: 0.61713 | Running loss: 1.09264\n",
      "Epoch: 2 | Iteration: 11 | Classification loss: 0.36055 | Regression loss: 0.50695 | Running loss: 1.09170\n",
      "Epoch: 2 | Iteration: 12 | Classification loss: 0.46459 | Regression loss: 0.78649 | Running loss: 1.09219\n",
      "Epoch: 2 | Iteration: 13 | Classification loss: 0.27644 | Regression loss: 0.63923 | Running loss: 1.09141\n",
      "Epoch: 2 | Iteration: 14 | Classification loss: 0.24049 | Regression loss: 0.59431 | Running loss: 1.09058\n",
      "Epoch: 2 | Iteration: 15 | Classification loss: 0.32511 | Regression loss: 0.63123 | Running loss: 1.08988\n",
      "Epoch: 2 | Iteration: 16 | Classification loss: 0.35350 | Regression loss: 0.61904 | Running loss: 1.08886\n",
      "Epoch: 2 | Iteration: 17 | Classification loss: 0.34807 | Regression loss: 0.71427 | Running loss: 1.08852\n",
      "Epoch: 2 | Iteration: 18 | Classification loss: 0.41055 | Regression loss: 0.80361 | Running loss: 1.08890\n",
      "Epoch: 2 | Iteration: 19 | Classification loss: 0.28921 | Regression loss: 0.75581 | Running loss: 1.08872\n",
      "Epoch: 2 | Iteration: 20 | Classification loss: 0.33041 | Regression loss: 0.68622 | Running loss: 1.08865\n",
      "Epoch: 2 | Iteration: 21 | Classification loss: 0.32757 | Regression loss: 0.77270 | Running loss: 1.08909\n",
      "Epoch: 2 | Iteration: 22 | Classification loss: 0.30270 | Regression loss: 0.71199 | Running loss: 1.08864\n",
      "Epoch: 2 | Iteration: 23 | Classification loss: 0.32283 | Regression loss: 0.67673 | Running loss: 1.08837\n",
      "Epoch: 2 | Iteration: 24 | Classification loss: 0.36214 | Regression loss: 0.74922 | Running loss: 1.08852\n",
      "Epoch: 2 | Iteration: 25 | Classification loss: 0.36024 | Regression loss: 0.81399 | Running loss: 1.08867\n",
      "Epoch: 2 | Iteration: 26 | Classification loss: 0.30188 | Regression loss: 0.73539 | Running loss: 1.08830\n",
      "Epoch: 2 | Iteration: 27 | Classification loss: 0.31356 | Regression loss: 0.53651 | Running loss: 1.08762\n",
      "Epoch: 2 | Iteration: 28 | Classification loss: 0.41110 | Regression loss: 0.79644 | Running loss: 1.08760\n",
      "Epoch: 2 | Iteration: 29 | Classification loss: 0.35423 | Regression loss: 0.72605 | Running loss: 1.08785\n",
      "Epoch: 2 | Iteration: 30 | Classification loss: 0.31360 | Regression loss: 0.70634 | Running loss: 1.08793\n",
      "Epoch: 2 | Iteration: 31 | Classification loss: 0.28454 | Regression loss: 0.68389 | Running loss: 1.08801\n",
      "Epoch: 2 | Iteration: 32 | Classification loss: 0.28769 | Regression loss: 0.65991 | Running loss: 1.08771\n",
      "Epoch: 2 | Iteration: 33 | Classification loss: 0.40295 | Regression loss: 0.87369 | Running loss: 1.08808\n",
      "Epoch: 2 | Iteration: 34 | Classification loss: 0.40769 | Regression loss: 0.63387 | Running loss: 1.08808\n",
      "Epoch: 2 | Iteration: 35 | Classification loss: 0.24973 | Regression loss: 0.55899 | Running loss: 1.08718\n",
      "Epoch: 2 | Iteration: 36 | Classification loss: 0.56024 | Regression loss: 0.87346 | Running loss: 1.08783\n",
      "Epoch: 2 | Iteration: 37 | Classification loss: 0.30868 | Regression loss: 0.60649 | Running loss: 1.08759\n",
      "Epoch: 2 | Iteration: 38 | Classification loss: 0.34255 | Regression loss: 0.71691 | Running loss: 1.08736\n",
      "Epoch: 2 | Iteration: 39 | Classification loss: 0.35020 | Regression loss: 0.67208 | Running loss: 1.08742\n",
      "Epoch: 2 | Iteration: 40 | Classification loss: 0.27606 | Regression loss: 0.64732 | Running loss: 1.08701\n",
      "Epoch: 2 | Iteration: 41 | Classification loss: 0.16227 | Regression loss: 0.46776 | Running loss: 1.08594\n",
      "Epoch: 2 | Iteration: 42 | Classification loss: 0.41093 | Regression loss: 0.73763 | Running loss: 1.08581\n",
      "Epoch: 2 | Iteration: 43 | Classification loss: 0.29935 | Regression loss: 0.72402 | Running loss: 1.08549\n",
      "Epoch: 2 | Iteration: 44 | Classification loss: 0.25056 | Regression loss: 0.58627 | Running loss: 1.08496\n",
      "Epoch: 2 | Iteration: 45 | Classification loss: 0.31541 | Regression loss: 0.81591 | Running loss: 1.08542\n",
      "Epoch: 2 | Iteration: 46 | Classification loss: 0.41847 | Regression loss: 0.80494 | Running loss: 1.08605\n",
      "Epoch: 2 | Iteration: 47 | Classification loss: 0.13944 | Regression loss: 0.43361 | Running loss: 1.08483\n",
      "Epoch: 2 | Iteration: 48 | Classification loss: 0.38688 | Regression loss: 0.65125 | Running loss: 1.08436\n",
      "Epoch: 2 | Iteration: 49 | Classification loss: 0.34173 | Regression loss: 0.66444 | Running loss: 1.08425\n",
      "Epoch: 2 | Iteration: 50 | Classification loss: 0.36745 | Regression loss: 0.56338 | Running loss: 1.08408\n",
      "Epoch: 2 | Iteration: 51 | Classification loss: 0.40442 | Regression loss: 0.70552 | Running loss: 1.08384\n",
      "Epoch: 2 | Iteration: 52 | Classification loss: 0.33431 | Regression loss: 0.65538 | Running loss: 1.08358\n",
      "Epoch: 2 | Iteration: 53 | Classification loss: 0.39997 | Regression loss: 0.77109 | Running loss: 1.08331\n",
      "Epoch: 2 | Iteration: 54 | Classification loss: 0.22391 | Regression loss: 0.57896 | Running loss: 1.08298\n",
      "Epoch: 2 | Iteration: 55 | Classification loss: 0.36154 | Regression loss: 0.76915 | Running loss: 1.08294\n",
      "Epoch: 2 | Iteration: 56 | Classification loss: 0.26797 | Regression loss: 0.58822 | Running loss: 1.08254\n",
      "Epoch: 2 | Iteration: 57 | Classification loss: 0.25367 | Regression loss: 0.62334 | Running loss: 1.08196\n",
      "Epoch: 2 | Iteration: 58 | Classification loss: 0.38261 | Regression loss: 0.78997 | Running loss: 1.08166\n",
      "Epoch: 2 | Iteration: 59 | Classification loss: 0.32530 | Regression loss: 0.71986 | Running loss: 1.08125\n",
      "Epoch: 2 | Iteration: 60 | Classification loss: 0.29849 | Regression loss: 0.69771 | Running loss: 1.08110\n",
      "Epoch: 2 | Iteration: 61 | Classification loss: 0.31073 | Regression loss: 0.62359 | Running loss: 1.08071\n",
      "Epoch: 2 | Iteration: 62 | Classification loss: 0.38607 | Regression loss: 0.73042 | Running loss: 1.08070\n",
      "Epoch: 2 | Iteration: 63 | Classification loss: 0.41054 | Regression loss: 0.68872 | Running loss: 1.08024\n",
      "Epoch: 2 | Iteration: 64 | Classification loss: 0.22796 | Regression loss: 0.56679 | Running loss: 1.07973\n",
      "Epoch: 2 | Iteration: 65 | Classification loss: 0.37574 | Regression loss: 0.83364 | Running loss: 1.07954\n",
      "Epoch: 2 | Iteration: 66 | Classification loss: 0.36381 | Regression loss: 0.88386 | Running loss: 1.08005\n",
      "Epoch: 2 | Iteration: 67 | Classification loss: 0.30973 | Regression loss: 0.57963 | Running loss: 1.07977\n",
      "Epoch: 2 | Iteration: 68 | Classification loss: 0.24671 | Regression loss: 0.62150 | Running loss: 1.07924\n",
      "Epoch: 2 | Iteration: 69 | Classification loss: 0.33760 | Regression loss: 0.80396 | Running loss: 1.07899\n",
      "Epoch: 2 | Iteration: 70 | Classification loss: 0.27734 | Regression loss: 0.68169 | Running loss: 1.07845\n",
      "Epoch: 2 | Iteration: 71 | Classification loss: 0.34064 | Regression loss: 0.76005 | Running loss: 1.07867\n",
      "Epoch: 2 | Iteration: 72 | Classification loss: 0.29168 | Regression loss: 0.60157 | Running loss: 1.07796\n",
      "Epoch: 2 | Iteration: 73 | Classification loss: 0.30379 | Regression loss: 0.65687 | Running loss: 1.07749\n",
      "Epoch: 2 | Iteration: 74 | Classification loss: 0.36922 | Regression loss: 0.86713 | Running loss: 1.07763\n",
      "Epoch: 2 | Iteration: 75 | Classification loss: 0.26775 | Regression loss: 0.49007 | Running loss: 1.07742\n",
      "Epoch: 2 | Iteration: 76 | Classification loss: 0.26833 | Regression loss: 0.61971 | Running loss: 1.07693\n",
      "Epoch: 2 | Iteration: 77 | Classification loss: 0.40902 | Regression loss: 0.71427 | Running loss: 1.07696\n",
      "Epoch: 2 | Iteration: 78 | Classification loss: 0.28619 | Regression loss: 0.57388 | Running loss: 1.07646\n",
      "Epoch: 2 | Iteration: 79 | Classification loss: 0.37971 | Regression loss: 0.57408 | Running loss: 1.07648\n",
      "Epoch: 2 | Iteration: 80 | Classification loss: 0.29209 | Regression loss: 0.65338 | Running loss: 1.07637\n",
      "Epoch: 2 | Iteration: 81 | Classification loss: 0.29827 | Regression loss: 0.83151 | Running loss: 1.07673\n",
      "Epoch: 2 | Iteration: 82 | Classification loss: 0.22675 | Regression loss: 0.57854 | Running loss: 1.07601\n",
      "Epoch: 2 | Iteration: 83 | Classification loss: 0.32924 | Regression loss: 0.69139 | Running loss: 1.07638\n",
      "Epoch: 2 | Iteration: 84 | Classification loss: 0.30628 | Regression loss: 0.67440 | Running loss: 1.07582\n",
      "Epoch: 2 | Iteration: 85 | Classification loss: 0.21233 | Regression loss: 0.58514 | Running loss: 1.07540\n",
      "Epoch: 2 | Iteration: 86 | Classification loss: 0.33007 | Regression loss: 0.68570 | Running loss: 1.07525\n",
      "Epoch: 2 | Iteration: 87 | Classification loss: 0.38606 | Regression loss: 0.77782 | Running loss: 1.07566\n",
      "Epoch: 2 | Iteration: 88 | Classification loss: 0.29317 | Regression loss: 0.67730 | Running loss: 1.07520\n",
      "Epoch: 2 | Iteration: 89 | Classification loss: 0.39809 | Regression loss: 0.57073 | Running loss: 1.07532\n",
      "Epoch: 2 | Iteration: 90 | Classification loss: 0.34113 | Regression loss: 0.71278 | Running loss: 1.07507\n",
      "Epoch: 2 | Iteration: 91 | Classification loss: 0.46458 | Regression loss: 0.85549 | Running loss: 1.07592\n",
      "Epoch: 2 | Iteration: 92 | Classification loss: 0.15957 | Regression loss: 0.38130 | Running loss: 1.07507\n",
      "Epoch: 2 | Iteration: 93 | Classification loss: 0.59237 | Regression loss: 0.70833 | Running loss: 1.07568\n",
      "Epoch: 2 | Iteration: 94 | Classification loss: 0.26365 | Regression loss: 0.59865 | Running loss: 1.07511\n",
      "Epoch: 2 | Iteration: 95 | Classification loss: 0.32249 | Regression loss: 0.59010 | Running loss: 1.07401\n",
      "Epoch: 2 | Iteration: 96 | Classification loss: 0.31961 | Regression loss: 0.74904 | Running loss: 1.07366\n",
      "Epoch: 2 | Iteration: 97 | Classification loss: 0.33549 | Regression loss: 0.76542 | Running loss: 1.07345\n",
      "Epoch: 2 | Iteration: 98 | Classification loss: 0.17949 | Regression loss: 0.50474 | Running loss: 1.07224\n",
      "Epoch: 2 | Iteration: 99 | Classification loss: 0.38799 | Regression loss: 0.79549 | Running loss: 1.07192\n",
      "Epoch: 2 | Iteration: 100 | Classification loss: 0.25258 | Regression loss: 0.53367 | Running loss: 1.07118\n",
      "Epoch: 2 | Iteration: 101 | Classification loss: 0.28865 | Regression loss: 0.69998 | Running loss: 1.07103\n",
      "Epoch: 2 | Iteration: 102 | Classification loss: 0.55653 | Regression loss: 0.76597 | Running loss: 1.07202\n",
      "Epoch: 2 | Iteration: 103 | Classification loss: 0.23732 | Regression loss: 0.57530 | Running loss: 1.07128\n",
      "Epoch: 2 | Iteration: 104 | Classification loss: 0.28825 | Regression loss: 0.81468 | Running loss: 1.07124\n",
      "Epoch: 2 | Iteration: 105 | Classification loss: 0.19368 | Regression loss: 0.57964 | Running loss: 1.07087\n",
      "Epoch: 2 | Iteration: 106 | Classification loss: 0.29662 | Regression loss: 0.55205 | Running loss: 1.07061\n",
      "Epoch: 2 | Iteration: 107 | Classification loss: 0.36859 | Regression loss: 0.62973 | Running loss: 1.07041\n",
      "Epoch: 2 | Iteration: 108 | Classification loss: 0.28287 | Regression loss: 0.58398 | Running loss: 1.07009\n",
      "Epoch: 2 | Iteration: 109 | Classification loss: 0.32629 | Regression loss: 0.65598 | Running loss: 1.06945\n",
      "Epoch: 2 | Iteration: 110 | Classification loss: 0.23004 | Regression loss: 0.56223 | Running loss: 1.06898\n",
      "Epoch: 2 | Iteration: 111 | Classification loss: 0.33185 | Regression loss: 0.74842 | Running loss: 1.06890\n",
      "Epoch: 2 | Iteration: 112 | Classification loss: 0.33350 | Regression loss: 0.54324 | Running loss: 1.06816\n",
      "Epoch: 2 | Iteration: 113 | Classification loss: 0.39637 | Regression loss: 0.75544 | Running loss: 1.06831\n",
      "Epoch: 2 | Iteration: 114 | Classification loss: 0.29816 | Regression loss: 0.74204 | Running loss: 1.06793\n",
      "Epoch: 2 | Iteration: 115 | Classification loss: 0.33588 | Regression loss: 0.71283 | Running loss: 1.06843\n",
      "Epoch: 2 | Iteration: 116 | Classification loss: 0.37120 | Regression loss: 0.65214 | Running loss: 1.06863\n",
      "Epoch: 2 | Iteration: 117 | Classification loss: 0.30201 | Regression loss: 0.72604 | Running loss: 1.06887\n",
      "Epoch: 2 | Iteration: 118 | Classification loss: 0.24005 | Regression loss: 0.52927 | Running loss: 1.06790\n",
      "Epoch: 2 | Iteration: 119 | Classification loss: 0.26780 | Regression loss: 0.67346 | Running loss: 1.06763\n",
      "Epoch: 2 | Iteration: 120 | Classification loss: 0.32742 | Regression loss: 0.64778 | Running loss: 1.06786\n",
      "Epoch: 2 | Iteration: 121 | Classification loss: 0.31439 | Regression loss: 0.77791 | Running loss: 1.06776\n",
      "Epoch: 2 | Iteration: 122 | Classification loss: 0.50514 | Regression loss: 0.74686 | Running loss: 1.06807\n",
      "Epoch: 2 | Iteration: 123 | Classification loss: 0.24550 | Regression loss: 0.63144 | Running loss: 1.06741\n",
      "Epoch: 2 | Iteration: 124 | Classification loss: 0.34053 | Regression loss: 0.61344 | Running loss: 1.06721\n",
      "Epoch: 2 | Iteration: 125 | Classification loss: 0.41024 | Regression loss: 0.72038 | Running loss: 1.06760\n",
      "Epoch: 2 | Iteration: 126 | Classification loss: 0.36749 | Regression loss: 0.81586 | Running loss: 1.06756\n",
      "Epoch: 2 | Iteration: 127 | Classification loss: 0.29511 | Regression loss: 0.65367 | Running loss: 1.06751\n",
      "Epoch: 2 | Iteration: 128 | Classification loss: 0.42522 | Regression loss: 0.82855 | Running loss: 1.06764\n",
      "Epoch: 2 | Iteration: 129 | Classification loss: 0.35269 | Regression loss: 0.77041 | Running loss: 1.06786\n",
      "Epoch: 2 | Iteration: 130 | Classification loss: 0.37220 | Regression loss: 0.70446 | Running loss: 1.06768\n",
      "Epoch: 2 | Iteration: 131 | Classification loss: 0.57475 | Regression loss: 0.80200 | Running loss: 1.06819\n",
      "Epoch: 2 | Iteration: 132 | Classification loss: 0.38633 | Regression loss: 0.70079 | Running loss: 1.06825\n",
      "Epoch: 2 | Iteration: 133 | Classification loss: 0.20725 | Regression loss: 0.51917 | Running loss: 1.06727\n",
      "Epoch: 2 | Iteration: 134 | Classification loss: 0.25230 | Regression loss: 0.61191 | Running loss: 1.06686\n",
      "Epoch: 2 | Iteration: 135 | Classification loss: 0.40742 | Regression loss: 0.63501 | Running loss: 1.06671\n",
      "Epoch: 2 | Iteration: 136 | Classification loss: 0.32562 | Regression loss: 0.77529 | Running loss: 1.06674\n",
      "Epoch: 2 | Iteration: 137 | Classification loss: 0.30706 | Regression loss: 0.61948 | Running loss: 1.06644\n",
      "Epoch: 2 | Iteration: 138 | Classification loss: 0.38914 | Regression loss: 0.71419 | Running loss: 1.06632\n",
      "Epoch: 2 | Iteration: 139 | Classification loss: 0.27386 | Regression loss: 0.63474 | Running loss: 1.06564\n",
      "Epoch: 2 | Iteration: 140 | Classification loss: 0.22855 | Regression loss: 0.56857 | Running loss: 1.06568\n",
      "Epoch: 2 | Iteration: 141 | Classification loss: 0.31601 | Regression loss: 0.73205 | Running loss: 1.06550\n",
      "Epoch: 2 | Iteration: 142 | Classification loss: 0.30917 | Regression loss: 0.64010 | Running loss: 1.06544\n",
      "Epoch: 2 | Iteration: 143 | Classification loss: 0.21958 | Regression loss: 0.61074 | Running loss: 1.06514\n",
      "Epoch: 2 | Iteration: 144 | Classification loss: 0.31381 | Regression loss: 0.72686 | Running loss: 1.06585\n",
      "Epoch: 2 | Iteration: 145 | Classification loss: 0.29677 | Regression loss: 0.71080 | Running loss: 1.06574\n",
      "Epoch: 2 | Iteration: 146 | Classification loss: 0.29650 | Regression loss: 0.62811 | Running loss: 1.06491\n",
      "Epoch: 2 | Iteration: 147 | Classification loss: 0.38593 | Regression loss: 0.84860 | Running loss: 1.06487\n",
      "Epoch: 2 | Iteration: 148 | Classification loss: 0.22039 | Regression loss: 0.48607 | Running loss: 1.06401\n",
      "Epoch: 2 | Iteration: 149 | Classification loss: 0.29217 | Regression loss: 0.58480 | Running loss: 1.06372\n",
      "Epoch: 2 | Iteration: 150 | Classification loss: 0.26716 | Regression loss: 0.58382 | Running loss: 1.06273\n",
      "Epoch: 2 | Iteration: 151 | Classification loss: 0.30409 | Regression loss: 0.72734 | Running loss: 1.06295\n",
      "Epoch: 2 | Iteration: 152 | Classification loss: 0.37895 | Regression loss: 0.64271 | Running loss: 1.06260\n",
      "Epoch: 2 | Iteration: 153 | Classification loss: 0.36712 | Regression loss: 0.62497 | Running loss: 1.06181\n",
      "Epoch: 2 | Iteration: 154 | Classification loss: 0.26110 | Regression loss: 0.62990 | Running loss: 1.06147\n",
      "Epoch: 2 | Iteration: 155 | Classification loss: 0.31175 | Regression loss: 0.69370 | Running loss: 1.06112\n",
      "Epoch: 2 | Iteration: 156 | Classification loss: 0.23602 | Regression loss: 0.60139 | Running loss: 1.06050\n",
      "Epoch: 2 | Iteration: 157 | Classification loss: 0.31055 | Regression loss: 0.69783 | Running loss: 1.06058\n",
      "Epoch: 2 | Iteration: 158 | Classification loss: 0.28931 | Regression loss: 0.69287 | Running loss: 1.06044\n",
      "Epoch: 2 | Iteration: 159 | Classification loss: 0.31148 | Regression loss: 0.80316 | Running loss: 1.06029\n",
      "Epoch: 2 | Iteration: 160 | Classification loss: 0.23199 | Regression loss: 0.57571 | Running loss: 1.05939\n",
      "Epoch: 2 | Iteration: 161 | Classification loss: 0.38120 | Regression loss: 0.75319 | Running loss: 1.05928\n",
      "Epoch: 2 | Iteration: 162 | Classification loss: 0.22238 | Regression loss: 0.61338 | Running loss: 1.05885\n",
      "Epoch: 2 | Iteration: 163 | Classification loss: 0.39109 | Regression loss: 0.73908 | Running loss: 1.05917\n",
      "Epoch: 2 | Iteration: 164 | Classification loss: 0.39737 | Regression loss: 0.81697 | Running loss: 1.05949\n",
      "Epoch: 2 | Iteration: 165 | Classification loss: 0.26407 | Regression loss: 0.72322 | Running loss: 1.05944\n",
      "Epoch: 2 | Iteration: 166 | Classification loss: 0.39917 | Regression loss: 0.78442 | Running loss: 1.05954\n",
      "Epoch: 2 | Iteration: 167 | Classification loss: 0.29985 | Regression loss: 0.77465 | Running loss: 1.05958\n",
      "Epoch: 2 | Iteration: 168 | Classification loss: 0.24234 | Regression loss: 0.67482 | Running loss: 1.05901\n",
      "Epoch: 2 | Iteration: 169 | Classification loss: 0.53154 | Regression loss: 0.86208 | Running loss: 1.05919\n",
      "Epoch: 2 | Iteration: 170 | Classification loss: 0.28394 | Regression loss: 0.74453 | Running loss: 1.05899\n",
      "Epoch: 2 | Iteration: 171 | Classification loss: 0.37528 | Regression loss: 0.82028 | Running loss: 1.05911\n",
      "Epoch: 2 | Iteration: 172 | Classification loss: 0.37786 | Regression loss: 0.78165 | Running loss: 1.05967\n",
      "Epoch: 2 | Iteration: 173 | Classification loss: 0.49569 | Regression loss: 0.75752 | Running loss: 1.05999\n",
      "Epoch: 2 | Iteration: 174 | Classification loss: 0.35565 | Regression loss: 0.74840 | Running loss: 1.05974\n",
      "Epoch: 2 | Iteration: 175 | Classification loss: 0.52480 | Regression loss: 0.80063 | Running loss: 1.06044\n",
      "Epoch: 2 | Iteration: 176 | Classification loss: 0.54379 | Regression loss: 0.84190 | Running loss: 1.06085\n",
      "Epoch: 2 | Iteration: 177 | Classification loss: 0.35300 | Regression loss: 0.64661 | Running loss: 1.06063\n",
      "Epoch: 2 | Iteration: 178 | Classification loss: 0.33865 | Regression loss: 0.65902 | Running loss: 1.06031\n",
      "Epoch: 2 | Iteration: 179 | Classification loss: 0.37117 | Regression loss: 0.69056 | Running loss: 1.06054\n",
      "Epoch: 2 | Iteration: 180 | Classification loss: 0.39217 | Regression loss: 0.60380 | Running loss: 1.06028\n",
      "Epoch: 2 | Iteration: 181 | Classification loss: 0.30633 | Regression loss: 0.74167 | Running loss: 1.06032\n",
      "Epoch: 2 | Iteration: 182 | Classification loss: 0.23543 | Regression loss: 0.57814 | Running loss: 1.05954\n",
      "Epoch: 2 | Iteration: 183 | Classification loss: 0.34468 | Regression loss: 0.74651 | Running loss: 1.05937\n",
      "Epoch: 2 | Iteration: 184 | Classification loss: 0.26553 | Regression loss: 0.50969 | Running loss: 1.05880\n",
      "Epoch: 2 | Iteration: 185 | Classification loss: 0.27537 | Regression loss: 0.52841 | Running loss: 1.05788\n",
      "Epoch: 2 | Iteration: 186 | Classification loss: 0.36908 | Regression loss: 0.73779 | Running loss: 1.05739\n",
      "Epoch: 2 | Iteration: 187 | Classification loss: 0.18647 | Regression loss: 0.55631 | Running loss: 1.05625\n",
      "Epoch: 2 | Iteration: 188 | Classification loss: 0.28055 | Regression loss: 0.62773 | Running loss: 1.05623\n",
      "Epoch: 2 | Iteration: 189 | Classification loss: 0.34155 | Regression loss: 0.67912 | Running loss: 1.05571\n",
      "Epoch: 2 | Iteration: 190 | Classification loss: 0.45388 | Regression loss: 0.86139 | Running loss: 1.05617\n",
      "Epoch: 2 | Iteration: 191 | Classification loss: 0.33725 | Regression loss: 0.78388 | Running loss: 1.05668\n",
      "Epoch: 2 | Iteration: 192 | Classification loss: 0.37959 | Regression loss: 0.62263 | Running loss: 1.05661\n",
      "Epoch: 2 | Iteration: 193 | Classification loss: 0.28112 | Regression loss: 0.71944 | Running loss: 1.05666\n",
      "Epoch: 2 | Iteration: 194 | Classification loss: 0.29363 | Regression loss: 0.55761 | Running loss: 1.05589\n",
      "Epoch: 2 | Iteration: 195 | Classification loss: 0.40841 | Regression loss: 0.75407 | Running loss: 1.05581\n",
      "Epoch: 2 | Iteration: 196 | Classification loss: 0.38813 | Regression loss: 0.70755 | Running loss: 1.05633\n",
      "Epoch: 2 | Iteration: 197 | Classification loss: 0.35979 | Regression loss: 0.78194 | Running loss: 1.05604\n",
      "Epoch: 2 | Iteration: 198 | Classification loss: 0.44477 | Regression loss: 0.85399 | Running loss: 1.05627\n",
      "Epoch: 2 | Iteration: 199 | Classification loss: 0.36981 | Regression loss: 0.71493 | Running loss: 1.05629\n",
      "Epoch: 2 | Iteration: 200 | Classification loss: 0.29997 | Regression loss: 0.66639 | Running loss: 1.05600\n",
      "Epoch: 2 | Iteration: 201 | Classification loss: 0.46381 | Regression loss: 0.71248 | Running loss: 1.05619\n",
      "Epoch: 2 | Iteration: 202 | Classification loss: 0.44064 | Regression loss: 0.67963 | Running loss: 1.05627\n",
      "Epoch: 2 | Iteration: 203 | Classification loss: 0.36049 | Regression loss: 0.67374 | Running loss: 1.05601\n",
      "Epoch: 2 | Iteration: 204 | Classification loss: 0.41949 | Regression loss: 0.75511 | Running loss: 1.05615\n",
      "Epoch: 2 | Iteration: 205 | Classification loss: 0.46197 | Regression loss: 0.88187 | Running loss: 1.05646\n",
      "Epoch: 2 | Iteration: 206 | Classification loss: 0.25106 | Regression loss: 0.69640 | Running loss: 1.05613\n",
      "Epoch: 2 | Iteration: 207 | Classification loss: 0.30676 | Regression loss: 0.73121 | Running loss: 1.05597\n",
      "Epoch: 2 | Iteration: 208 | Classification loss: 0.37182 | Regression loss: 0.71997 | Running loss: 1.05660\n",
      "Epoch: 2 | Iteration: 209 | Classification loss: 0.38280 | Regression loss: 0.73223 | Running loss: 1.05670\n",
      "Epoch: 2 | Iteration: 210 | Classification loss: 0.29441 | Regression loss: 0.66525 | Running loss: 1.05649\n",
      "Epoch: 2 | Iteration: 211 | Classification loss: 0.42452 | Regression loss: 0.80384 | Running loss: 1.05643\n",
      "Epoch: 2 | Iteration: 212 | Classification loss: 0.39035 | Regression loss: 0.70894 | Running loss: 1.05643\n",
      "Epoch: 2 | Iteration: 213 | Classification loss: 0.48082 | Regression loss: 0.78607 | Running loss: 1.05691\n",
      "Epoch: 2 | Iteration: 214 | Classification loss: 0.43117 | Regression loss: 0.75785 | Running loss: 1.05727\n",
      "Epoch: 2 | Iteration: 215 | Classification loss: 0.34213 | Regression loss: 0.71839 | Running loss: 1.05667\n",
      "Epoch: 2 | Iteration: 216 | Classification loss: 0.29756 | Regression loss: 0.66046 | Running loss: 1.05588\n",
      "Epoch: 2 | Iteration: 217 | Classification loss: 0.32949 | Regression loss: 0.74230 | Running loss: 1.05637\n",
      "Epoch: 2 | Iteration: 218 | Classification loss: 0.38147 | Regression loss: 0.79775 | Running loss: 1.05590\n",
      "Epoch: 2 | Iteration: 219 | Classification loss: 0.28338 | Regression loss: 0.56430 | Running loss: 1.05529\n",
      "Epoch: 2 | Iteration: 220 | Classification loss: 0.35412 | Regression loss: 0.65112 | Running loss: 1.05522\n",
      "Epoch: 2 | Iteration: 221 | Classification loss: 0.29932 | Regression loss: 0.70484 | Running loss: 1.05516\n",
      "Epoch: 2 | Iteration: 222 | Classification loss: 0.40779 | Regression loss: 0.59861 | Running loss: 1.05557\n",
      "Epoch: 2 | Iteration: 223 | Classification loss: 0.30885 | Regression loss: 0.66505 | Running loss: 1.05509\n",
      "Epoch: 2 | Iteration: 224 | Classification loss: 0.36746 | Regression loss: 0.71096 | Running loss: 1.05507\n",
      "Epoch: 2 | Iteration: 225 | Classification loss: 0.36433 | Regression loss: 0.72816 | Running loss: 1.05527\n",
      "Epoch: 2 | Iteration: 226 | Classification loss: 0.29157 | Regression loss: 0.66088 | Running loss: 1.05529\n",
      "Epoch: 2 | Iteration: 227 | Classification loss: 0.28289 | Regression loss: 0.68005 | Running loss: 1.05500\n",
      "Epoch: 2 | Iteration: 228 | Classification loss: 0.23949 | Regression loss: 0.61888 | Running loss: 1.05438\n",
      "Epoch: 2 | Iteration: 229 | Classification loss: 0.30802 | Regression loss: 0.70179 | Running loss: 1.05429\n",
      "Epoch: 2 | Iteration: 230 | Classification loss: 0.36813 | Regression loss: 0.71421 | Running loss: 1.05392\n",
      "Epoch: 2 | Iteration: 231 | Classification loss: 0.49446 | Regression loss: 0.81613 | Running loss: 1.05422\n",
      "Epoch: 2 | Iteration: 232 | Classification loss: 0.39434 | Regression loss: 0.84148 | Running loss: 1.05441\n",
      "Epoch: 2 | Iteration: 233 | Classification loss: 0.41431 | Regression loss: 0.64691 | Running loss: 1.05379\n",
      "Epoch: 2 | Iteration: 234 | Classification loss: 0.36286 | Regression loss: 0.64144 | Running loss: 1.05317\n",
      "Epoch: 2 | Iteration: 235 | Classification loss: 0.79138 | Regression loss: 0.87769 | Running loss: 1.05439\n",
      "Epoch: 2 | Iteration: 236 | Classification loss: 0.24345 | Regression loss: 0.51056 | Running loss: 1.05343\n",
      "Epoch: 2 | Iteration: 237 | Classification loss: 0.39139 | Regression loss: 0.77711 | Running loss: 1.05337\n",
      "Epoch: 2 | Iteration: 238 | Classification loss: 0.47953 | Regression loss: 0.80937 | Running loss: 1.05383\n",
      "Epoch: 2 | Iteration: 239 | Classification loss: 0.29480 | Regression loss: 0.61536 | Running loss: 1.05339\n",
      "Epoch: 2 | Iteration: 240 | Classification loss: 0.36353 | Regression loss: 0.80912 | Running loss: 1.05372\n",
      "Epoch: 2 | Iteration: 241 | Classification loss: 0.29291 | Regression loss: 0.71099 | Running loss: 1.05424\n",
      "Epoch: 2 | Iteration: 242 | Classification loss: 0.27608 | Regression loss: 0.50860 | Running loss: 1.05363\n",
      "Epoch: 2 | Iteration: 243 | Classification loss: 0.32029 | Regression loss: 0.80278 | Running loss: 1.05394\n",
      "Epoch: 2 | Iteration: 244 | Classification loss: 0.33041 | Regression loss: 0.57751 | Running loss: 1.05386\n",
      "Epoch: 2 | Iteration: 245 | Classification loss: 0.21319 | Regression loss: 0.48593 | Running loss: 1.05319\n",
      "Epoch: 2 | Iteration: 246 | Classification loss: 0.32199 | Regression loss: 0.77525 | Running loss: 1.05318\n",
      "Epoch: 2 | Iteration: 247 | Classification loss: 0.29560 | Regression loss: 0.75458 | Running loss: 1.05319\n",
      "Epoch: 2 | Iteration: 248 | Classification loss: 0.28591 | Regression loss: 0.62306 | Running loss: 1.05315\n",
      "Epoch: 2 | Iteration: 249 | Classification loss: 0.31395 | Regression loss: 0.57608 | Running loss: 1.05280\n",
      "Epoch: 2 | Iteration: 250 | Classification loss: 0.33998 | Regression loss: 0.74358 | Running loss: 1.05311\n",
      "Epoch: 2 | Iteration: 251 | Classification loss: 0.22846 | Regression loss: 0.53202 | Running loss: 1.05179\n",
      "Epoch: 2 | Iteration: 252 | Classification loss: 0.44515 | Regression loss: 0.80867 | Running loss: 1.05210\n",
      "Epoch: 2 | Iteration: 253 | Classification loss: 0.31373 | Regression loss: 0.70865 | Running loss: 1.05194\n",
      "Epoch: 2 | Iteration: 254 | Classification loss: 0.33441 | Regression loss: 0.67683 | Running loss: 1.05146\n",
      "Epoch: 2 | Iteration: 255 | Classification loss: 0.42193 | Regression loss: 0.81146 | Running loss: 1.05174\n",
      "Epoch: 2 | Iteration: 256 | Classification loss: 0.35784 | Regression loss: 0.62637 | Running loss: 1.05132\n",
      "Epoch: 2 | Iteration: 257 | Classification loss: 0.32133 | Regression loss: 0.73088 | Running loss: 1.05096\n",
      "Epoch: 2 | Iteration: 258 | Classification loss: 0.26135 | Regression loss: 0.54916 | Running loss: 1.04982\n",
      "Epoch: 2 | Iteration: 259 | Classification loss: 0.31194 | Regression loss: 0.62130 | Running loss: 1.04953\n",
      "Epoch: 2 | Iteration: 260 | Classification loss: 0.44445 | Regression loss: 0.68548 | Running loss: 1.04971\n",
      "Epoch: 2 | Iteration: 261 | Classification loss: 0.35791 | Regression loss: 0.75886 | Running loss: 1.04948\n",
      "Epoch: 2 | Iteration: 262 | Classification loss: 0.22437 | Regression loss: 0.52338 | Running loss: 1.04879\n",
      "Epoch: 2 | Iteration: 263 | Classification loss: 0.28111 | Regression loss: 0.60358 | Running loss: 1.04828\n",
      "Epoch: 2 | Iteration: 264 | Classification loss: 0.46961 | Regression loss: 0.75004 | Running loss: 1.04871\n",
      "Epoch: 2 | Iteration: 265 | Classification loss: 0.29489 | Regression loss: 0.61039 | Running loss: 1.04833\n",
      "Epoch: 2 | Iteration: 266 | Classification loss: 0.37268 | Regression loss: 0.67799 | Running loss: 1.04812\n",
      "Epoch: 2 | Iteration: 267 | Classification loss: 0.32882 | Regression loss: 0.67754 | Running loss: 1.04793\n",
      "Epoch: 2 | Iteration: 268 | Classification loss: 0.32270 | Regression loss: 0.73437 | Running loss: 1.04796\n",
      "Epoch: 2 | Iteration: 269 | Classification loss: 0.31688 | Regression loss: 0.71880 | Running loss: 1.04829\n",
      "Epoch: 2 | Iteration: 270 | Classification loss: 0.30340 | Regression loss: 0.65186 | Running loss: 1.04840\n",
      "Epoch: 2 | Iteration: 271 | Classification loss: 0.26316 | Regression loss: 0.48982 | Running loss: 1.04757\n",
      "Epoch: 2 | Iteration: 272 | Classification loss: 0.33706 | Regression loss: 0.64921 | Running loss: 1.04760\n",
      "Epoch: 2 | Iteration: 273 | Classification loss: 0.27582 | Regression loss: 0.60209 | Running loss: 1.04743\n",
      "Epoch: 2 | Iteration: 274 | Classification loss: 0.18498 | Regression loss: 0.57782 | Running loss: 1.04720\n",
      "Epoch: 2 | Iteration: 275 | Classification loss: 0.27256 | Regression loss: 0.71863 | Running loss: 1.04700\n",
      "Epoch: 2 | Iteration: 276 | Classification loss: 0.27284 | Regression loss: 0.55873 | Running loss: 1.04667\n",
      "Epoch: 2 | Iteration: 277 | Classification loss: 0.32877 | Regression loss: 0.76225 | Running loss: 1.04616\n",
      "Epoch: 2 | Iteration: 278 | Classification loss: 0.20270 | Regression loss: 0.56445 | Running loss: 1.04528\n",
      "Epoch: 2 | Iteration: 279 | Classification loss: 0.32841 | Regression loss: 0.66752 | Running loss: 1.04474\n",
      "Epoch: 2 | Iteration: 280 | Classification loss: 0.25618 | Regression loss: 0.50570 | Running loss: 1.04457\n",
      "Epoch: 2 | Iteration: 281 | Classification loss: 0.39407 | Regression loss: 0.76525 | Running loss: 1.04438\n",
      "Epoch: 2 | Iteration: 282 | Classification loss: 0.36775 | Regression loss: 0.75369 | Running loss: 1.04442\n",
      "Epoch: 2 | Iteration: 283 | Classification loss: 0.32371 | Regression loss: 0.67177 | Running loss: 1.04369\n",
      "Epoch: 2 | Iteration: 284 | Classification loss: 0.24390 | Regression loss: 0.60577 | Running loss: 1.04336\n",
      "Epoch: 2 | Iteration: 285 | Classification loss: 0.40620 | Regression loss: 0.70588 | Running loss: 1.04314\n",
      "Epoch: 2 | Iteration: 286 | Classification loss: 0.46343 | Regression loss: 0.75646 | Running loss: 1.04322\n",
      "Epoch: 2 | Iteration: 287 | Classification loss: 0.32211 | Regression loss: 0.69869 | Running loss: 1.04332\n",
      "Epoch: 2 | Iteration: 288 | Classification loss: 0.35978 | Regression loss: 0.70789 | Running loss: 1.04296\n",
      "Epoch: 2 | Iteration: 289 | Classification loss: 0.22549 | Regression loss: 0.65819 | Running loss: 1.04284\n",
      "Epoch: 2 | Iteration: 290 | Classification loss: 0.36366 | Regression loss: 0.79524 | Running loss: 1.04340\n",
      "Epoch: 2 | Iteration: 291 | Classification loss: 0.30246 | Regression loss: 0.77098 | Running loss: 1.04305\n",
      "Epoch: 2 | Iteration: 292 | Classification loss: 0.35098 | Regression loss: 0.64873 | Running loss: 1.04275\n",
      "Epoch: 2 | Iteration: 293 | Classification loss: 0.33491 | Regression loss: 0.61971 | Running loss: 1.04275\n",
      "Epoch: 2 | Iteration: 294 | Classification loss: 0.30295 | Regression loss: 0.69931 | Running loss: 1.04207\n",
      "Epoch: 2 | Iteration: 295 | Classification loss: 0.30786 | Regression loss: 0.73612 | Running loss: 1.04222\n",
      "Epoch: 2 | Iteration: 296 | Classification loss: 0.32848 | Regression loss: 0.71749 | Running loss: 1.04217\n",
      "Epoch: 2 | Iteration: 297 | Classification loss: 0.27437 | Regression loss: 0.71928 | Running loss: 1.04168\n",
      "Epoch: 2 | Iteration: 298 | Classification loss: 0.19088 | Regression loss: 0.46092 | Running loss: 1.04101\n",
      "Epoch: 2 | Iteration: 299 | Classification loss: 0.30031 | Regression loss: 0.63180 | Running loss: 1.04059\n",
      "Epoch: 2 | Iteration: 300 | Classification loss: 0.36527 | Regression loss: 0.77870 | Running loss: 1.04108\n",
      "Epoch: 2 | Iteration: 301 | Classification loss: 0.29305 | Regression loss: 0.60319 | Running loss: 1.04049\n",
      "Epoch: 2 | Iteration: 302 | Classification loss: 0.31362 | Regression loss: 0.65220 | Running loss: 1.04007\n",
      "Epoch: 2 | Iteration: 303 | Classification loss: 0.68176 | Regression loss: 0.65679 | Running loss: 1.04045\n",
      "Epoch: 2 | Iteration: 304 | Classification loss: 0.27409 | Regression loss: 0.58359 | Running loss: 1.03993\n",
      "Epoch: 2 | Iteration: 305 | Classification loss: 0.27485 | Regression loss: 0.75480 | Running loss: 1.04021\n",
      "Epoch: 2 | Iteration: 306 | Classification loss: 0.36887 | Regression loss: 0.69309 | Running loss: 1.04052\n",
      "Epoch: 2 | Iteration: 307 | Classification loss: 0.32641 | Regression loss: 0.57333 | Running loss: 1.04024\n",
      "Epoch: 2 | Iteration: 308 | Classification loss: 0.32487 | Regression loss: 0.74027 | Running loss: 1.04064\n",
      "Epoch: 2 | Iteration: 309 | Classification loss: 0.35510 | Regression loss: 0.74621 | Running loss: 1.04101\n",
      "Epoch: 2 | Iteration: 310 | Classification loss: 0.43058 | Regression loss: 0.75084 | Running loss: 1.04104\n",
      "Epoch: 2 | Iteration: 311 | Classification loss: 0.31504 | Regression loss: 0.62750 | Running loss: 1.04057\n",
      "Epoch: 2 | Iteration: 312 | Classification loss: 0.26878 | Regression loss: 0.60883 | Running loss: 1.03994\n",
      "Epoch: 2 | Iteration: 313 | Classification loss: 0.29431 | Regression loss: 0.73929 | Running loss: 1.03982\n",
      "Epoch: 2 | Iteration: 314 | Classification loss: 0.28969 | Regression loss: 0.73169 | Running loss: 1.03972\n",
      "Epoch: 2 | Iteration: 315 | Classification loss: 0.29133 | Regression loss: 0.48691 | Running loss: 1.03948\n",
      "Epoch: 2 | Iteration: 316 | Classification loss: 0.42661 | Regression loss: 0.67130 | Running loss: 1.03966\n",
      "Epoch: 2 | Iteration: 317 | Classification loss: 0.26245 | Regression loss: 0.50181 | Running loss: 1.03928\n",
      "Epoch: 2 | Iteration: 318 | Classification loss: 0.32049 | Regression loss: 0.68352 | Running loss: 1.03923\n",
      "Epoch: 2 | Iteration: 319 | Classification loss: 0.36435 | Regression loss: 0.80872 | Running loss: 1.03971\n",
      "Epoch: 2 | Iteration: 320 | Classification loss: 0.35416 | Regression loss: 0.70653 | Running loss: 1.03950\n",
      "Epoch: 2 | Iteration: 321 | Classification loss: 0.28297 | Regression loss: 0.66140 | Running loss: 1.03938\n",
      "Epoch: 2 | Iteration: 322 | Classification loss: 0.54257 | Regression loss: 0.77266 | Running loss: 1.03968\n",
      "Epoch: 2 | Iteration: 323 | Classification loss: 0.29239 | Regression loss: 0.61093 | Running loss: 1.03935\n",
      "Epoch: 2 | Iteration: 324 | Classification loss: 0.33402 | Regression loss: 0.63277 | Running loss: 1.03924\n",
      "Epoch: 2 | Iteration: 325 | Classification loss: 0.31541 | Regression loss: 0.69719 | Running loss: 1.03892\n",
      "Epoch: 2 | Iteration: 326 | Classification loss: 0.28554 | Regression loss: 0.51410 | Running loss: 1.03796\n",
      "Epoch: 2 | Iteration: 327 | Classification loss: 0.37008 | Regression loss: 0.75582 | Running loss: 1.03824\n",
      "Epoch: 2 | Iteration: 328 | Classification loss: 0.32075 | Regression loss: 0.72747 | Running loss: 1.03819\n",
      "Epoch: 2 | Iteration: 329 | Classification loss: 0.35499 | Regression loss: 0.80859 | Running loss: 1.03830\n",
      "Epoch: 2 | Iteration: 330 | Classification loss: 0.29282 | Regression loss: 0.57597 | Running loss: 1.03832\n",
      "Epoch: 2 | Iteration: 331 | Classification loss: 0.46973 | Regression loss: 0.70385 | Running loss: 1.03858\n",
      "Epoch: 2 | Iteration: 332 | Classification loss: 0.38695 | Regression loss: 0.71766 | Running loss: 1.03848\n",
      "Epoch: 2 | Iteration: 333 | Classification loss: 0.31548 | Regression loss: 0.68551 | Running loss: 1.03785\n",
      "Epoch: 2 | Iteration: 334 | Classification loss: 0.29057 | Regression loss: 0.64764 | Running loss: 1.03723\n",
      "Epoch: 2 | Iteration: 335 | Classification loss: 0.32872 | Regression loss: 0.58350 | Running loss: 1.03660\n",
      "Epoch: 2 | Iteration: 336 | Classification loss: 0.35001 | Regression loss: 0.65898 | Running loss: 1.03697\n",
      "Epoch: 2 | Iteration: 337 | Classification loss: 0.44822 | Regression loss: 0.87768 | Running loss: 1.03728\n",
      "Epoch: 2 | Iteration: 338 | Classification loss: 0.26744 | Regression loss: 0.61126 | Running loss: 1.03669\n",
      "Epoch: 2 | Iteration: 339 | Classification loss: 0.27805 | Regression loss: 0.65655 | Running loss: 1.03594\n",
      "Epoch: 2 | Iteration: 340 | Classification loss: 0.30163 | Regression loss: 0.64913 | Running loss: 1.03530\n",
      "Epoch: 2 | Iteration: 341 | Classification loss: 0.32696 | Regression loss: 0.74459 | Running loss: 1.03471\n",
      "Epoch: 2 | Iteration: 342 | Classification loss: 0.38573 | Regression loss: 0.54781 | Running loss: 1.03491\n",
      "Epoch: 2 | Iteration: 343 | Classification loss: 0.29923 | Regression loss: 0.70845 | Running loss: 1.03508\n",
      "Epoch: 2 | Iteration: 344 | Classification loss: 0.44295 | Regression loss: 0.79110 | Running loss: 1.03526\n",
      "Epoch: 2 | Iteration: 345 | Classification loss: 0.30467 | Regression loss: 0.65220 | Running loss: 1.03550\n",
      "Epoch: 2 | Iteration: 346 | Classification loss: 0.42181 | Regression loss: 0.73414 | Running loss: 1.03598\n",
      "Epoch: 2 | Iteration: 347 | Classification loss: 0.41528 | Regression loss: 0.52684 | Running loss: 1.03559\n",
      "Epoch: 2 | Iteration: 348 | Classification loss: 0.32932 | Regression loss: 0.59648 | Running loss: 1.03619\n",
      "Epoch: 2 | Iteration: 349 | Classification loss: 0.36018 | Regression loss: 0.77702 | Running loss: 1.03647\n",
      "Epoch: 2 | Iteration: 350 | Classification loss: 0.33609 | Regression loss: 0.69268 | Running loss: 1.03622\n",
      "Epoch: 2 | Iteration: 351 | Classification loss: 0.34205 | Regression loss: 0.68677 | Running loss: 1.03589\n",
      "Epoch: 2 | Iteration: 352 | Classification loss: 0.28321 | Regression loss: 0.71875 | Running loss: 1.03575\n",
      "Epoch: 2 | Iteration: 353 | Classification loss: 0.29421 | Regression loss: 0.53277 | Running loss: 1.03519\n",
      "Epoch: 2 | Iteration: 354 | Classification loss: 0.32209 | Regression loss: 0.60476 | Running loss: 1.03500\n",
      "Epoch: 2 | Iteration: 355 | Classification loss: 0.41448 | Regression loss: 0.79017 | Running loss: 1.03608\n",
      "Epoch: 2 | Iteration: 356 | Classification loss: 0.33976 | Regression loss: 0.68015 | Running loss: 1.03589\n",
      "Epoch: 2 | Iteration: 357 | Classification loss: 0.87149 | Regression loss: 0.96972 | Running loss: 1.03779\n",
      "Epoch: 2 | Iteration: 358 | Classification loss: 0.25112 | Regression loss: 0.62513 | Running loss: 1.03738\n",
      "Epoch: 2 | Iteration: 359 | Classification loss: 0.38616 | Regression loss: 0.64849 | Running loss: 1.03712\n",
      "Epoch: 2 | Iteration: 360 | Classification loss: 0.39900 | Regression loss: 0.73583 | Running loss: 1.03698\n",
      "Epoch: 2 | Iteration: 361 | Classification loss: 0.40062 | Regression loss: 0.70548 | Running loss: 1.03749\n",
      "Epoch: 2 | Iteration: 362 | Classification loss: 0.27644 | Regression loss: 0.53451 | Running loss: 1.03721\n",
      "Epoch: 2 | Iteration: 363 | Classification loss: 0.42661 | Regression loss: 0.81415 | Running loss: 1.03786\n",
      "Epoch: 2 | Iteration: 364 | Classification loss: 0.31822 | Regression loss: 0.63356 | Running loss: 1.03771\n",
      "Epoch: 2 | Iteration: 365 | Classification loss: 0.27959 | Regression loss: 0.73318 | Running loss: 1.03758\n",
      "Epoch: 2 | Iteration: 366 | Classification loss: 0.28863 | Regression loss: 0.66388 | Running loss: 1.03682\n",
      "Epoch: 2 | Iteration: 367 | Classification loss: 0.44890 | Regression loss: 0.54025 | Running loss: 1.03695\n",
      "Epoch: 2 | Iteration: 368 | Classification loss: 0.38727 | Regression loss: 0.80798 | Running loss: 1.03735\n",
      "Epoch: 2 | Iteration: 369 | Classification loss: 0.45318 | Regression loss: 0.79093 | Running loss: 1.03744\n",
      "Epoch: 2 | Iteration: 370 | Classification loss: 0.31447 | Regression loss: 0.64408 | Running loss: 1.03675\n",
      "Epoch: 2 | Iteration: 371 | Classification loss: 0.27466 | Regression loss: 0.68532 | Running loss: 1.03607\n",
      "Epoch: 2 | Iteration: 372 | Classification loss: 0.41669 | Regression loss: 0.81640 | Running loss: 1.03672\n",
      "Epoch: 2 | Iteration: 373 | Classification loss: 0.32796 | Regression loss: 0.71288 | Running loss: 1.03662\n",
      "Epoch: 2 | Iteration: 374 | Classification loss: 0.37761 | Regression loss: 0.74488 | Running loss: 1.03682\n",
      "Epoch: 2 | Iteration: 375 | Classification loss: 0.35287 | Regression loss: 0.78036 | Running loss: 1.03721\n",
      "Epoch: 2 | Iteration: 376 | Classification loss: 0.30290 | Regression loss: 0.70012 | Running loss: 1.03702\n",
      "Epoch: 2 | Iteration: 377 | Classification loss: 0.23165 | Regression loss: 0.57015 | Running loss: 1.03627\n",
      "Epoch: 2 | Iteration: 378 | Classification loss: 0.35720 | Regression loss: 0.72491 | Running loss: 1.03638\n",
      "Epoch: 2 | Iteration: 379 | Classification loss: 0.48941 | Regression loss: 0.44435 | Running loss: 1.03567\n",
      "Epoch: 2 | Iteration: 380 | Classification loss: 0.26097 | Regression loss: 0.67322 | Running loss: 1.03512\n",
      "Epoch: 2 | Iteration: 381 | Classification loss: 0.31193 | Regression loss: 0.41159 | Running loss: 1.03468\n",
      "Epoch: 2 | Iteration: 382 | Classification loss: 0.45828 | Regression loss: 0.78573 | Running loss: 1.03533\n",
      "Epoch: 2 | Iteration: 383 | Classification loss: 0.23579 | Regression loss: 0.54849 | Running loss: 1.03493\n",
      "Epoch: 2 | Iteration: 384 | Classification loss: 0.35936 | Regression loss: 0.73183 | Running loss: 1.03498\n",
      "Epoch: 2 | Iteration: 385 | Classification loss: 0.30016 | Regression loss: 0.62337 | Running loss: 1.03506\n",
      "Epoch: 2 | Iteration: 386 | Classification loss: 0.15842 | Regression loss: 0.43613 | Running loss: 1.03396\n",
      "Epoch: 2 | Iteration: 387 | Classification loss: 0.29059 | Regression loss: 0.63599 | Running loss: 1.03387\n",
      "Epoch: 2 | Iteration: 388 | Classification loss: 0.40747 | Regression loss: 0.83246 | Running loss: 1.03433\n",
      "Epoch: 2 | Iteration: 389 | Classification loss: 0.36820 | Regression loss: 0.74808 | Running loss: 1.03461\n",
      "Epoch: 2 | Iteration: 390 | Classification loss: 0.39244 | Regression loss: 0.75663 | Running loss: 1.03423\n",
      "Epoch: 2 | Iteration: 391 | Classification loss: 0.45744 | Regression loss: 0.60808 | Running loss: 1.03402\n",
      "Epoch: 2 | Iteration: 392 | Classification loss: 0.31329 | Regression loss: 0.74035 | Running loss: 1.03454\n",
      "Epoch: 2 | Iteration: 393 | Classification loss: 0.36453 | Regression loss: 0.76786 | Running loss: 1.03472\n",
      "Epoch: 2 | Iteration: 394 | Classification loss: 0.36332 | Regression loss: 0.60277 | Running loss: 1.03464\n",
      "Epoch: 2 | Iteration: 395 | Classification loss: 0.36710 | Regression loss: 0.74840 | Running loss: 1.03466\n",
      "Epoch: 2 | Iteration: 396 | Classification loss: 0.41769 | Regression loss: 0.88556 | Running loss: 1.03506\n",
      "Epoch: 2 | Iteration: 397 | Classification loss: 0.28447 | Regression loss: 0.74400 | Running loss: 1.03490\n",
      "Epoch: 2 | Iteration: 398 | Classification loss: 0.31324 | Regression loss: 0.71390 | Running loss: 1.03498\n",
      "Epoch: 2 | Iteration: 399 | Classification loss: 0.21888 | Regression loss: 0.54459 | Running loss: 1.03481\n",
      "Epoch: 2 | Iteration: 400 | Classification loss: 0.40269 | Regression loss: 0.73113 | Running loss: 1.03515\n",
      "Epoch: 2 | Iteration: 401 | Classification loss: 0.33139 | Regression loss: 0.69945 | Running loss: 1.03554\n",
      "Epoch: 2 | Iteration: 402 | Classification loss: 0.29457 | Regression loss: 0.55649 | Running loss: 1.03516\n",
      "Epoch: 2 | Iteration: 403 | Classification loss: 0.32613 | Regression loss: 0.56451 | Running loss: 1.03494\n",
      "Epoch: 2 | Iteration: 404 | Classification loss: 0.30535 | Regression loss: 0.65561 | Running loss: 1.03457\n",
      "Epoch: 2 | Iteration: 405 | Classification loss: 0.29153 | Regression loss: 0.55156 | Running loss: 1.03422\n",
      "Epoch: 2 | Iteration: 406 | Classification loss: 0.32914 | Regression loss: 0.66204 | Running loss: 1.03412\n",
      "Epoch: 2 | Iteration: 407 | Classification loss: 0.26799 | Regression loss: 0.56967 | Running loss: 1.03354\n",
      "Epoch: 2 | Iteration: 408 | Classification loss: 0.22606 | Regression loss: 0.55417 | Running loss: 1.03284\n",
      "Epoch: 2 | Iteration: 409 | Classification loss: 0.40743 | Regression loss: 0.74325 | Running loss: 1.03280\n",
      "Epoch: 2 | Iteration: 410 | Classification loss: 0.21591 | Regression loss: 0.51938 | Running loss: 1.03163\n",
      "Epoch: 2 | Iteration: 411 | Classification loss: 0.40774 | Regression loss: 0.76157 | Running loss: 1.03135\n",
      "Epoch: 2 | Iteration: 412 | Classification loss: 0.32309 | Regression loss: 0.75608 | Running loss: 1.03114\n",
      "Epoch: 2 | Iteration: 413 | Classification loss: 0.24008 | Regression loss: 0.55104 | Running loss: 1.03031\n",
      "Epoch: 2 | Iteration: 414 | Classification loss: 0.25496 | Regression loss: 0.49191 | Running loss: 1.02993\n",
      "Epoch: 2 | Iteration: 415 | Classification loss: 0.35197 | Regression loss: 0.73889 | Running loss: 1.03032\n",
      "Epoch: 2 | Iteration: 416 | Classification loss: 0.29868 | Regression loss: 0.72175 | Running loss: 1.03048\n",
      "Epoch: 2 | Iteration: 417 | Classification loss: 0.41709 | Regression loss: 0.88752 | Running loss: 1.03078\n",
      "Epoch: 2 | Iteration: 418 | Classification loss: 0.30191 | Regression loss: 0.74513 | Running loss: 1.03046\n",
      "Epoch: 2 | Iteration: 419 | Classification loss: 0.29862 | Regression loss: 0.66231 | Running loss: 1.03050\n",
      "Epoch: 2 | Iteration: 420 | Classification loss: 0.29295 | Regression loss: 0.74609 | Running loss: 1.02987\n",
      "Epoch: 2 | Iteration: 421 | Classification loss: 0.31581 | Regression loss: 0.78832 | Running loss: 1.02958\n",
      "Epoch: 2 | Iteration: 422 | Classification loss: 0.23780 | Regression loss: 0.62260 | Running loss: 1.02931\n",
      "Epoch: 2 | Iteration: 423 | Classification loss: 0.35767 | Regression loss: 0.50287 | Running loss: 1.02920\n",
      "Epoch: 2 | Iteration: 424 | Classification loss: 0.31133 | Regression loss: 0.65576 | Running loss: 1.02855\n",
      "Epoch: 2 | Iteration: 425 | Classification loss: 0.23948 | Regression loss: 0.60928 | Running loss: 1.02830\n",
      "Epoch: 2 | Iteration: 426 | Classification loss: 0.27778 | Regression loss: 0.73111 | Running loss: 1.02869\n",
      "Epoch: 2 | Iteration: 427 | Classification loss: 0.27068 | Regression loss: 0.45579 | Running loss: 1.02805\n",
      "Epoch: 2 | Iteration: 428 | Classification loss: 0.29621 | Regression loss: 0.58242 | Running loss: 1.02815\n",
      "Epoch: 2 | Iteration: 429 | Classification loss: 0.30250 | Regression loss: 0.74719 | Running loss: 1.02834\n",
      "Epoch: 2 | Iteration: 430 | Classification loss: 0.30347 | Regression loss: 0.65478 | Running loss: 1.02792\n",
      "Epoch: 2 | Iteration: 431 | Classification loss: 0.42271 | Regression loss: 0.76074 | Running loss: 1.02807\n",
      "Epoch: 2 | Iteration: 432 | Classification loss: 0.31495 | Regression loss: 0.79704 | Running loss: 1.02822\n",
      "Epoch: 2 | Iteration: 433 | Classification loss: 0.37817 | Regression loss: 0.76552 | Running loss: 1.02841\n",
      "Epoch: 2 | Iteration: 434 | Classification loss: 0.23056 | Regression loss: 0.60237 | Running loss: 1.02751\n",
      "Epoch: 2 | Iteration: 435 | Classification loss: 0.37715 | Regression loss: 0.78217 | Running loss: 1.02787\n",
      "Epoch: 2 | Iteration: 436 | Classification loss: 0.30736 | Regression loss: 0.70822 | Running loss: 1.02722\n",
      "Epoch: 2 | Iteration: 437 | Classification loss: 0.21544 | Regression loss: 0.53876 | Running loss: 1.02665\n",
      "Epoch: 2 | Iteration: 438 | Classification loss: 0.38124 | Regression loss: 0.64187 | Running loss: 1.02667\n",
      "Epoch: 2 | Iteration: 439 | Classification loss: 0.33286 | Regression loss: 0.70748 | Running loss: 1.02646\n",
      "Epoch: 2 | Iteration: 440 | Classification loss: 0.43090 | Regression loss: 0.88924 | Running loss: 1.02653\n",
      "Epoch: 2 | Iteration: 441 | Classification loss: 0.40033 | Regression loss: 0.72611 | Running loss: 1.02648\n",
      "Epoch: 2 | Iteration: 442 | Classification loss: 0.34371 | Regression loss: 0.72521 | Running loss: 1.02607\n",
      "Epoch: 2 | Iteration: 443 | Classification loss: 0.41768 | Regression loss: 0.78400 | Running loss: 1.02660\n",
      "Epoch: 2 | Iteration: 444 | Classification loss: 0.34217 | Regression loss: 0.76671 | Running loss: 1.02659\n",
      "Epoch: 2 | Iteration: 445 | Classification loss: 0.27135 | Regression loss: 0.60596 | Running loss: 1.02629\n",
      "Epoch: 2 | Iteration: 446 | Classification loss: 0.39612 | Regression loss: 0.77744 | Running loss: 1.02649\n",
      "Epoch: 2 | Iteration: 447 | Classification loss: 0.29977 | Regression loss: 0.62393 | Running loss: 1.02619\n",
      "Epoch: 2 | Iteration: 448 | Classification loss: 0.25142 | Regression loss: 0.65916 | Running loss: 1.02595\n",
      "Epoch: 2 | Iteration: 449 | Classification loss: 0.38033 | Regression loss: 0.70391 | Running loss: 1.02591\n",
      "Epoch: 2 | Iteration: 450 | Classification loss: 0.34823 | Regression loss: 0.72889 | Running loss: 1.02564\n",
      "Epoch: 2 | Iteration: 451 | Classification loss: 0.22929 | Regression loss: 0.57410 | Running loss: 1.02558\n",
      "Epoch: 2 | Iteration: 452 | Classification loss: 0.43429 | Regression loss: 0.83816 | Running loss: 1.02619\n",
      "Epoch: 2 | Iteration: 453 | Classification loss: 0.43819 | Regression loss: 0.77245 | Running loss: 1.02664\n",
      "Epoch: 2 | Iteration: 454 | Classification loss: 0.60151 | Regression loss: 0.84049 | Running loss: 1.02765\n",
      "Epoch: 2 | Iteration: 455 | Classification loss: 0.30922 | Regression loss: 0.68703 | Running loss: 1.02769\n",
      "Epoch: 2 | Iteration: 456 | Classification loss: 0.29138 | Regression loss: 0.60233 | Running loss: 1.02735\n",
      "Epoch: 2 | Iteration: 457 | Classification loss: 0.34248 | Regression loss: 0.67515 | Running loss: 1.02718\n",
      "Epoch: 2 | Iteration: 458 | Classification loss: 0.32270 | Regression loss: 0.74486 | Running loss: 1.02704\n",
      "Epoch: 2 | Iteration: 459 | Classification loss: 0.40156 | Regression loss: 0.66409 | Running loss: 1.02649\n",
      "Epoch: 2 | Iteration: 460 | Classification loss: 0.32637 | Regression loss: 0.72372 | Running loss: 1.02599\n",
      "Epoch: 2 | Iteration: 461 | Classification loss: 0.26453 | Regression loss: 0.64002 | Running loss: 1.02565\n",
      "Epoch: 2 | Iteration: 462 | Classification loss: 0.34494 | Regression loss: 0.66038 | Running loss: 1.02529\n",
      "Epoch: 2 | Iteration: 463 | Classification loss: 0.27740 | Regression loss: 0.62891 | Running loss: 1.02450\n",
      "Epoch: 2 | Iteration: 464 | Classification loss: 0.46982 | Regression loss: 0.63012 | Running loss: 1.02417\n",
      "Epoch: 2 | Iteration: 465 | Classification loss: 0.37055 | Regression loss: 0.70558 | Running loss: 1.02393\n",
      "Epoch: 2 | Iteration: 466 | Classification loss: 0.43060 | Regression loss: 0.58953 | Running loss: 1.02402\n",
      "Epoch: 2 | Iteration: 467 | Classification loss: 0.25825 | Regression loss: 0.67852 | Running loss: 1.02395\n",
      "Epoch: 2 | Iteration: 468 | Classification loss: 0.27276 | Regression loss: 0.63960 | Running loss: 1.02367\n",
      "Epoch: 2 | Iteration: 469 | Classification loss: 0.33013 | Regression loss: 0.77993 | Running loss: 1.02397\n",
      "Epoch: 2 | Iteration: 470 | Classification loss: 0.26752 | Regression loss: 0.56554 | Running loss: 1.02362\n",
      "Epoch: 2 | Iteration: 471 | Classification loss: 0.36888 | Regression loss: 0.61023 | Running loss: 1.02323\n",
      "Epoch: 2 | Iteration: 472 | Classification loss: 0.32010 | Regression loss: 0.47702 | Running loss: 1.02267\n",
      "Epoch: 2 | Iteration: 473 | Classification loss: 0.26970 | Regression loss: 0.56922 | Running loss: 1.02298\n",
      "Epoch: 2 | Iteration: 474 | Classification loss: 0.25558 | Regression loss: 0.58855 | Running loss: 1.02244\n",
      "Epoch: 2 | Iteration: 475 | Classification loss: 0.38056 | Regression loss: 0.59631 | Running loss: 1.02275\n",
      "Epoch: 2 | Iteration: 476 | Classification loss: 0.27620 | Regression loss: 0.57373 | Running loss: 1.02208\n",
      "Epoch: 2 | Iteration: 477 | Classification loss: 0.21643 | Regression loss: 0.49580 | Running loss: 1.02145\n",
      "Epoch: 2 | Iteration: 478 | Classification loss: 0.46816 | Regression loss: 0.72065 | Running loss: 1.02132\n",
      "Epoch: 2 | Iteration: 479 | Classification loss: 0.13547 | Regression loss: 0.37334 | Running loss: 1.02016\n",
      "Epoch: 2 | Iteration: 480 | Classification loss: 0.48543 | Regression loss: 0.93078 | Running loss: 1.01912\n",
      "Epoch: 2 | Iteration: 481 | Classification loss: 0.34893 | Regression loss: 0.67994 | Running loss: 1.01915\n",
      "Epoch: 2 | Iteration: 482 | Classification loss: 0.33240 | Regression loss: 0.75237 | Running loss: 1.01867\n",
      "Epoch: 2 | Iteration: 483 | Classification loss: 0.27886 | Regression loss: 0.61790 | Running loss: 1.01816\n",
      "Epoch: 2 | Iteration: 484 | Classification loss: 0.34940 | Regression loss: 0.67315 | Running loss: 1.01815\n",
      "Epoch: 2 | Iteration: 485 | Classification loss: 0.37799 | Regression loss: 0.65123 | Running loss: 1.01773\n",
      "Epoch: 2 | Iteration: 486 | Classification loss: 0.39831 | Regression loss: 0.79997 | Running loss: 1.01775\n",
      "Epoch: 2 | Iteration: 487 | Classification loss: 0.34802 | Regression loss: 0.77929 | Running loss: 1.01802\n",
      "Epoch: 2 | Iteration: 488 | Classification loss: 0.40940 | Regression loss: 0.75679 | Running loss: 1.01866\n",
      "Epoch: 2 | Iteration: 489 | Classification loss: 0.34610 | Regression loss: 0.78562 | Running loss: 1.01893\n",
      "Epoch: 2 | Iteration: 490 | Classification loss: 0.40140 | Regression loss: 0.75010 | Running loss: 1.01912\n",
      "Epoch: 2 | Iteration: 491 | Classification loss: 0.29170 | Regression loss: 0.74573 | Running loss: 1.01874\n",
      "Epoch: 2 | Iteration: 492 | Classification loss: 0.42668 | Regression loss: 0.84934 | Running loss: 1.01900\n",
      "Epoch: 2 | Iteration: 493 | Classification loss: 0.37140 | Regression loss: 0.71054 | Running loss: 1.01933\n",
      "Epoch: 2 | Iteration: 494 | Classification loss: 0.35039 | Regression loss: 0.71212 | Running loss: 1.01924\n",
      "Epoch: 2 | Iteration: 495 | Classification loss: 0.22548 | Regression loss: 0.51115 | Running loss: 1.01833\n",
      "Epoch: 2 | Iteration: 496 | Classification loss: 0.30108 | Regression loss: 0.69078 | Running loss: 1.01787\n",
      "Epoch: 2 | Iteration: 497 | Classification loss: 0.36598 | Regression loss: 0.71748 | Running loss: 1.01746\n",
      "Epoch: 2 | Iteration: 498 | Classification loss: 0.39143 | Regression loss: 0.75708 | Running loss: 1.01760\n",
      "Epoch: 2 | Iteration: 499 | Classification loss: 0.37649 | Regression loss: 0.73056 | Running loss: 1.01731\n",
      "Epoch: 2 | Iteration: 500 | Classification loss: 0.32822 | Regression loss: 0.59005 | Running loss: 1.01729\n",
      "Epoch: 2 | Iteration: 501 | Classification loss: 0.27248 | Regression loss: 0.59425 | Running loss: 1.01682\n",
      "Epoch: 2 | Iteration: 502 | Classification loss: 0.31980 | Regression loss: 0.67564 | Running loss: 1.01704\n",
      "Epoch: 2 | Iteration: 503 | Classification loss: 0.35177 | Regression loss: 0.62412 | Running loss: 1.01685\n",
      "Epoch: 2 | Iteration: 504 | Classification loss: 0.40344 | Regression loss: 0.75568 | Running loss: 1.01744\n",
      "Epoch: 2 | Iteration: 505 | Classification loss: 0.33509 | Regression loss: 0.63185 | Running loss: 1.01769\n",
      "Epoch: 2 | Iteration: 506 | Classification loss: 0.31249 | Regression loss: 0.71843 | Running loss: 1.01765\n",
      "Epoch: 2 | Iteration: 507 | Classification loss: 0.38094 | Regression loss: 0.77600 | Running loss: 1.01774\n",
      "Epoch: 2 | Iteration: 508 | Classification loss: 0.24001 | Regression loss: 0.49138 | Running loss: 1.01705\n",
      "Epoch: 2 | Iteration: 509 | Classification loss: 0.27296 | Regression loss: 0.58779 | Running loss: 1.01671\n",
      "Epoch: 2 | Iteration: 510 | Classification loss: 0.21076 | Regression loss: 0.69352 | Running loss: 1.01674\n",
      "Epoch: 2 | Iteration: 511 | Classification loss: 0.31821 | Regression loss: 0.61309 | Running loss: 1.01687\n",
      "Epoch: 2 | Iteration: 512 | Classification loss: 0.43842 | Regression loss: 0.75044 | Running loss: 1.01674\n",
      "Epoch: 2 | Iteration: 513 | Classification loss: 0.37173 | Regression loss: 0.80960 | Running loss: 1.01727\n",
      "Epoch: 2 | Iteration: 514 | Classification loss: 0.48600 | Regression loss: 0.65028 | Running loss: 1.01788\n",
      "Epoch: 2 | Iteration: 515 | Classification loss: 0.27195 | Regression loss: 0.64990 | Running loss: 1.01781\n",
      "Epoch: 2 | Iteration: 516 | Classification loss: 0.35651 | Regression loss: 0.63064 | Running loss: 1.01784\n",
      "Epoch: 2 | Iteration: 517 | Classification loss: 0.30146 | Regression loss: 0.66319 | Running loss: 1.01764\n",
      "Epoch: 2 | Iteration: 518 | Classification loss: 0.33657 | Regression loss: 0.71135 | Running loss: 1.01731\n",
      "Epoch: 2 | Iteration: 519 | Classification loss: 0.32071 | Regression loss: 0.66947 | Running loss: 1.01720\n",
      "Epoch: 2 | Iteration: 520 | Classification loss: 0.27176 | Regression loss: 0.71212 | Running loss: 1.01713\n",
      "Epoch: 2 | Iteration: 521 | Classification loss: 0.34642 | Regression loss: 0.60751 | Running loss: 1.01684\n",
      "Epoch: 2 | Iteration: 522 | Classification loss: 0.30245 | Regression loss: 0.53263 | Running loss: 1.01648\n",
      "Epoch: 2 | Iteration: 523 | Classification loss: 0.32380 | Regression loss: 0.67351 | Running loss: 1.01648\n",
      "Epoch: 2 | Iteration: 524 | Classification loss: 0.25501 | Regression loss: 0.68902 | Running loss: 1.01614\n",
      "Epoch: 2 | Iteration: 525 | Classification loss: 0.31494 | Regression loss: 0.72521 | Running loss: 1.01588\n",
      "Epoch: 2 | Iteration: 526 | Classification loss: 0.28712 | Regression loss: 0.61404 | Running loss: 1.01560\n",
      "Epoch: 2 | Iteration: 527 | Classification loss: 0.25833 | Regression loss: 0.60183 | Running loss: 1.01562\n",
      "Epoch: 2 | Iteration: 528 | Classification loss: 0.39561 | Regression loss: 0.72813 | Running loss: 1.01546\n",
      "Epoch: 2 | Iteration: 529 | Classification loss: 0.35020 | Regression loss: 0.49060 | Running loss: 1.01498\n",
      "Epoch: 2 | Iteration: 530 | Classification loss: 0.32215 | Regression loss: 0.61309 | Running loss: 1.01481\n",
      "Epoch: 2 | Iteration: 531 | Classification loss: 0.37427 | Regression loss: 0.66805 | Running loss: 1.01496\n",
      "Epoch: 2 | Iteration: 532 | Classification loss: 0.34862 | Regression loss: 0.80279 | Running loss: 1.01536\n",
      "Epoch: 2 | Iteration: 533 | Classification loss: 0.39239 | Regression loss: 0.78979 | Running loss: 1.01517\n",
      "Epoch: 2 | Iteration: 534 | Classification loss: 0.38973 | Regression loss: 0.78394 | Running loss: 1.01544\n",
      "Epoch: 2 | Iteration: 535 | Classification loss: 0.32240 | Regression loss: 0.56342 | Running loss: 1.01559\n",
      "Epoch: 2 | Iteration: 536 | Classification loss: 0.28055 | Regression loss: 0.62854 | Running loss: 1.01454\n",
      "Epoch: 2 | Iteration: 537 | Classification loss: 0.43040 | Regression loss: 0.75328 | Running loss: 1.01508\n",
      "Epoch: 2 | Iteration: 538 | Classification loss: 0.30068 | Regression loss: 0.64294 | Running loss: 1.01485\n",
      "Epoch: 2 | Iteration: 539 | Classification loss: 0.32568 | Regression loss: 0.66798 | Running loss: 1.01479\n",
      "Epoch: 2 | Iteration: 540 | Classification loss: 0.25910 | Regression loss: 0.61972 | Running loss: 1.01470\n",
      "Epoch: 2 | Iteration: 541 | Classification loss: 0.39160 | Regression loss: 0.72796 | Running loss: 1.01568\n",
      "Epoch: 2 | Iteration: 542 | Classification loss: 0.32640 | Regression loss: 0.64278 | Running loss: 1.01532\n",
      "Epoch: 2 | Iteration: 543 | Classification loss: 0.36585 | Regression loss: 0.70063 | Running loss: 1.01541\n",
      "Epoch: 2 | Iteration: 544 | Classification loss: 0.39804 | Regression loss: 0.81451 | Running loss: 1.01616\n",
      "Epoch: 2 | Iteration: 545 | Classification loss: 0.40458 | Regression loss: 0.81236 | Running loss: 1.01633\n",
      "Epoch: 2 | Iteration: 546 | Classification loss: 0.26613 | Regression loss: 0.59440 | Running loss: 1.01561\n",
      "Epoch: 2 | Iteration: 547 | Classification loss: 0.35590 | Regression loss: 0.60589 | Running loss: 1.01638\n",
      "Epoch: 2 | Iteration: 548 | Classification loss: 0.40401 | Regression loss: 0.75249 | Running loss: 1.01662\n",
      "Epoch: 2 | Iteration: 549 | Classification loss: 0.43682 | Regression loss: 0.80597 | Running loss: 1.01709\n",
      "Epoch: 2 | Iteration: 550 | Classification loss: 0.34861 | Regression loss: 0.70738 | Running loss: 1.01734\n",
      "Epoch: 2 | Iteration: 551 | Classification loss: 0.20340 | Regression loss: 0.51944 | Running loss: 1.01657\n",
      "Epoch: 2 | Iteration: 552 | Classification loss: 0.37103 | Regression loss: 0.69524 | Running loss: 1.01672\n",
      "Epoch: 2 | Iteration: 553 | Classification loss: 0.28342 | Regression loss: 0.66433 | Running loss: 1.01628\n",
      "Epoch: 2 | Iteration: 554 | Classification loss: 0.35356 | Regression loss: 0.70506 | Running loss: 1.01679\n",
      "Epoch: 2 | Iteration: 555 | Classification loss: 0.27282 | Regression loss: 0.63011 | Running loss: 1.01633\n",
      "Epoch: 2 | Iteration: 556 | Classification loss: 0.39347 | Regression loss: 0.82611 | Running loss: 1.01706\n",
      "Epoch: 2 | Iteration: 557 | Classification loss: 0.32153 | Regression loss: 0.72769 | Running loss: 1.01740\n",
      "Epoch: 2 | Iteration: 558 | Classification loss: 0.30084 | Regression loss: 0.66189 | Running loss: 1.01698\n",
      "Epoch: 2 | Iteration: 559 | Classification loss: 0.35010 | Regression loss: 0.49842 | Running loss: 1.01659\n",
      "Epoch: 2 | Iteration: 560 | Classification loss: 0.36207 | Regression loss: 0.59272 | Running loss: 1.01651\n",
      "Epoch: 2 | Iteration: 561 | Classification loss: 0.26471 | Regression loss: 0.52915 | Running loss: 1.01623\n",
      "Epoch: 2 | Iteration: 562 | Classification loss: 0.28524 | Regression loss: 0.66314 | Running loss: 1.01589\n",
      "Epoch: 2 | Iteration: 563 | Classification loss: 0.24077 | Regression loss: 0.54077 | Running loss: 1.01525\n",
      "Epoch: 2 | Iteration: 564 | Classification loss: 0.22553 | Regression loss: 0.58592 | Running loss: 1.01529\n",
      "Epoch: 2 | Iteration: 565 | Classification loss: 0.38857 | Regression loss: 0.76502 | Running loss: 1.01518\n",
      "Epoch: 2 | Iteration: 566 | Classification loss: 0.39376 | Regression loss: 0.63588 | Running loss: 1.01474\n",
      "Epoch: 2 | Iteration: 567 | Classification loss: 0.31443 | Regression loss: 0.64214 | Running loss: 1.01487\n",
      "Epoch: 2 | Iteration: 568 | Classification loss: 0.32252 | Regression loss: 0.72545 | Running loss: 1.01523\n",
      "Epoch: 2 | Iteration: 569 | Classification loss: 0.34855 | Regression loss: 0.68105 | Running loss: 1.01501\n",
      "Epoch: 2 | Iteration: 570 | Classification loss: 0.28605 | Regression loss: 0.66849 | Running loss: 1.01500\n",
      "Epoch: 2 | Iteration: 571 | Classification loss: 0.41965 | Regression loss: 0.45692 | Running loss: 1.01455\n",
      "Epoch: 2 | Iteration: 572 | Classification loss: 0.36006 | Regression loss: 0.67541 | Running loss: 1.01484\n",
      "Epoch: 2 | Iteration: 573 | Classification loss: 0.31589 | Regression loss: 0.72402 | Running loss: 1.01500\n",
      "Epoch: 2 | Iteration: 574 | Classification loss: 0.35879 | Regression loss: 0.57506 | Running loss: 1.01439\n",
      "Epoch: 2 | Iteration: 575 | Classification loss: 0.35267 | Regression loss: 0.77190 | Running loss: 1.01512\n",
      "Epoch: 2 | Iteration: 576 | Classification loss: 0.31880 | Regression loss: 0.65342 | Running loss: 1.01529\n",
      "Epoch: 2 | Iteration: 577 | Classification loss: 0.31578 | Regression loss: 0.75619 | Running loss: 1.01519\n",
      "Epoch: 2 | Iteration: 578 | Classification loss: 0.18567 | Regression loss: 0.48128 | Running loss: 1.01480\n",
      "Epoch: 2 | Iteration: 579 | Classification loss: 0.27320 | Regression loss: 0.63540 | Running loss: 1.01471\n",
      "Epoch: 2 | Iteration: 580 | Classification loss: 0.20828 | Regression loss: 0.57832 | Running loss: 1.01440\n",
      "Epoch: 2 | Iteration: 581 | Classification loss: 0.34502 | Regression loss: 0.62418 | Running loss: 1.01407\n",
      "Epoch: 2 | Iteration: 582 | Classification loss: 0.36800 | Regression loss: 0.74850 | Running loss: 1.01470\n",
      "Epoch: 2 | Iteration: 583 | Classification loss: 0.28022 | Regression loss: 0.54316 | Running loss: 1.01430\n",
      "Epoch: 2 | Iteration: 584 | Classification loss: 0.21856 | Regression loss: 0.53248 | Running loss: 1.01384\n",
      "Epoch: 2 | Iteration: 585 | Classification loss: 0.29694 | Regression loss: 0.58064 | Running loss: 1.01400\n",
      "Epoch: 2 | Iteration: 586 | Classification loss: 0.26187 | Regression loss: 0.67708 | Running loss: 1.01385\n",
      "Epoch: 2 | Iteration: 587 | Classification loss: 0.32176 | Regression loss: 0.66380 | Running loss: 1.01349\n",
      "Epoch: 2 | Iteration: 588 | Classification loss: 0.25610 | Regression loss: 0.61585 | Running loss: 1.01330\n",
      "Epoch: 2 | Iteration: 589 | Classification loss: 0.35362 | Regression loss: 0.64563 | Running loss: 1.01336\n",
      "Epoch: 2 | Iteration: 590 | Classification loss: 0.27841 | Regression loss: 0.66045 | Running loss: 1.01313\n",
      "Epoch: 2 | Iteration: 591 | Classification loss: 0.29486 | Regression loss: 0.67474 | Running loss: 1.01243\n",
      "Epoch: 2 | Iteration: 592 | Classification loss: 0.30758 | Regression loss: 0.56147 | Running loss: 1.01308\n",
      "Epoch: 2 | Iteration: 593 | Classification loss: 0.20345 | Regression loss: 0.58633 | Running loss: 1.01206\n",
      "Epoch: 2 | Iteration: 594 | Classification loss: 0.33106 | Regression loss: 0.66540 | Running loss: 1.01233\n",
      "Epoch: 2 | Iteration: 595 | Classification loss: 0.35499 | Regression loss: 0.73592 | Running loss: 1.01269\n",
      "Epoch: 2 | Iteration: 596 | Classification loss: 0.42781 | Regression loss: 0.68973 | Running loss: 1.01278\n",
      "Epoch: 2 | Iteration: 597 | Classification loss: 0.25168 | Regression loss: 0.60989 | Running loss: 1.01230\n",
      "Epoch: 2 | Iteration: 598 | Classification loss: 0.21432 | Regression loss: 0.62008 | Running loss: 1.01261\n",
      "Epoch: 2 | Iteration: 599 | Classification loss: 0.32888 | Regression loss: 0.69823 | Running loss: 1.01229\n",
      "Epoch: 2 | Iteration: 600 | Classification loss: 0.33347 | Regression loss: 0.73490 | Running loss: 1.01286\n",
      "Epoch: 2 | Iteration: 601 | Classification loss: 0.32651 | Regression loss: 0.72093 | Running loss: 1.01297\n",
      "Epoch: 2 | Iteration: 602 | Classification loss: 0.44771 | Regression loss: 0.70812 | Running loss: 1.01264\n",
      "Epoch: 2 | Iteration: 603 | Classification loss: 0.40942 | Regression loss: 0.71196 | Running loss: 1.01326\n",
      "Epoch: 2 | Iteration: 604 | Classification loss: 0.30443 | Regression loss: 0.69027 | Running loss: 1.01304\n",
      "Epoch: 2 | Iteration: 605 | Classification loss: 0.38559 | Regression loss: 0.34344 | Running loss: 1.01295\n",
      "Epoch: 2 | Iteration: 606 | Classification loss: 0.39165 | Regression loss: 0.75152 | Running loss: 1.01354\n",
      "Epoch: 2 | Iteration: 607 | Classification loss: 0.30106 | Regression loss: 0.64077 | Running loss: 1.01343\n",
      "Epoch: 2 | Iteration: 608 | Classification loss: 0.32694 | Regression loss: 0.76382 | Running loss: 1.01388\n",
      "Epoch: 2 | Iteration: 609 | Classification loss: 0.31964 | Regression loss: 0.71963 | Running loss: 1.01399\n",
      "Epoch: 2 | Iteration: 610 | Classification loss: 0.34901 | Regression loss: 0.67400 | Running loss: 1.01445\n",
      "Epoch: 2 | Iteration: 611 | Classification loss: 0.37765 | Regression loss: 0.76073 | Running loss: 1.01457\n",
      "Epoch: 2 | Iteration: 612 | Classification loss: 0.33380 | Regression loss: 0.73168 | Running loss: 1.01495\n",
      "Epoch: 2 | Iteration: 613 | Classification loss: 0.32012 | Regression loss: 0.69156 | Running loss: 1.01467\n",
      "Epoch: 2 | Iteration: 614 | Classification loss: 0.45458 | Regression loss: 0.77330 | Running loss: 1.01504\n",
      "Epoch: 2 | Iteration: 615 | Classification loss: 0.31830 | Regression loss: 0.74662 | Running loss: 1.01507\n",
      "Epoch: 2 | Iteration: 616 | Classification loss: 0.38167 | Regression loss: 0.75530 | Running loss: 1.01530\n",
      "Epoch: 2 | Iteration: 617 | Classification loss: 0.25778 | Regression loss: 0.51619 | Running loss: 1.01479\n",
      "Epoch: 2 | Iteration: 618 | Classification loss: 0.31789 | Regression loss: 0.66044 | Running loss: 1.01521\n",
      "Epoch: 2 | Iteration: 619 | Classification loss: 0.27587 | Regression loss: 0.60434 | Running loss: 1.01509\n",
      "Epoch: 2 | Iteration: 620 | Classification loss: 0.20988 | Regression loss: 0.44734 | Running loss: 1.01445\n",
      "Epoch: 2 | Iteration: 621 | Classification loss: 0.28667 | Regression loss: 0.59887 | Running loss: 1.01404\n",
      "Epoch: 2 | Iteration: 622 | Classification loss: 0.35025 | Regression loss: 0.68439 | Running loss: 1.01360\n",
      "Epoch: 2 | Iteration: 623 | Classification loss: 0.26621 | Regression loss: 0.57518 | Running loss: 1.01353\n",
      "Epoch: 2 | Iteration: 624 | Classification loss: 0.33503 | Regression loss: 0.70398 | Running loss: 1.01370\n",
      "Epoch: 2 | Iteration: 625 | Classification loss: 0.32423 | Regression loss: 0.70233 | Running loss: 1.01350\n",
      "Epoch: 2 | Iteration: 626 | Classification loss: 0.20975 | Regression loss: 0.58857 | Running loss: 1.01273\n",
      "Epoch: 2 | Iteration: 627 | Classification loss: 0.30382 | Regression loss: 0.81494 | Running loss: 1.01307\n",
      "Epoch: 2 | Iteration: 628 | Classification loss: 0.27625 | Regression loss: 0.61389 | Running loss: 1.01234\n",
      "Epoch: 2 | Iteration: 629 | Classification loss: 0.23281 | Regression loss: 0.61641 | Running loss: 1.01179\n",
      "Epoch: 2 | Iteration: 630 | Classification loss: 0.44117 | Regression loss: 0.76179 | Running loss: 1.01204\n",
      "Epoch: 2 | Iteration: 631 | Classification loss: 0.30590 | Regression loss: 0.69617 | Running loss: 1.01129\n",
      "Epoch: 2 | Iteration: 632 | Classification loss: 0.89736 | Regression loss: 0.67283 | Running loss: 1.01226\n",
      "Epoch: 2 | Iteration: 633 | Classification loss: 0.30695 | Regression loss: 0.66747 | Running loss: 1.01276\n",
      "Epoch: 2 | Iteration: 634 | Classification loss: 0.35400 | Regression loss: 0.72260 | Running loss: 1.01318\n",
      "Epoch: 2 | Iteration: 635 | Classification loss: 0.43408 | Regression loss: 0.58833 | Running loss: 1.01314\n",
      "Epoch: 2 | Iteration: 636 | Classification loss: 0.25136 | Regression loss: 0.55837 | Running loss: 1.01256\n",
      "Epoch: 2 | Iteration: 637 | Classification loss: 0.37393 | Regression loss: 0.77919 | Running loss: 1.01301\n",
      "Epoch: 2 | Iteration: 638 | Classification loss: 0.27234 | Regression loss: 0.60038 | Running loss: 1.01255\n",
      "Epoch: 2 | Iteration: 639 | Classification loss: 0.25647 | Regression loss: 0.58268 | Running loss: 1.01241\n",
      "Epoch: 2 | Iteration: 640 | Classification loss: 0.50506 | Regression loss: 0.80311 | Running loss: 1.01343\n",
      "Epoch: 2 | Iteration: 641 | Classification loss: 0.44130 | Regression loss: 0.67319 | Running loss: 1.01357\n",
      "Epoch: 2 | Iteration: 642 | Classification loss: 0.33281 | Regression loss: 0.68473 | Running loss: 1.01370\n",
      "Epoch: 2 | Iteration: 643 | Classification loss: 0.34434 | Regression loss: 0.99964 | Running loss: 1.01473\n",
      "Epoch: 2 | Iteration: 644 | Classification loss: 0.27759 | Regression loss: 0.57777 | Running loss: 1.01436\n",
      "Epoch: 2 | Iteration: 645 | Classification loss: 0.21411 | Regression loss: 0.49696 | Running loss: 1.01377\n",
      "Epoch: 2 | Iteration: 646 | Classification loss: 0.36582 | Regression loss: 0.78218 | Running loss: 1.01421\n",
      "Epoch: 2 | Iteration: 647 | Classification loss: 0.43663 | Regression loss: 0.76021 | Running loss: 1.01414\n",
      "Epoch: 2 | Iteration: 648 | Classification loss: 0.37290 | Regression loss: 0.73467 | Running loss: 1.01494\n",
      "Epoch: 2 | Iteration: 649 | Classification loss: 0.30612 | Regression loss: 0.75457 | Running loss: 1.01531\n",
      "Epoch: 2 | Iteration: 650 | Classification loss: 0.30543 | Regression loss: 0.67259 | Running loss: 1.01556\n",
      "Epoch: 2 | Iteration: 651 | Classification loss: 0.40836 | Regression loss: 0.72970 | Running loss: 1.01577\n",
      "Epoch: 2 | Iteration: 652 | Classification loss: 0.26625 | Regression loss: 0.53830 | Running loss: 1.01534\n",
      "Epoch: 2 | Iteration: 653 | Classification loss: 0.31010 | Regression loss: 0.63729 | Running loss: 1.01525\n",
      "Epoch: 2 | Iteration: 654 | Classification loss: 0.29244 | Regression loss: 0.68578 | Running loss: 1.01543\n",
      "Epoch: 2 | Iteration: 655 | Classification loss: 0.32363 | Regression loss: 0.66002 | Running loss: 1.01538\n",
      "Epoch: 2 | Iteration: 656 | Classification loss: 0.29705 | Regression loss: 0.66126 | Running loss: 1.01562\n",
      "Epoch: 2 | Iteration: 657 | Classification loss: 0.32638 | Regression loss: 0.66654 | Running loss: 1.01559\n",
      "Epoch: 2 | Iteration: 658 | Classification loss: 0.46495 | Regression loss: 0.79844 | Running loss: 1.01616\n",
      "Epoch: 2 | Iteration: 659 | Classification loss: 0.36071 | Regression loss: 0.72915 | Running loss: 1.01611\n",
      "Epoch: 2 | Iteration: 660 | Classification loss: 0.38136 | Regression loss: 0.66446 | Running loss: 1.01658\n",
      "Epoch: 2 | Iteration: 661 | Classification loss: 0.37676 | Regression loss: 0.81530 | Running loss: 1.01670\n",
      "Epoch: 2 | Iteration: 662 | Classification loss: 0.33511 | Regression loss: 0.80265 | Running loss: 1.01730\n",
      "Epoch: 2 | Iteration: 663 | Classification loss: 0.36253 | Regression loss: 0.54705 | Running loss: 1.01686\n",
      "Epoch: 2 | Iteration: 664 | Classification loss: 0.35310 | Regression loss: 0.73652 | Running loss: 1.01661\n",
      "Epoch: 2 | Iteration: 665 | Classification loss: 0.29601 | Regression loss: 0.63392 | Running loss: 1.01650\n",
      "Epoch: 2 | Iteration: 666 | Classification loss: 0.33596 | Regression loss: 0.62246 | Running loss: 1.01605\n",
      "Epoch: 2 | Iteration: 667 | Classification loss: 0.44888 | Regression loss: 0.83055 | Running loss: 1.01646\n",
      "Epoch: 2 | Iteration: 668 | Classification loss: 0.28143 | Regression loss: 0.62675 | Running loss: 1.01644\n",
      "Epoch: 2 | Iteration: 669 | Classification loss: 0.34862 | Regression loss: 0.70605 | Running loss: 1.01576\n",
      "Epoch: 2 | Iteration: 670 | Classification loss: 0.37250 | Regression loss: 0.71256 | Running loss: 1.01587\n",
      "Epoch: 2 | Iteration: 671 | Classification loss: 0.41088 | Regression loss: 0.80965 | Running loss: 1.01592\n",
      "Epoch: 2 | Iteration: 672 | Classification loss: 0.37791 | Regression loss: 0.78206 | Running loss: 1.01592\n",
      "Epoch: 2 | Iteration: 673 | Classification loss: 0.34571 | Regression loss: 0.66646 | Running loss: 1.01544\n",
      "Epoch: 2 | Iteration: 674 | Classification loss: 0.42330 | Regression loss: 0.83509 | Running loss: 1.01575\n",
      "Epoch: 2 | Iteration: 675 | Classification loss: 0.31689 | Regression loss: 0.65432 | Running loss: 1.01504\n",
      "Epoch: 2 | Iteration: 676 | Classification loss: 0.41511 | Regression loss: 0.76195 | Running loss: 1.01462\n",
      "Epoch: 2 | Iteration: 677 | Classification loss: 0.23371 | Regression loss: 0.64641 | Running loss: 1.01439\n",
      "Epoch: 2 | Iteration: 678 | Classification loss: 0.25812 | Regression loss: 0.64892 | Running loss: 1.01420\n",
      "Epoch: 2 | Iteration: 679 | Classification loss: 0.22224 | Regression loss: 0.56214 | Running loss: 1.01365\n",
      "Epoch: 2 | Iteration: 680 | Classification loss: 0.29971 | Regression loss: 0.66972 | Running loss: 1.01360\n",
      "Epoch: 2 | Iteration: 681 | Classification loss: 0.25120 | Regression loss: 0.65380 | Running loss: 1.01331\n",
      "Epoch: 2 | Iteration: 682 | Classification loss: 0.38715 | Regression loss: 0.64691 | Running loss: 1.01375\n",
      "Epoch: 2 | Iteration: 683 | Classification loss: 0.28320 | Regression loss: 0.62134 | Running loss: 1.01338\n",
      "Epoch: 2 | Iteration: 684 | Classification loss: 0.33416 | Regression loss: 0.66749 | Running loss: 1.01383\n",
      "Epoch: 2 | Iteration: 685 | Classification loss: 0.27530 | Regression loss: 0.68563 | Running loss: 1.01415\n",
      "Epoch: 2 | Iteration: 686 | Classification loss: 0.28378 | Regression loss: 0.75220 | Running loss: 1.01400\n",
      "Epoch: 2 | Iteration: 687 | Classification loss: 0.33373 | Regression loss: 0.78549 | Running loss: 1.01476\n",
      "Epoch: 2 | Iteration: 688 | Classification loss: 0.35723 | Regression loss: 0.85208 | Running loss: 1.01536\n",
      "Epoch: 2 | Iteration: 689 | Classification loss: 0.37190 | Regression loss: 0.71567 | Running loss: 1.01549\n",
      "Epoch: 2 | Iteration: 690 | Classification loss: 0.27508 | Regression loss: 0.76944 | Running loss: 1.01495\n",
      "Epoch: 2 | Iteration: 691 | Classification loss: 0.26385 | Regression loss: 0.58027 | Running loss: 1.01440\n",
      "Epoch: 2 | Iteration: 692 | Classification loss: 0.33385 | Regression loss: 0.65710 | Running loss: 1.01437\n",
      "Epoch: 2 | Iteration: 693 | Classification loss: 0.35190 | Regression loss: 0.73034 | Running loss: 1.01454\n",
      "Epoch: 2 | Iteration: 694 | Classification loss: 0.37114 | Regression loss: 0.69142 | Running loss: 1.01496\n",
      "Epoch: 2 | Iteration: 695 | Classification loss: 0.39836 | Regression loss: 0.73727 | Running loss: 1.01491\n",
      "Epoch: 2 | Iteration: 696 | Classification loss: 0.43710 | Regression loss: 0.83453 | Running loss: 1.01526\n",
      "Epoch: 2 | Iteration: 697 | Classification loss: 0.35260 | Regression loss: 0.71255 | Running loss: 1.01511\n",
      "Epoch: 2 | Iteration: 698 | Classification loss: 0.21508 | Regression loss: 0.55730 | Running loss: 1.01405\n",
      "Epoch: 2 | Iteration: 699 | Classification loss: 0.39579 | Regression loss: 0.70146 | Running loss: 1.01408\n",
      "Epoch: 2 | Iteration: 700 | Classification loss: 0.42153 | Regression loss: 0.67695 | Running loss: 1.01434\n",
      "Epoch: 2 | Iteration: 701 | Classification loss: 0.34922 | Regression loss: 0.73182 | Running loss: 1.01415\n",
      "Epoch: 2 | Iteration: 702 | Classification loss: 0.43002 | Regression loss: 0.58343 | Running loss: 1.01394\n",
      "Epoch: 2 | Iteration: 703 | Classification loss: 0.36639 | Regression loss: 0.74267 | Running loss: 1.01409\n",
      "Epoch: 2 | Iteration: 704 | Classification loss: 0.36326 | Regression loss: 0.75908 | Running loss: 1.01398\n",
      "Epoch: 2 | Iteration: 705 | Classification loss: 0.39576 | Regression loss: 0.80686 | Running loss: 1.01370\n",
      "Epoch: 2 | Iteration: 706 | Classification loss: 0.29598 | Regression loss: 0.64500 | Running loss: 1.01369\n",
      "Epoch: 2 | Iteration: 707 | Classification loss: 0.42187 | Regression loss: 0.67172 | Running loss: 1.01380\n",
      "Epoch: 2 | Iteration: 708 | Classification loss: 0.22619 | Regression loss: 0.47149 | Running loss: 1.01301\n",
      "Epoch: 2 | Iteration: 709 | Classification loss: 0.31615 | Regression loss: 0.71824 | Running loss: 1.01285\n",
      "Epoch: 2 | Iteration: 710 | Classification loss: 0.54800 | Regression loss: 0.60060 | Running loss: 1.01323\n",
      "Epoch: 2 | Iteration: 711 | Classification loss: 0.27537 | Regression loss: 0.64737 | Running loss: 1.01262\n",
      "Epoch: 2 | Iteration: 712 | Classification loss: 0.25639 | Regression loss: 0.59848 | Running loss: 1.01213\n",
      "Epoch: 2 | Iteration: 713 | Classification loss: 0.31294 | Regression loss: 0.73531 | Running loss: 1.01169\n",
      "Epoch: 2 | Iteration: 714 | Classification loss: 0.21687 | Regression loss: 0.50280 | Running loss: 1.01075\n",
      "Epoch: 2 | Iteration: 715 | Classification loss: 0.27115 | Regression loss: 0.67949 | Running loss: 1.01053\n",
      "Epoch: 2 | Iteration: 716 | Classification loss: 0.38155 | Regression loss: 0.69655 | Running loss: 1.01077\n",
      "Epoch: 2 | Iteration: 717 | Classification loss: 0.33335 | Regression loss: 0.76555 | Running loss: 1.01083\n",
      "Epoch: 2 | Iteration: 718 | Classification loss: 0.25567 | Regression loss: 0.63444 | Running loss: 1.01025\n",
      "Epoch: 2 | Iteration: 719 | Classification loss: 0.33837 | Regression loss: 0.74967 | Running loss: 1.01073\n",
      "Epoch: 2 | Iteration: 720 | Classification loss: 0.35136 | Regression loss: 0.73040 | Running loss: 1.01088\n",
      "Epoch: 2 | Iteration: 721 | Classification loss: 0.29510 | Regression loss: 0.69729 | Running loss: 1.01086\n",
      "Epoch: 2 | Iteration: 722 | Classification loss: 0.30030 | Regression loss: 0.63652 | Running loss: 1.01072\n",
      "Epoch: 2 | Iteration: 723 | Classification loss: 0.40920 | Regression loss: 0.71343 | Running loss: 1.01102\n",
      "Epoch: 2 | Iteration: 724 | Classification loss: 0.44875 | Regression loss: 0.73553 | Running loss: 1.01123\n",
      "Epoch: 2 | Iteration: 725 | Classification loss: 0.20401 | Regression loss: 0.63716 | Running loss: 1.01072\n",
      "Epoch: 2 | Iteration: 726 | Classification loss: 0.24393 | Regression loss: 0.55391 | Running loss: 1.01042\n",
      "Epoch: 2 | Iteration: 727 | Classification loss: 0.33103 | Regression loss: 0.70142 | Running loss: 1.01055\n",
      "Epoch: 2 | Iteration: 728 | Classification loss: 0.32682 | Regression loss: 0.64866 | Running loss: 1.01079\n",
      "Epoch: 2 | Iteration: 729 | Classification loss: 0.27824 | Regression loss: 0.58618 | Running loss: 1.01050\n",
      "Epoch: 2 | Iteration: 730 | Classification loss: 0.39528 | Regression loss: 0.65065 | Running loss: 1.01043\n",
      "Epoch: 2 | Iteration: 731 | Classification loss: 0.35985 | Regression loss: 0.82474 | Running loss: 1.01017\n",
      "Epoch: 2 | Iteration: 732 | Classification loss: 0.38604 | Regression loss: 0.81340 | Running loss: 1.01010\n",
      "Epoch: 2 | Iteration: 733 | Classification loss: 0.26625 | Regression loss: 0.62770 | Running loss: 1.00977\n",
      "Epoch: 2 | Iteration: 734 | Classification loss: 0.32667 | Regression loss: 0.56516 | Running loss: 1.00954\n",
      "Epoch: 2 | Iteration: 735 | Classification loss: 0.39426 | Regression loss: 0.75431 | Running loss: 1.00850\n",
      "Epoch: 2 | Iteration: 736 | Classification loss: 0.34118 | Regression loss: 0.67228 | Running loss: 1.00902\n",
      "Epoch: 2 | Iteration: 737 | Classification loss: 0.30742 | Regression loss: 0.71895 | Running loss: 1.00873\n",
      "Epoch: 2 | Iteration: 738 | Classification loss: 0.23688 | Regression loss: 0.62279 | Running loss: 1.00788\n",
      "Epoch: 2 | Iteration: 739 | Classification loss: 0.36311 | Regression loss: 0.79211 | Running loss: 1.00837\n",
      "Epoch: 2 | Iteration: 740 | Classification loss: 0.23725 | Regression loss: 0.64486 | Running loss: 1.00779\n",
      "Epoch: 2 | Iteration: 741 | Classification loss: 0.39164 | Regression loss: 0.73956 | Running loss: 1.00804\n",
      "Epoch: 2 | Iteration: 742 | Classification loss: 0.35349 | Regression loss: 0.67531 | Running loss: 1.00853\n",
      "Epoch: 2 | Iteration: 743 | Classification loss: 0.32962 | Regression loss: 0.63491 | Running loss: 1.00821\n",
      "Epoch: 2 | Iteration: 744 | Classification loss: 0.32995 | Regression loss: 0.76017 | Running loss: 1.00858\n",
      "Epoch: 2 | Iteration: 745 | Classification loss: 0.26707 | Regression loss: 0.61187 | Running loss: 1.00894\n",
      "Epoch: 2 | Iteration: 746 | Classification loss: 0.32160 | Regression loss: 0.64817 | Running loss: 1.00868\n",
      "Epoch: 2 | Iteration: 747 | Classification loss: 0.28617 | Regression loss: 0.66218 | Running loss: 1.00848\n",
      "Epoch: 2 | Iteration: 748 | Classification loss: 0.32817 | Regression loss: 0.67408 | Running loss: 1.00866\n",
      "Epoch: 2 | Iteration: 749 | Classification loss: 0.22104 | Regression loss: 0.71094 | Running loss: 1.00875\n",
      "Epoch: 2 | Iteration: 750 | Classification loss: 0.43934 | Regression loss: 0.70426 | Running loss: 1.00887\n",
      "Epoch: 2 | Iteration: 751 | Classification loss: 0.31954 | Regression loss: 0.64682 | Running loss: 1.00928\n",
      "Epoch: 2 | Iteration: 752 | Classification loss: 0.31840 | Regression loss: 0.60700 | Running loss: 1.00862\n",
      "Epoch: 2 | Iteration: 753 | Classification loss: 0.29412 | Regression loss: 0.68688 | Running loss: 1.00854\n",
      "Epoch: 2 | Iteration: 754 | Classification loss: 0.37256 | Regression loss: 0.77689 | Running loss: 1.00882\n",
      "Epoch: 2 | Iteration: 755 | Classification loss: 0.35114 | Regression loss: 0.73065 | Running loss: 1.00851\n",
      "Epoch: 2 | Iteration: 756 | Classification loss: 0.23522 | Regression loss: 0.61096 | Running loss: 1.00824\n",
      "Epoch: 2 | Iteration: 757 | Classification loss: 0.28576 | Regression loss: 0.71852 | Running loss: 1.00814\n",
      "Epoch: 2 | Iteration: 758 | Classification loss: 0.39329 | Regression loss: 0.74407 | Running loss: 1.00879\n",
      "Epoch: 2 | Iteration: 759 | Classification loss: 0.27072 | Regression loss: 0.55283 | Running loss: 1.00857\n",
      "Epoch: 2 | Iteration: 760 | Classification loss: 0.28636 | Regression loss: 0.78198 | Running loss: 1.00845\n",
      "Epoch: 2 | Iteration: 761 | Classification loss: 0.31129 | Regression loss: 0.62161 | Running loss: 1.00808\n",
      "Epoch: 2 | Iteration: 762 | Classification loss: 0.30483 | Regression loss: 0.78085 | Running loss: 1.00876\n",
      "Epoch: 2 | Iteration: 763 | Classification loss: 0.17878 | Regression loss: 0.39652 | Running loss: 1.00814\n",
      "Epoch: 2 | Iteration: 764 | Classification loss: 0.48974 | Regression loss: 0.57079 | Running loss: 1.00782\n",
      "Epoch: 2 | Iteration: 765 | Classification loss: 0.26602 | Regression loss: 0.64978 | Running loss: 1.00784\n",
      "Epoch: 2 | Iteration: 766 | Classification loss: 0.26999 | Regression loss: 0.66367 | Running loss: 1.00761\n",
      "Epoch: 2 | Iteration: 767 | Classification loss: 0.26130 | Regression loss: 0.65515 | Running loss: 1.00743\n",
      "Epoch: 2 | Iteration: 768 | Classification loss: 0.20735 | Regression loss: 0.52631 | Running loss: 1.00678\n",
      "Epoch: 2 | Iteration: 769 | Classification loss: 0.33947 | Regression loss: 0.68258 | Running loss: 1.00676\n",
      "Epoch: 2 | Iteration: 770 | Classification loss: 0.30784 | Regression loss: 0.60579 | Running loss: 1.00667\n",
      "Epoch: 2 | Iteration: 771 | Classification loss: 0.29914 | Regression loss: 0.63131 | Running loss: 1.00703\n",
      "Epoch: 2 | Iteration: 772 | Classification loss: 0.38473 | Regression loss: 0.78642 | Running loss: 1.00740\n",
      "Epoch: 2 | Iteration: 773 | Classification loss: 0.27935 | Regression loss: 0.61957 | Running loss: 1.00744\n",
      "Epoch: 2 | Iteration: 774 | Classification loss: 0.16945 | Regression loss: 0.44083 | Running loss: 1.00713\n",
      "Epoch: 2 | Iteration: 775 | Classification loss: 0.20623 | Regression loss: 0.53233 | Running loss: 1.00663\n",
      "Epoch: 2 | Iteration: 776 | Classification loss: 0.48021 | Regression loss: 0.68518 | Running loss: 1.00730\n",
      "Epoch: 2 | Iteration: 777 | Classification loss: 0.25883 | Regression loss: 0.60005 | Running loss: 1.00683\n",
      "Epoch: 2 | Iteration: 778 | Classification loss: 0.31630 | Regression loss: 0.70623 | Running loss: 1.00734\n",
      "Epoch: 2 | Iteration: 779 | Classification loss: 0.31298 | Regression loss: 0.61336 | Running loss: 1.00720\n",
      "Epoch: 2 | Iteration: 780 | Classification loss: 0.25713 | Regression loss: 0.57158 | Running loss: 1.00734\n",
      "Epoch: 2 | Iteration: 781 | Classification loss: 0.25158 | Regression loss: 0.61633 | Running loss: 1.00675\n",
      "Epoch: 2 | Iteration: 782 | Classification loss: 0.35139 | Regression loss: 0.75584 | Running loss: 1.00673\n",
      "Epoch: 2 | Iteration: 783 | Classification loss: 0.28399 | Regression loss: 0.71022 | Running loss: 1.00672\n",
      "Evaluating dataset\n",
      "\n",
      "mAP:\n",
      "person: 0.3730510354506985\n",
      "Precision:  0.054169125706095604\n",
      "Recall:  0.7296990346394094\n",
      "car: 0.47542724423450144\n",
      "Precision:  0.054169125706095604\n",
      "Recall:  0.7296990346394094\n",
      "Epoch: 3 | Iteration: 0 | Classification loss: 0.38183 | Regression loss: 0.62987 | Running loss: 1.00705\n",
      "Epoch: 3 | Iteration: 1 | Classification loss: 0.29583 | Regression loss: 0.68377 | Running loss: 1.00678\n",
      "Epoch: 3 | Iteration: 2 | Classification loss: 0.26846 | Regression loss: 0.57693 | Running loss: 1.00603\n",
      "Epoch: 3 | Iteration: 3 | Classification loss: 0.36844 | Regression loss: 0.67133 | Running loss: 1.00607\n",
      "Epoch: 3 | Iteration: 4 | Classification loss: 0.36396 | Regression loss: 0.65813 | Running loss: 1.00598\n",
      "Epoch: 3 | Iteration: 5 | Classification loss: 0.32423 | Regression loss: 0.73332 | Running loss: 1.00633\n",
      "Epoch: 3 | Iteration: 6 | Classification loss: 0.35691 | Regression loss: 0.66616 | Running loss: 1.00606\n",
      "Epoch: 3 | Iteration: 7 | Classification loss: 0.30242 | Regression loss: 0.66662 | Running loss: 1.00585\n",
      "Epoch: 3 | Iteration: 8 | Classification loss: 0.47397 | Regression loss: 0.78345 | Running loss: 1.00636\n",
      "Epoch: 3 | Iteration: 9 | Classification loss: 0.24099 | Regression loss: 0.64329 | Running loss: 1.00622\n",
      "Epoch: 3 | Iteration: 10 | Classification loss: 0.26673 | Regression loss: 0.70059 | Running loss: 1.00615\n",
      "Epoch: 3 | Iteration: 11 | Classification loss: 0.20257 | Regression loss: 0.56375 | Running loss: 1.00560\n",
      "Epoch: 3 | Iteration: 12 | Classification loss: 0.41081 | Regression loss: 0.75497 | Running loss: 1.00584\n",
      "Epoch: 3 | Iteration: 13 | Classification loss: 0.32201 | Regression loss: 0.69079 | Running loss: 1.00588\n",
      "Epoch: 3 | Iteration: 14 | Classification loss: 0.25406 | Regression loss: 0.58719 | Running loss: 1.00625\n",
      "Epoch: 3 | Iteration: 15 | Classification loss: 0.33662 | Regression loss: 0.74137 | Running loss: 1.00655\n",
      "Epoch: 3 | Iteration: 16 | Classification loss: 0.28523 | Regression loss: 0.64890 | Running loss: 1.00613\n",
      "Epoch: 3 | Iteration: 17 | Classification loss: 0.26548 | Regression loss: 0.65251 | Running loss: 1.00617\n",
      "Epoch: 3 | Iteration: 18 | Classification loss: 0.31151 | Regression loss: 0.69550 | Running loss: 1.00625\n",
      "Epoch: 3 | Iteration: 19 | Classification loss: 0.31665 | Regression loss: 0.69650 | Running loss: 1.00560\n",
      "Epoch: 3 | Iteration: 20 | Classification loss: 0.42867 | Regression loss: 0.76200 | Running loss: 1.00627\n",
      "Epoch: 3 | Iteration: 21 | Classification loss: 0.21372 | Regression loss: 0.63450 | Running loss: 1.00590\n",
      "Epoch: 3 | Iteration: 22 | Classification loss: 0.37788 | Regression loss: 0.43447 | Running loss: 1.00541\n",
      "Epoch: 3 | Iteration: 23 | Classification loss: 0.36676 | Regression loss: 0.69838 | Running loss: 1.00574\n",
      "Epoch: 3 | Iteration: 24 | Classification loss: 0.30264 | Regression loss: 0.71650 | Running loss: 1.00564\n",
      "Epoch: 3 | Iteration: 25 | Classification loss: 0.55593 | Regression loss: 0.52516 | Running loss: 1.00560\n",
      "Epoch: 3 | Iteration: 26 | Classification loss: 0.23134 | Regression loss: 0.60461 | Running loss: 1.00491\n",
      "Epoch: 3 | Iteration: 27 | Classification loss: 0.28912 | Regression loss: 0.61501 | Running loss: 1.00484\n",
      "Epoch: 3 | Iteration: 28 | Classification loss: 0.33329 | Regression loss: 0.73962 | Running loss: 1.00523\n",
      "Epoch: 3 | Iteration: 29 | Classification loss: 0.33722 | Regression loss: 0.62069 | Running loss: 1.00508\n",
      "Epoch: 3 | Iteration: 30 | Classification loss: 0.15716 | Regression loss: 0.34785 | Running loss: 1.00404\n",
      "Epoch: 3 | Iteration: 31 | Classification loss: 0.32822 | Regression loss: 0.77865 | Running loss: 1.00470\n",
      "Epoch: 3 | Iteration: 32 | Classification loss: 0.30007 | Regression loss: 0.71707 | Running loss: 1.00454\n",
      "Epoch: 3 | Iteration: 33 | Classification loss: 0.29529 | Regression loss: 0.76720 | Running loss: 1.00513\n",
      "Epoch: 3 | Iteration: 34 | Classification loss: 0.25083 | Regression loss: 0.57693 | Running loss: 1.00478\n",
      "Epoch: 3 | Iteration: 35 | Classification loss: 0.33504 | Regression loss: 0.66226 | Running loss: 1.00443\n",
      "Epoch: 3 | Iteration: 36 | Classification loss: 0.25313 | Regression loss: 0.62782 | Running loss: 1.00407\n",
      "Epoch: 3 | Iteration: 37 | Classification loss: 0.22481 | Regression loss: 0.62461 | Running loss: 1.00388\n",
      "Epoch: 3 | Iteration: 38 | Classification loss: 0.30238 | Regression loss: 0.52933 | Running loss: 1.00291\n",
      "Epoch: 3 | Iteration: 39 | Classification loss: 0.17892 | Regression loss: 0.54219 | Running loss: 1.00255\n",
      "Epoch: 3 | Iteration: 40 | Classification loss: 0.35491 | Regression loss: 0.78502 | Running loss: 1.00290\n",
      "Epoch: 3 | Iteration: 41 | Classification loss: 0.29103 | Regression loss: 0.62498 | Running loss: 1.00270\n",
      "Epoch: 3 | Iteration: 42 | Classification loss: 0.20305 | Regression loss: 0.51027 | Running loss: 1.00253\n",
      "Epoch: 3 | Iteration: 43 | Classification loss: 0.27474 | Regression loss: 0.61141 | Running loss: 1.00205\n",
      "Epoch: 3 | Iteration: 44 | Classification loss: 0.30983 | Regression loss: 0.74248 | Running loss: 1.00206\n",
      "Epoch: 3 | Iteration: 45 | Classification loss: 0.42222 | Regression loss: 0.77819 | Running loss: 1.00213\n",
      "Epoch: 3 | Iteration: 46 | Classification loss: 0.23452 | Regression loss: 0.61692 | Running loss: 1.00210\n",
      "Epoch: 3 | Iteration: 47 | Classification loss: 0.37775 | Regression loss: 0.75810 | Running loss: 1.00202\n",
      "Epoch: 3 | Iteration: 48 | Classification loss: 0.18483 | Regression loss: 0.48100 | Running loss: 1.00114\n",
      "Epoch: 3 | Iteration: 49 | Classification loss: 0.28973 | Regression loss: 0.69172 | Running loss: 1.00111\n",
      "Epoch: 3 | Iteration: 50 | Classification loss: 0.26168 | Regression loss: 0.66347 | Running loss: 1.00108\n",
      "Epoch: 3 | Iteration: 51 | Classification loss: 0.18175 | Regression loss: 0.50856 | Running loss: 1.00064\n",
      "Epoch: 3 | Iteration: 52 | Classification loss: 0.22053 | Regression loss: 0.63067 | Running loss: 1.00032\n",
      "Epoch: 3 | Iteration: 53 | Classification loss: 0.30233 | Regression loss: 0.77010 | Running loss: 0.99981\n",
      "Epoch: 3 | Iteration: 54 | Classification loss: 0.23483 | Regression loss: 0.43617 | Running loss: 0.99940\n",
      "Epoch: 3 | Iteration: 55 | Classification loss: 0.32210 | Regression loss: 0.65707 | Running loss: 0.99949\n",
      "Epoch: 3 | Iteration: 56 | Classification loss: 0.36794 | Regression loss: 0.70809 | Running loss: 0.99974\n",
      "Epoch: 3 | Iteration: 57 | Classification loss: 0.28239 | Regression loss: 0.49055 | Running loss: 0.99914\n",
      "Epoch: 3 | Iteration: 58 | Classification loss: 0.29534 | Regression loss: 0.57795 | Running loss: 0.99902\n",
      "Epoch: 3 | Iteration: 59 | Classification loss: 0.29956 | Regression loss: 0.63234 | Running loss: 0.99887\n",
      "Epoch: 3 | Iteration: 60 | Classification loss: 0.48177 | Regression loss: 0.69668 | Running loss: 0.99876\n",
      "Epoch: 3 | Iteration: 61 | Classification loss: 0.27395 | Regression loss: 0.66595 | Running loss: 0.99872\n",
      "Epoch: 3 | Iteration: 62 | Classification loss: 0.20394 | Regression loss: 0.49010 | Running loss: 0.99780\n",
      "Epoch: 3 | Iteration: 63 | Classification loss: 0.26926 | Regression loss: 0.68106 | Running loss: 0.99782\n",
      "Epoch: 3 | Iteration: 64 | Classification loss: 0.29089 | Regression loss: 0.65343 | Running loss: 0.99785\n",
      "Epoch: 3 | Iteration: 65 | Classification loss: 0.30606 | Regression loss: 0.69207 | Running loss: 0.99757\n",
      "Epoch: 3 | Iteration: 66 | Classification loss: 0.31490 | Regression loss: 0.61209 | Running loss: 0.99737\n",
      "Epoch: 3 | Iteration: 67 | Classification loss: 0.43326 | Regression loss: 0.82995 | Running loss: 0.99784\n",
      "Epoch: 3 | Iteration: 68 | Classification loss: 0.38741 | Regression loss: 0.74952 | Running loss: 0.99811\n",
      "Epoch: 3 | Iteration: 69 | Classification loss: 0.29675 | Regression loss: 0.50397 | Running loss: 0.99806\n",
      "Epoch: 3 | Iteration: 70 | Classification loss: 0.24154 | Regression loss: 0.50491 | Running loss: 0.99770\n",
      "Epoch: 3 | Iteration: 71 | Classification loss: 0.28245 | Regression loss: 0.61901 | Running loss: 0.99709\n",
      "Epoch: 3 | Iteration: 72 | Classification loss: 0.24614 | Regression loss: 0.67888 | Running loss: 0.99690\n",
      "Epoch: 3 | Iteration: 73 | Classification loss: 0.36651 | Regression loss: 0.56743 | Running loss: 0.99509\n",
      "Epoch: 3 | Iteration: 74 | Classification loss: 0.25654 | Regression loss: 0.61248 | Running loss: 0.99507\n",
      "Epoch: 3 | Iteration: 75 | Classification loss: 0.38030 | Regression loss: 0.58126 | Running loss: 0.99493\n",
      "Epoch: 3 | Iteration: 76 | Classification loss: 0.21090 | Regression loss: 0.55495 | Running loss: 0.99419\n",
      "Epoch: 3 | Iteration: 77 | Classification loss: 0.47531 | Regression loss: 0.76012 | Running loss: 0.99445\n",
      "Epoch: 3 | Iteration: 78 | Classification loss: 0.40201 | Regression loss: 0.84462 | Running loss: 0.99532\n",
      "Epoch: 3 | Iteration: 79 | Classification loss: 0.29191 | Regression loss: 0.59877 | Running loss: 0.99462\n",
      "Epoch: 3 | Iteration: 80 | Classification loss: 0.28839 | Regression loss: 0.71225 | Running loss: 0.99471\n",
      "Epoch: 3 | Iteration: 81 | Classification loss: 0.24345 | Regression loss: 0.63045 | Running loss: 0.99444\n",
      "Epoch: 3 | Iteration: 82 | Classification loss: 0.54289 | Regression loss: 0.70658 | Running loss: 0.99503\n",
      "Epoch: 3 | Iteration: 83 | Classification loss: 0.31935 | Regression loss: 0.69593 | Running loss: 0.99508\n",
      "Epoch: 3 | Iteration: 84 | Classification loss: 0.26960 | Regression loss: 0.59706 | Running loss: 0.99443\n",
      "Epoch: 3 | Iteration: 85 | Classification loss: 0.33045 | Regression loss: 0.62278 | Running loss: 0.99384\n",
      "Epoch: 3 | Iteration: 86 | Classification loss: 0.31052 | Regression loss: 0.57504 | Running loss: 0.99370\n",
      "Epoch: 3 | Iteration: 87 | Classification loss: 0.32351 | Regression loss: 0.80433 | Running loss: 0.99403\n",
      "Epoch: 3 | Iteration: 88 | Classification loss: 0.16272 | Regression loss: 0.52043 | Running loss: 0.99293\n",
      "Epoch: 3 | Iteration: 89 | Classification loss: 0.33877 | Regression loss: 0.68427 | Running loss: 0.99290\n",
      "Epoch: 3 | Iteration: 90 | Classification loss: 0.32104 | Regression loss: 0.69489 | Running loss: 0.99269\n",
      "Epoch: 3 | Iteration: 91 | Classification loss: 0.31003 | Regression loss: 0.57704 | Running loss: 0.99219\n",
      "Epoch: 3 | Iteration: 92 | Classification loss: 0.23415 | Regression loss: 0.58025 | Running loss: 0.99182\n",
      "Epoch: 3 | Iteration: 93 | Classification loss: 0.32606 | Regression loss: 0.62405 | Running loss: 0.99211\n",
      "Epoch: 3 | Iteration: 94 | Classification loss: 0.36588 | Regression loss: 0.67884 | Running loss: 0.99204\n",
      "Epoch: 3 | Iteration: 95 | Classification loss: 0.36656 | Regression loss: 0.73712 | Running loss: 0.99238\n",
      "Epoch: 3 | Iteration: 96 | Classification loss: 0.36811 | Regression loss: 0.69905 | Running loss: 0.99264\n",
      "Epoch: 3 | Iteration: 97 | Classification loss: 0.33527 | Regression loss: 0.64233 | Running loss: 0.99315\n",
      "Epoch: 3 | Iteration: 98 | Classification loss: 0.33836 | Regression loss: 0.74964 | Running loss: 0.99284\n",
      "Epoch: 3 | Iteration: 99 | Classification loss: 0.24952 | Regression loss: 0.66243 | Running loss: 0.99309\n",
      "Epoch: 3 | Iteration: 100 | Classification loss: 0.34529 | Regression loss: 0.72037 | Running loss: 0.99304\n",
      "Epoch: 3 | Iteration: 101 | Classification loss: 0.29177 | Regression loss: 0.66513 | Running loss: 0.99311\n",
      "Epoch: 3 | Iteration: 102 | Classification loss: 0.31806 | Regression loss: 0.68044 | Running loss: 0.99392\n",
      "Epoch: 3 | Iteration: 103 | Classification loss: 0.24789 | Regression loss: 0.54049 | Running loss: 0.99364\n",
      "Epoch: 3 | Iteration: 104 | Classification loss: 0.26317 | Regression loss: 0.64339 | Running loss: 0.99298\n",
      "Epoch: 3 | Iteration: 105 | Classification loss: 0.30473 | Regression loss: 0.60160 | Running loss: 0.99256\n",
      "Epoch: 3 | Iteration: 106 | Classification loss: 0.29660 | Regression loss: 0.66213 | Running loss: 0.99217\n",
      "Epoch: 3 | Iteration: 107 | Classification loss: 0.27956 | Regression loss: 0.62767 | Running loss: 0.99186\n",
      "Epoch: 3 | Iteration: 108 | Classification loss: 0.30929 | Regression loss: 0.63385 | Running loss: 0.99164\n",
      "Epoch: 3 | Iteration: 109 | Classification loss: 0.43893 | Regression loss: 0.76219 | Running loss: 0.99177\n",
      "Epoch: 3 | Iteration: 110 | Classification loss: 0.24656 | Regression loss: 0.58349 | Running loss: 0.99150\n",
      "Epoch: 3 | Iteration: 111 | Classification loss: 0.44776 | Regression loss: 0.66394 | Running loss: 0.99149\n",
      "Epoch: 3 | Iteration: 112 | Classification loss: 0.35047 | Regression loss: 0.66009 | Running loss: 0.99091\n",
      "Epoch: 3 | Iteration: 113 | Classification loss: 0.29651 | Regression loss: 0.55039 | Running loss: 0.99055\n",
      "Epoch: 3 | Iteration: 114 | Classification loss: 0.33254 | Regression loss: 0.64195 | Running loss: 0.99044\n",
      "Epoch: 3 | Iteration: 115 | Classification loss: 0.42394 | Regression loss: 0.78148 | Running loss: 0.99133\n",
      "Epoch: 3 | Iteration: 116 | Classification loss: 0.21181 | Regression loss: 0.52462 | Running loss: 0.99053\n",
      "Epoch: 3 | Iteration: 117 | Classification loss: 0.27407 | Regression loss: 0.68363 | Running loss: 0.99038\n",
      "Epoch: 3 | Iteration: 118 | Classification loss: 0.27464 | Regression loss: 0.54013 | Running loss: 0.99031\n",
      "Epoch: 3 | Iteration: 119 | Classification loss: 0.49849 | Regression loss: 0.66024 | Running loss: 0.99085\n",
      "Epoch: 3 | Iteration: 120 | Classification loss: 0.22628 | Regression loss: 0.64970 | Running loss: 0.99068\n",
      "Epoch: 3 | Iteration: 121 | Classification loss: 0.26028 | Regression loss: 0.56726 | Running loss: 0.99065\n",
      "Epoch: 3 | Iteration: 122 | Classification loss: 0.24820 | Regression loss: 0.63430 | Running loss: 0.99043\n",
      "Epoch: 3 | Iteration: 123 | Classification loss: 0.35325 | Regression loss: 0.72313 | Running loss: 0.99091\n",
      "Epoch: 3 | Iteration: 124 | Classification loss: 0.28904 | Regression loss: 0.72213 | Running loss: 0.99137\n",
      "Epoch: 3 | Iteration: 125 | Classification loss: 0.33713 | Regression loss: 0.80572 | Running loss: 0.99135\n",
      "Epoch: 3 | Iteration: 126 | Classification loss: 0.30958 | Regression loss: 0.70011 | Running loss: 0.99190\n",
      "Epoch: 3 | Iteration: 127 | Classification loss: 0.21712 | Regression loss: 0.51390 | Running loss: 0.99103\n",
      "Epoch: 3 | Iteration: 128 | Classification loss: 0.26276 | Regression loss: 0.45967 | Running loss: 0.99031\n",
      "Epoch: 3 | Iteration: 129 | Classification loss: 0.32863 | Regression loss: 0.43572 | Running loss: 0.99026\n",
      "Epoch: 3 | Iteration: 130 | Classification loss: 0.22963 | Regression loss: 0.55266 | Running loss: 0.99033\n",
      "Epoch: 3 | Iteration: 131 | Classification loss: 0.35139 | Regression loss: 0.76731 | Running loss: 0.99038\n",
      "Epoch: 3 | Iteration: 132 | Classification loss: 0.28948 | Regression loss: 0.54924 | Running loss: 0.99002\n",
      "Epoch: 3 | Iteration: 133 | Classification loss: 0.36728 | Regression loss: 0.77616 | Running loss: 0.98970\n",
      "Epoch: 3 | Iteration: 134 | Classification loss: 0.28091 | Regression loss: 0.57412 | Running loss: 0.98931\n",
      "Epoch: 3 | Iteration: 135 | Classification loss: 0.31642 | Regression loss: 0.54442 | Running loss: 0.98911\n",
      "Epoch: 3 | Iteration: 136 | Classification loss: 0.27280 | Regression loss: 0.60903 | Running loss: 0.98880\n",
      "Epoch: 3 | Iteration: 137 | Classification loss: 0.28511 | Regression loss: 0.60654 | Running loss: 0.98838\n",
      "Epoch: 3 | Iteration: 138 | Classification loss: 0.37325 | Regression loss: 0.61728 | Running loss: 0.98864\n",
      "Epoch: 3 | Iteration: 139 | Classification loss: 0.40358 | Regression loss: 0.79955 | Running loss: 0.98932\n",
      "Epoch: 3 | Iteration: 140 | Classification loss: 0.36083 | Regression loss: 0.71076 | Running loss: 0.98953\n",
      "Epoch: 3 | Iteration: 141 | Classification loss: 0.27282 | Regression loss: 0.56519 | Running loss: 0.98951\n",
      "Epoch: 3 | Iteration: 142 | Classification loss: 0.25058 | Regression loss: 0.61454 | Running loss: 0.98922\n",
      "Epoch: 3 | Iteration: 143 | Classification loss: 0.24641 | Regression loss: 0.66977 | Running loss: 0.98960\n",
      "Epoch: 3 | Iteration: 144 | Classification loss: 0.32557 | Regression loss: 0.70545 | Running loss: 0.98990\n",
      "Epoch: 3 | Iteration: 145 | Classification loss: 0.44033 | Regression loss: 0.83539 | Running loss: 0.99036\n",
      "Epoch: 3 | Iteration: 146 | Classification loss: 0.27074 | Regression loss: 0.73706 | Running loss: 0.99046\n",
      "Epoch: 3 | Iteration: 147 | Classification loss: 0.25814 | Regression loss: 0.55593 | Running loss: 0.98972\n",
      "Epoch: 3 | Iteration: 148 | Classification loss: 0.28546 | Regression loss: 0.69621 | Running loss: 0.98946\n",
      "Epoch: 3 | Iteration: 149 | Classification loss: 0.32625 | Regression loss: 0.71371 | Running loss: 0.98925\n",
      "Epoch: 3 | Iteration: 150 | Classification loss: 0.72659 | Regression loss: 0.68682 | Running loss: 0.99041\n",
      "Epoch: 3 | Iteration: 151 | Classification loss: 0.31319 | Regression loss: 0.73865 | Running loss: 0.99020\n",
      "Epoch: 3 | Iteration: 152 | Classification loss: 0.41677 | Regression loss: 0.65800 | Running loss: 0.99031\n",
      "Epoch: 3 | Iteration: 153 | Classification loss: 0.35625 | Regression loss: 0.66187 | Running loss: 0.99084\n",
      "Epoch: 3 | Iteration: 154 | Classification loss: 0.24300 | Regression loss: 0.50980 | Running loss: 0.99030\n",
      "Epoch: 3 | Iteration: 155 | Classification loss: 0.27714 | Regression loss: 0.63146 | Running loss: 0.99004\n",
      "Epoch: 3 | Iteration: 156 | Classification loss: 0.39106 | Regression loss: 0.69637 | Running loss: 0.98957\n",
      "Epoch: 3 | Iteration: 157 | Classification loss: 0.23644 | Regression loss: 0.64119 | Running loss: 0.98907\n",
      "Epoch: 3 | Iteration: 158 | Classification loss: 0.39442 | Regression loss: 0.77845 | Running loss: 0.98928\n",
      "Epoch: 3 | Iteration: 159 | Classification loss: 0.36495 | Regression loss: 0.61602 | Running loss: 0.98884\n",
      "Epoch: 3 | Iteration: 160 | Classification loss: 0.27715 | Regression loss: 0.60954 | Running loss: 0.98840\n",
      "Epoch: 3 | Iteration: 161 | Classification loss: 0.24167 | Regression loss: 0.58138 | Running loss: 0.98829\n",
      "Epoch: 3 | Iteration: 162 | Classification loss: 0.19484 | Regression loss: 0.53509 | Running loss: 0.98740\n",
      "Epoch: 3 | Iteration: 163 | Classification loss: 0.28030 | Regression loss: 0.75300 | Running loss: 0.98762\n",
      "Epoch: 3 | Iteration: 164 | Classification loss: 0.39553 | Regression loss: 0.83161 | Running loss: 0.98825\n",
      "Epoch: 3 | Iteration: 165 | Classification loss: 0.22301 | Regression loss: 0.57320 | Running loss: 0.98768\n",
      "Epoch: 3 | Iteration: 166 | Classification loss: 0.22632 | Regression loss: 0.56529 | Running loss: 0.98711\n",
      "Epoch: 3 | Iteration: 167 | Classification loss: 0.30268 | Regression loss: 0.65037 | Running loss: 0.98741\n",
      "Epoch: 3 | Iteration: 168 | Classification loss: 0.29270 | Regression loss: 0.70048 | Running loss: 0.98685\n",
      "Epoch: 3 | Iteration: 169 | Classification loss: 0.34743 | Regression loss: 0.65917 | Running loss: 0.98644\n",
      "Epoch: 3 | Iteration: 170 | Classification loss: 0.33096 | Regression loss: 0.73726 | Running loss: 0.98569\n",
      "Epoch: 3 | Iteration: 171 | Classification loss: 0.29231 | Regression loss: 0.59110 | Running loss: 0.98547\n",
      "Epoch: 3 | Iteration: 172 | Classification loss: 0.35635 | Regression loss: 0.60445 | Running loss: 0.98560\n",
      "Epoch: 3 | Iteration: 173 | Classification loss: 0.30006 | Regression loss: 0.60282 | Running loss: 0.98537\n",
      "Epoch: 3 | Iteration: 174 | Classification loss: 0.25566 | Regression loss: 0.45379 | Running loss: 0.98465\n",
      "Epoch: 3 | Iteration: 175 | Classification loss: 0.36340 | Regression loss: 0.83979 | Running loss: 0.98493\n",
      "Epoch: 3 | Iteration: 176 | Classification loss: 0.43015 | Regression loss: 0.92040 | Running loss: 0.98553\n",
      "Epoch: 3 | Iteration: 177 | Classification loss: 0.44412 | Regression loss: 0.66240 | Running loss: 0.98593\n",
      "Epoch: 3 | Iteration: 178 | Classification loss: 0.30092 | Regression loss: 0.64437 | Running loss: 0.98581\n",
      "Epoch: 3 | Iteration: 179 | Classification loss: 0.35044 | Regression loss: 0.67868 | Running loss: 0.98606\n",
      "Epoch: 3 | Iteration: 180 | Classification loss: 0.18114 | Regression loss: 0.44058 | Running loss: 0.98510\n",
      "Epoch: 3 | Iteration: 181 | Classification loss: 0.22975 | Regression loss: 0.64432 | Running loss: 0.98470\n",
      "Epoch: 3 | Iteration: 182 | Classification loss: 0.35751 | Regression loss: 0.63660 | Running loss: 0.98465\n",
      "Epoch: 3 | Iteration: 183 | Classification loss: 0.33154 | Regression loss: 0.73196 | Running loss: 0.98490\n",
      "Epoch: 3 | Iteration: 184 | Classification loss: 0.28935 | Regression loss: 0.59937 | Running loss: 0.98485\n",
      "Epoch: 3 | Iteration: 185 | Classification loss: 0.24412 | Regression loss: 0.55616 | Running loss: 0.98423\n",
      "Epoch: 3 | Iteration: 186 | Classification loss: 0.25265 | Regression loss: 0.62173 | Running loss: 0.98432\n",
      "Epoch: 3 | Iteration: 187 | Classification loss: 0.17665 | Regression loss: 0.46918 | Running loss: 0.98365\n",
      "Epoch: 3 | Iteration: 188 | Classification loss: 0.31314 | Regression loss: 0.65955 | Running loss: 0.98400\n",
      "Epoch: 3 | Iteration: 189 | Classification loss: 0.41587 | Regression loss: 0.72192 | Running loss: 0.98460\n",
      "Epoch: 3 | Iteration: 190 | Classification loss: 0.25991 | Regression loss: 0.58242 | Running loss: 0.98459\n",
      "Epoch: 3 | Iteration: 191 | Classification loss: 0.27345 | Regression loss: 0.56791 | Running loss: 0.98432\n",
      "Epoch: 3 | Iteration: 192 | Classification loss: 0.31663 | Regression loss: 0.63048 | Running loss: 0.98452\n",
      "Epoch: 3 | Iteration: 193 | Classification loss: 0.26495 | Regression loss: 0.64174 | Running loss: 0.98491\n",
      "Epoch: 3 | Iteration: 194 | Classification loss: 0.24130 | Regression loss: 0.59461 | Running loss: 0.98420\n",
      "Epoch: 3 | Iteration: 195 | Classification loss: 0.19760 | Regression loss: 0.50161 | Running loss: 0.98458\n",
      "Epoch: 3 | Iteration: 196 | Classification loss: 0.37182 | Regression loss: 0.80379 | Running loss: 0.98410\n",
      "Epoch: 3 | Iteration: 197 | Classification loss: 0.28241 | Regression loss: 0.58265 | Running loss: 0.98377\n",
      "Epoch: 3 | Iteration: 198 | Classification loss: 0.25395 | Regression loss: 0.63480 | Running loss: 0.98338\n",
      "Epoch: 3 | Iteration: 199 | Classification loss: 0.20175 | Regression loss: 0.43888 | Running loss: 0.98287\n",
      "Epoch: 3 | Iteration: 200 | Classification loss: 0.31913 | Regression loss: 0.68801 | Running loss: 0.98284\n",
      "Epoch: 3 | Iteration: 201 | Classification loss: 0.23246 | Regression loss: 0.52748 | Running loss: 0.98230\n",
      "Epoch: 3 | Iteration: 202 | Classification loss: 0.38076 | Regression loss: 0.72472 | Running loss: 0.98211\n",
      "Epoch: 3 | Iteration: 203 | Classification loss: 0.27939 | Regression loss: 0.59636 | Running loss: 0.98161\n",
      "Epoch: 3 | Iteration: 204 | Classification loss: 0.29210 | Regression loss: 0.69937 | Running loss: 0.98126\n",
      "Epoch: 3 | Iteration: 205 | Classification loss: 0.35616 | Regression loss: 0.62267 | Running loss: 0.98096\n",
      "Epoch: 3 | Iteration: 206 | Classification loss: 0.30181 | Regression loss: 0.64131 | Running loss: 0.98054\n",
      "Epoch: 3 | Iteration: 207 | Classification loss: 0.40012 | Regression loss: 0.71288 | Running loss: 0.98069\n",
      "Epoch: 3 | Iteration: 208 | Classification loss: 0.22976 | Regression loss: 0.70578 | Running loss: 0.98001\n",
      "Epoch: 3 | Iteration: 209 | Classification loss: 0.31962 | Regression loss: 0.65701 | Running loss: 0.97980\n",
      "Epoch: 3 | Iteration: 210 | Classification loss: 0.34124 | Regression loss: 0.68264 | Running loss: 0.97972\n",
      "Epoch: 3 | Iteration: 211 | Classification loss: 0.91674 | Regression loss: 0.57708 | Running loss: 0.98124\n",
      "Epoch: 3 | Iteration: 212 | Classification loss: 0.35378 | Regression loss: 0.81711 | Running loss: 0.98159\n",
      "Epoch: 3 | Iteration: 213 | Classification loss: 0.45914 | Regression loss: 0.53848 | Running loss: 0.98142\n",
      "Epoch: 3 | Iteration: 214 | Classification loss: 0.30922 | Regression loss: 0.53617 | Running loss: 0.98082\n",
      "Epoch: 3 | Iteration: 215 | Classification loss: 0.28760 | Regression loss: 0.59961 | Running loss: 0.98038\n",
      "Epoch: 3 | Iteration: 216 | Classification loss: 0.31843 | Regression loss: 0.62911 | Running loss: 0.98043\n",
      "Epoch: 3 | Iteration: 217 | Classification loss: 0.36860 | Regression loss: 0.75803 | Running loss: 0.98095\n",
      "Epoch: 3 | Iteration: 218 | Classification loss: 0.27405 | Regression loss: 0.41661 | Running loss: 0.98034\n",
      "Epoch: 3 | Iteration: 219 | Classification loss: 0.28941 | Regression loss: 0.63967 | Running loss: 0.98025\n",
      "Epoch: 3 | Iteration: 220 | Classification loss: 0.31711 | Regression loss: 0.65648 | Running loss: 0.97988\n",
      "Epoch: 3 | Iteration: 221 | Classification loss: 0.35196 | Regression loss: 0.79768 | Running loss: 0.98025\n",
      "Epoch: 3 | Iteration: 222 | Classification loss: 0.23139 | Regression loss: 0.60165 | Running loss: 0.97985\n",
      "Epoch: 3 | Iteration: 223 | Classification loss: 0.43729 | Regression loss: 0.68557 | Running loss: 0.97978\n",
      "Epoch: 3 | Iteration: 224 | Classification loss: 0.51465 | Regression loss: 0.79614 | Running loss: 0.98094\n",
      "Epoch: 3 | Iteration: 225 | Classification loss: 0.47643 | Regression loss: 0.75898 | Running loss: 0.98169\n",
      "Epoch: 3 | Iteration: 226 | Classification loss: 0.34846 | Regression loss: 0.72986 | Running loss: 0.98204\n",
      "Epoch: 3 | Iteration: 227 | Classification loss: 0.30458 | Regression loss: 0.68971 | Running loss: 0.98216\n",
      "Epoch: 3 | Iteration: 228 | Classification loss: 0.25783 | Regression loss: 0.62288 | Running loss: 0.98155\n",
      "Epoch: 3 | Iteration: 229 | Classification loss: 0.27984 | Regression loss: 0.69712 | Running loss: 0.98114\n",
      "Epoch: 3 | Iteration: 230 | Classification loss: 0.31512 | Regression loss: 0.68767 | Running loss: 0.98087\n",
      "Epoch: 3 | Iteration: 231 | Classification loss: 0.20241 | Regression loss: 0.55908 | Running loss: 0.98055\n",
      "Epoch: 3 | Iteration: 232 | Classification loss: 0.22576 | Regression loss: 0.58171 | Running loss: 0.98019\n",
      "Epoch: 3 | Iteration: 233 | Classification loss: 0.35048 | Regression loss: 0.70439 | Running loss: 0.98037\n",
      "Epoch: 3 | Iteration: 234 | Classification loss: 0.31609 | Regression loss: 0.71600 | Running loss: 0.98034\n",
      "Epoch: 3 | Iteration: 235 | Classification loss: 0.22054 | Regression loss: 0.56019 | Running loss: 0.97992\n",
      "Epoch: 3 | Iteration: 236 | Classification loss: 0.40062 | Regression loss: 0.78561 | Running loss: 0.98033\n",
      "Epoch: 3 | Iteration: 237 | Classification loss: 0.26291 | Regression loss: 0.54060 | Running loss: 0.98003\n",
      "Epoch: 3 | Iteration: 238 | Classification loss: 0.29836 | Regression loss: 0.72558 | Running loss: 0.98040\n",
      "Epoch: 3 | Iteration: 239 | Classification loss: 0.29983 | Regression loss: 0.68460 | Running loss: 0.98038\n",
      "Epoch: 3 | Iteration: 240 | Classification loss: 0.33680 | Regression loss: 0.68335 | Running loss: 0.98053\n",
      "Epoch: 3 | Iteration: 241 | Classification loss: 0.29901 | Regression loss: 0.61825 | Running loss: 0.98028\n",
      "Epoch: 3 | Iteration: 242 | Classification loss: 0.23263 | Regression loss: 0.52192 | Running loss: 0.97999\n",
      "Epoch: 3 | Iteration: 243 | Classification loss: 0.29981 | Regression loss: 0.74178 | Running loss: 0.98035\n",
      "Epoch: 3 | Iteration: 244 | Classification loss: 0.29277 | Regression loss: 0.69237 | Running loss: 0.98008\n",
      "Epoch: 3 | Iteration: 245 | Classification loss: 0.27714 | Regression loss: 0.64495 | Running loss: 0.98024\n",
      "Epoch: 3 | Iteration: 246 | Classification loss: 0.29216 | Regression loss: 0.59244 | Running loss: 0.98014\n",
      "Epoch: 3 | Iteration: 247 | Classification loss: 0.21494 | Regression loss: 0.51373 | Running loss: 0.97951\n",
      "Epoch: 3 | Iteration: 248 | Classification loss: 0.38516 | Regression loss: 0.71431 | Running loss: 0.97941\n",
      "Epoch: 3 | Iteration: 249 | Classification loss: 0.25135 | Regression loss: 0.49493 | Running loss: 0.97853\n",
      "Epoch: 3 | Iteration: 250 | Classification loss: 0.17642 | Regression loss: 0.53224 | Running loss: 0.97760\n",
      "Epoch: 3 | Iteration: 251 | Classification loss: 0.39328 | Regression loss: 0.72123 | Running loss: 0.97806\n",
      "Epoch: 3 | Iteration: 252 | Classification loss: 0.38793 | Regression loss: 0.65734 | Running loss: 0.97833\n",
      "Epoch: 3 | Iteration: 253 | Classification loss: 0.22797 | Regression loss: 0.61264 | Running loss: 0.97765\n",
      "Epoch: 3 | Iteration: 254 | Classification loss: 0.30293 | Regression loss: 0.70042 | Running loss: 0.97777\n",
      "Epoch: 3 | Iteration: 255 | Classification loss: 0.28896 | Regression loss: 0.61874 | Running loss: 0.97760\n",
      "Epoch: 3 | Iteration: 256 | Classification loss: 0.35712 | Regression loss: 0.73185 | Running loss: 0.97802\n",
      "Epoch: 3 | Iteration: 257 | Classification loss: 0.29551 | Regression loss: 0.65570 | Running loss: 0.97768\n",
      "Epoch: 3 | Iteration: 258 | Classification loss: 0.23798 | Regression loss: 0.55273 | Running loss: 0.97732\n",
      "Epoch: 3 | Iteration: 259 | Classification loss: 0.44477 | Regression loss: 0.82412 | Running loss: 0.97773\n",
      "Epoch: 3 | Iteration: 260 | Classification loss: 0.35866 | Regression loss: 0.66169 | Running loss: 0.97734\n",
      "Epoch: 3 | Iteration: 261 | Classification loss: 0.33174 | Regression loss: 0.72400 | Running loss: 0.97702\n",
      "Epoch: 3 | Iteration: 262 | Classification loss: 0.41022 | Regression loss: 0.67498 | Running loss: 0.97747\n",
      "Epoch: 3 | Iteration: 263 | Classification loss: 0.17188 | Regression loss: 0.43505 | Running loss: 0.97676\n",
      "Epoch: 3 | Iteration: 264 | Classification loss: 0.15866 | Regression loss: 0.39366 | Running loss: 0.97555\n",
      "Epoch: 3 | Iteration: 265 | Classification loss: 0.26369 | Regression loss: 0.62189 | Running loss: 0.97484\n",
      "Epoch: 3 | Iteration: 266 | Classification loss: 0.23908 | Regression loss: 0.64613 | Running loss: 0.97450\n",
      "Epoch: 3 | Iteration: 267 | Classification loss: 0.22319 | Regression loss: 0.54671 | Running loss: 0.97459\n",
      "Epoch: 3 | Iteration: 268 | Classification loss: 0.36889 | Regression loss: 0.70464 | Running loss: 0.97460\n",
      "Epoch: 3 | Iteration: 269 | Classification loss: 0.36909 | Regression loss: 0.75677 | Running loss: 0.97496\n",
      "Epoch: 3 | Iteration: 270 | Classification loss: 0.27889 | Regression loss: 0.63514 | Running loss: 0.97467\n",
      "Epoch: 3 | Iteration: 271 | Classification loss: 0.34679 | Regression loss: 0.66510 | Running loss: 0.97489\n",
      "Epoch: 3 | Iteration: 272 | Classification loss: 0.33828 | Regression loss: 0.61616 | Running loss: 0.97436\n",
      "Epoch: 3 | Iteration: 273 | Classification loss: 0.38948 | Regression loss: 0.74209 | Running loss: 0.97452\n",
      "Epoch: 3 | Iteration: 274 | Classification loss: 0.35355 | Regression loss: 0.77006 | Running loss: 0.97485\n",
      "Epoch: 3 | Iteration: 275 | Classification loss: 0.25534 | Regression loss: 0.65880 | Running loss: 0.97498\n",
      "Epoch: 3 | Iteration: 276 | Classification loss: 0.27248 | Regression loss: 0.68613 | Running loss: 0.97498\n",
      "Epoch: 3 | Iteration: 277 | Classification loss: 0.22714 | Regression loss: 0.63183 | Running loss: 0.97511\n",
      "Epoch: 3 | Iteration: 278 | Classification loss: 0.43521 | Regression loss: 0.77169 | Running loss: 0.97563\n",
      "Epoch: 3 | Iteration: 279 | Classification loss: 0.33334 | Regression loss: 0.69649 | Running loss: 0.97613\n",
      "Epoch: 3 | Iteration: 280 | Classification loss: 0.38856 | Regression loss: 0.71885 | Running loss: 0.97672\n",
      "Epoch: 3 | Iteration: 281 | Classification loss: 0.32781 | Regression loss: 0.70926 | Running loss: 0.97649\n",
      "Epoch: 3 | Iteration: 282 | Classification loss: 0.25507 | Regression loss: 0.61881 | Running loss: 0.97618\n",
      "Epoch: 3 | Iteration: 283 | Classification loss: 0.22891 | Regression loss: 0.56866 | Running loss: 0.97586\n",
      "Epoch: 3 | Iteration: 284 | Classification loss: 0.30908 | Regression loss: 0.74642 | Running loss: 0.97587\n",
      "Epoch: 3 | Iteration: 285 | Classification loss: 0.33145 | Regression loss: 0.71076 | Running loss: 0.97590\n",
      "Epoch: 3 | Iteration: 286 | Classification loss: 0.30120 | Regression loss: 0.56961 | Running loss: 0.97573\n",
      "Epoch: 3 | Iteration: 287 | Classification loss: 0.22887 | Regression loss: 0.60388 | Running loss: 0.97564\n",
      "Epoch: 3 | Iteration: 288 | Classification loss: 0.50477 | Regression loss: 0.32092 | Running loss: 0.97522\n",
      "Epoch: 3 | Iteration: 289 | Classification loss: 0.34331 | Regression loss: 0.57478 | Running loss: 0.97498\n",
      "Epoch: 3 | Iteration: 290 | Classification loss: 0.25989 | Regression loss: 0.60782 | Running loss: 0.97485\n",
      "Epoch: 3 | Iteration: 291 | Classification loss: 0.49601 | Regression loss: 0.71736 | Running loss: 0.97502\n",
      "Epoch: 3 | Iteration: 292 | Classification loss: 0.24192 | Regression loss: 0.59827 | Running loss: 0.97476\n",
      "Epoch: 3 | Iteration: 293 | Classification loss: 0.29286 | Regression loss: 0.58338 | Running loss: 0.97437\n",
      "Epoch: 3 | Iteration: 294 | Classification loss: 0.28458 | Regression loss: 0.60419 | Running loss: 0.97481\n",
      "Epoch: 3 | Iteration: 295 | Classification loss: 0.37523 | Regression loss: 0.78633 | Running loss: 0.97532\n",
      "Epoch: 3 | Iteration: 296 | Classification loss: 0.33927 | Regression loss: 0.51327 | Running loss: 0.97545\n",
      "Epoch: 3 | Iteration: 297 | Classification loss: 0.26180 | Regression loss: 0.61795 | Running loss: 0.97527\n",
      "Epoch: 3 | Iteration: 298 | Classification loss: 0.25794 | Regression loss: 0.69188 | Running loss: 0.97494\n",
      "Epoch: 3 | Iteration: 299 | Classification loss: 0.23470 | Regression loss: 0.56992 | Running loss: 0.97490\n",
      "Epoch: 3 | Iteration: 300 | Classification loss: 0.26640 | Regression loss: 0.46038 | Running loss: 0.97485\n",
      "Epoch: 3 | Iteration: 301 | Classification loss: 0.27480 | Regression loss: 0.57229 | Running loss: 0.97479\n",
      "Epoch: 3 | Iteration: 302 | Classification loss: 0.28604 | Regression loss: 0.75111 | Running loss: 0.97499\n",
      "Epoch: 3 | Iteration: 303 | Classification loss: 0.23465 | Regression loss: 0.51366 | Running loss: 0.97451\n",
      "Epoch: 3 | Iteration: 304 | Classification loss: 0.31858 | Regression loss: 0.63597 | Running loss: 0.97468\n",
      "Epoch: 3 | Iteration: 305 | Classification loss: 0.23654 | Regression loss: 0.61322 | Running loss: 0.97438\n",
      "Epoch: 3 | Iteration: 306 | Classification loss: 0.27703 | Regression loss: 0.49256 | Running loss: 0.97404\n",
      "Epoch: 3 | Iteration: 307 | Classification loss: 0.34044 | Regression loss: 0.66239 | Running loss: 0.97411\n",
      "Epoch: 3 | Iteration: 308 | Classification loss: 0.28801 | Regression loss: 0.71205 | Running loss: 0.97437\n",
      "Epoch: 3 | Iteration: 309 | Classification loss: 0.28062 | Regression loss: 0.59849 | Running loss: 0.97455\n",
      "Epoch: 3 | Iteration: 310 | Classification loss: 0.27403 | Regression loss: 0.65768 | Running loss: 0.97442\n",
      "Epoch: 3 | Iteration: 311 | Classification loss: 0.30877 | Regression loss: 0.70455 | Running loss: 0.97426\n",
      "Epoch: 3 | Iteration: 312 | Classification loss: 0.26797 | Regression loss: 0.70317 | Running loss: 0.97397\n",
      "Epoch: 3 | Iteration: 313 | Classification loss: 0.28620 | Regression loss: 0.60739 | Running loss: 0.97403\n",
      "Epoch: 3 | Iteration: 314 | Classification loss: 0.30057 | Regression loss: 0.56700 | Running loss: 0.97410\n",
      "Epoch: 3 | Iteration: 315 | Classification loss: 0.23441 | Regression loss: 0.47046 | Running loss: 0.97346\n",
      "Epoch: 3 | Iteration: 316 | Classification loss: 0.26000 | Regression loss: 0.52079 | Running loss: 0.97288\n",
      "Epoch: 3 | Iteration: 317 | Classification loss: 0.39659 | Regression loss: 0.72161 | Running loss: 0.97302\n",
      "Epoch: 3 | Iteration: 318 | Classification loss: 0.30540 | Regression loss: 0.68596 | Running loss: 0.97269\n",
      "Epoch: 3 | Iteration: 319 | Classification loss: 0.32981 | Regression loss: 0.71116 | Running loss: 0.97253\n",
      "Epoch: 3 | Iteration: 320 | Classification loss: 0.27994 | Regression loss: 0.59763 | Running loss: 0.97230\n",
      "Epoch: 3 | Iteration: 321 | Classification loss: 0.33445 | Regression loss: 0.72907 | Running loss: 0.97297\n",
      "Epoch: 3 | Iteration: 322 | Classification loss: 0.28077 | Regression loss: 0.61674 | Running loss: 0.97248\n",
      "Epoch: 3 | Iteration: 323 | Classification loss: 0.35870 | Regression loss: 0.66648 | Running loss: 0.97264\n",
      "Epoch: 3 | Iteration: 324 | Classification loss: 0.31837 | Regression loss: 0.66814 | Running loss: 0.97243\n",
      "Epoch: 3 | Iteration: 325 | Classification loss: 0.49742 | Regression loss: 0.76979 | Running loss: 0.97289\n",
      "Epoch: 3 | Iteration: 326 | Classification loss: 0.25832 | Regression loss: 0.68619 | Running loss: 0.97273\n",
      "Epoch: 3 | Iteration: 327 | Classification loss: 0.33922 | Regression loss: 0.67097 | Running loss: 0.97248\n",
      "Epoch: 3 | Iteration: 328 | Classification loss: 0.22584 | Regression loss: 0.60189 | Running loss: 0.97200\n",
      "Epoch: 3 | Iteration: 329 | Classification loss: 0.24378 | Regression loss: 0.61887 | Running loss: 0.97170\n",
      "Epoch: 3 | Iteration: 330 | Classification loss: 0.29110 | Regression loss: 0.65478 | Running loss: 0.97114\n",
      "Epoch: 3 | Iteration: 331 | Classification loss: 0.33475 | Regression loss: 0.70585 | Running loss: 0.97109\n",
      "Epoch: 3 | Iteration: 332 | Classification loss: 0.40378 | Regression loss: 0.79291 | Running loss: 0.97121\n",
      "Epoch: 3 | Iteration: 333 | Classification loss: 0.39176 | Regression loss: 0.71275 | Running loss: 0.97187\n",
      "Epoch: 3 | Iteration: 334 | Classification loss: 0.18464 | Regression loss: 0.41277 | Running loss: 0.97111\n",
      "Epoch: 3 | Iteration: 335 | Classification loss: 0.25183 | Regression loss: 0.54323 | Running loss: 0.97094\n",
      "Epoch: 3 | Iteration: 336 | Classification loss: 0.25868 | Regression loss: 0.63184 | Running loss: 0.97141\n",
      "Epoch: 3 | Iteration: 337 | Classification loss: 0.26827 | Regression loss: 0.61817 | Running loss: 0.97141\n",
      "Epoch: 3 | Iteration: 338 | Classification loss: 0.23004 | Regression loss: 0.61465 | Running loss: 0.97103\n",
      "Epoch: 3 | Iteration: 339 | Classification loss: 0.38462 | Regression loss: 0.67341 | Running loss: 0.97146\n",
      "Epoch: 3 | Iteration: 340 | Classification loss: 0.31532 | Regression loss: 0.37801 | Running loss: 0.97077\n",
      "Epoch: 3 | Iteration: 341 | Classification loss: 0.34871 | Regression loss: 0.82187 | Running loss: 0.97106\n",
      "Epoch: 3 | Iteration: 342 | Classification loss: 0.33928 | Regression loss: 0.64926 | Running loss: 0.97144\n",
      "Epoch: 3 | Iteration: 343 | Classification loss: 0.22820 | Regression loss: 0.77061 | Running loss: 0.97120\n",
      "Epoch: 3 | Iteration: 344 | Classification loss: 0.29371 | Regression loss: 0.51530 | Running loss: 0.97104\n",
      "Epoch: 3 | Iteration: 345 | Classification loss: 0.20867 | Regression loss: 0.47543 | Running loss: 0.97071\n",
      "Epoch: 3 | Iteration: 346 | Classification loss: 0.38996 | Regression loss: 0.67624 | Running loss: 0.97043\n",
      "Epoch: 3 | Iteration: 347 | Classification loss: 0.17770 | Regression loss: 0.42758 | Running loss: 0.96964\n",
      "Epoch: 3 | Iteration: 348 | Classification loss: 0.36130 | Regression loss: 0.69540 | Running loss: 0.96861\n",
      "Epoch: 3 | Iteration: 349 | Classification loss: 0.28186 | Regression loss: 0.65998 | Running loss: 0.96855\n",
      "Epoch: 3 | Iteration: 350 | Classification loss: 0.22457 | Regression loss: 0.47134 | Running loss: 0.96779\n",
      "Epoch: 3 | Iteration: 351 | Classification loss: 0.47094 | Regression loss: 0.78947 | Running loss: 0.96826\n",
      "Epoch: 3 | Iteration: 352 | Classification loss: 0.37613 | Regression loss: 0.70891 | Running loss: 0.96881\n",
      "Epoch: 3 | Iteration: 353 | Classification loss: 0.27541 | Regression loss: 0.57505 | Running loss: 0.96821\n",
      "Epoch: 3 | Iteration: 354 | Classification loss: 0.19059 | Regression loss: 0.58248 | Running loss: 0.96801\n",
      "Epoch: 3 | Iteration: 355 | Classification loss: 0.21513 | Regression loss: 0.51747 | Running loss: 0.96779\n",
      "Epoch: 3 | Iteration: 356 | Classification loss: 0.28519 | Regression loss: 0.57846 | Running loss: 0.96691\n",
      "Epoch: 3 | Iteration: 357 | Classification loss: 0.25986 | Regression loss: 0.58259 | Running loss: 0.96636\n",
      "Epoch: 3 | Iteration: 358 | Classification loss: 0.34304 | Regression loss: 0.58506 | Running loss: 0.96618\n",
      "Epoch: 3 | Iteration: 359 | Classification loss: 0.27970 | Regression loss: 0.71785 | Running loss: 0.96549\n",
      "Epoch: 3 | Iteration: 360 | Classification loss: 0.24634 | Regression loss: 0.62023 | Running loss: 0.96551\n",
      "Epoch: 3 | Iteration: 361 | Classification loss: 0.36373 | Regression loss: 0.70353 | Running loss: 0.96622\n",
      "Epoch: 3 | Iteration: 362 | Classification loss: 0.32563 | Regression loss: 0.68330 | Running loss: 0.96595\n",
      "Epoch: 3 | Iteration: 363 | Classification loss: 0.34999 | Regression loss: 0.66993 | Running loss: 0.96559\n",
      "Epoch: 3 | Iteration: 364 | Classification loss: 0.23166 | Regression loss: 0.64112 | Running loss: 0.96512\n",
      "Epoch: 3 | Iteration: 365 | Classification loss: 0.36471 | Regression loss: 0.58183 | Running loss: 0.96489\n",
      "Epoch: 3 | Iteration: 366 | Classification loss: 0.23693 | Regression loss: 0.59548 | Running loss: 0.96460\n",
      "Epoch: 3 | Iteration: 367 | Classification loss: 0.30547 | Regression loss: 0.68848 | Running loss: 0.96431\n",
      "Epoch: 3 | Iteration: 368 | Classification loss: 0.38056 | Regression loss: 0.56608 | Running loss: 0.96460\n",
      "Epoch: 3 | Iteration: 369 | Classification loss: 0.43933 | Regression loss: 0.68549 | Running loss: 0.96495\n",
      "Epoch: 3 | Iteration: 370 | Classification loss: 0.29629 | Regression loss: 0.56549 | Running loss: 0.96472\n",
      "Epoch: 3 | Iteration: 371 | Classification loss: 0.37430 | Regression loss: 0.59974 | Running loss: 0.96470\n",
      "Epoch: 3 | Iteration: 372 | Classification loss: 0.32277 | Regression loss: 0.68448 | Running loss: 0.96480\n",
      "Epoch: 3 | Iteration: 373 | Classification loss: 0.38118 | Regression loss: 0.78591 | Running loss: 0.96515\n",
      "Epoch: 3 | Iteration: 374 | Classification loss: 0.31422 | Regression loss: 0.73070 | Running loss: 0.96471\n",
      "Epoch: 3 | Iteration: 375 | Classification loss: 0.20254 | Regression loss: 0.47227 | Running loss: 0.96388\n",
      "Epoch: 3 | Iteration: 376 | Classification loss: 0.36131 | Regression loss: 0.60698 | Running loss: 0.96373\n",
      "Epoch: 3 | Iteration: 377 | Classification loss: 0.27416 | Regression loss: 0.57418 | Running loss: 0.96304\n",
      "Epoch: 3 | Iteration: 378 | Classification loss: 0.29014 | Regression loss: 0.60355 | Running loss: 0.96255\n",
      "Epoch: 3 | Iteration: 379 | Classification loss: 0.26551 | Regression loss: 0.47191 | Running loss: 0.96221\n",
      "Epoch: 3 | Iteration: 380 | Classification loss: 0.34399 | Regression loss: 0.73107 | Running loss: 0.96218\n",
      "Epoch: 3 | Iteration: 381 | Classification loss: 0.28788 | Regression loss: 0.59854 | Running loss: 0.96209\n",
      "Epoch: 3 | Iteration: 382 | Classification loss: 0.18922 | Regression loss: 0.56303 | Running loss: 0.96168\n",
      "Epoch: 3 | Iteration: 383 | Classification loss: 0.30869 | Regression loss: 0.70206 | Running loss: 0.96114\n",
      "Epoch: 3 | Iteration: 384 | Classification loss: 0.20447 | Regression loss: 0.63110 | Running loss: 0.96099\n",
      "Epoch: 3 | Iteration: 385 | Classification loss: 0.34495 | Regression loss: 0.71457 | Running loss: 0.96100\n",
      "Epoch: 3 | Iteration: 386 | Classification loss: 0.32923 | Regression loss: 0.71201 | Running loss: 0.96092\n",
      "Epoch: 3 | Iteration: 387 | Classification loss: 0.32607 | Regression loss: 0.66733 | Running loss: 0.96046\n",
      "Epoch: 3 | Iteration: 388 | Classification loss: 0.23807 | Regression loss: 0.56746 | Running loss: 0.95975\n",
      "Epoch: 3 | Iteration: 389 | Classification loss: 0.17122 | Regression loss: 0.39933 | Running loss: 0.95887\n",
      "Epoch: 3 | Iteration: 390 | Classification loss: 0.23701 | Regression loss: 0.55623 | Running loss: 0.95794\n",
      "Epoch: 3 | Iteration: 391 | Classification loss: 0.35252 | Regression loss: 0.62085 | Running loss: 0.95794\n",
      "Epoch: 3 | Iteration: 392 | Classification loss: 0.24632 | Regression loss: 0.57679 | Running loss: 0.95724\n",
      "Epoch: 3 | Iteration: 393 | Classification loss: 0.25760 | Regression loss: 0.63312 | Running loss: 0.95726\n",
      "Epoch: 3 | Iteration: 394 | Classification loss: 0.12627 | Regression loss: 0.36984 | Running loss: 0.95644\n",
      "Epoch: 3 | Iteration: 395 | Classification loss: 0.26539 | Regression loss: 0.54134 | Running loss: 0.95648\n",
      "Epoch: 3 | Iteration: 396 | Classification loss: 0.34086 | Regression loss: 0.66459 | Running loss: 0.95655\n",
      "Epoch: 3 | Iteration: 397 | Classification loss: 0.26277 | Regression loss: 0.47014 | Running loss: 0.95621\n",
      "Epoch: 3 | Iteration: 398 | Classification loss: 0.33504 | Regression loss: 0.53903 | Running loss: 0.95589\n",
      "Epoch: 3 | Iteration: 399 | Classification loss: 0.26932 | Regression loss: 0.60773 | Running loss: 0.95583\n",
      "Epoch: 3 | Iteration: 400 | Classification loss: 0.38212 | Regression loss: 0.71039 | Running loss: 0.95602\n",
      "Epoch: 3 | Iteration: 401 | Classification loss: 0.28062 | Regression loss: 0.58880 | Running loss: 0.95583\n",
      "Epoch: 3 | Iteration: 402 | Classification loss: 0.31793 | Regression loss: 0.71769 | Running loss: 0.95583\n",
      "Epoch: 3 | Iteration: 403 | Classification loss: 0.31997 | Regression loss: 0.59016 | Running loss: 0.95541\n",
      "Epoch: 3 | Iteration: 404 | Classification loss: 0.27171 | Regression loss: 0.72128 | Running loss: 0.95498\n",
      "Epoch: 3 | Iteration: 405 | Classification loss: 0.22640 | Regression loss: 0.57957 | Running loss: 0.95442\n",
      "Epoch: 3 | Iteration: 406 | Classification loss: 0.22594 | Regression loss: 0.57377 | Running loss: 0.95393\n",
      "Epoch: 3 | Iteration: 407 | Classification loss: 0.20819 | Regression loss: 0.46243 | Running loss: 0.95358\n",
      "Epoch: 3 | Iteration: 408 | Classification loss: 0.77714 | Regression loss: 0.86023 | Running loss: 0.95487\n",
      "Epoch: 3 | Iteration: 409 | Classification loss: 0.22975 | Regression loss: 0.48219 | Running loss: 0.95413\n",
      "Epoch: 3 | Iteration: 410 | Classification loss: 0.27182 | Regression loss: 0.54931 | Running loss: 0.95365\n",
      "Epoch: 3 | Iteration: 411 | Classification loss: 0.22670 | Regression loss: 0.48950 | Running loss: 0.95281\n",
      "Epoch: 3 | Iteration: 412 | Classification loss: 0.30736 | Regression loss: 0.66717 | Running loss: 0.95222\n",
      "Epoch: 3 | Iteration: 413 | Classification loss: 0.33762 | Regression loss: 0.71479 | Running loss: 0.95219\n",
      "Epoch: 3 | Iteration: 414 | Classification loss: 0.21823 | Regression loss: 0.61068 | Running loss: 0.95230\n",
      "Epoch: 3 | Iteration: 415 | Classification loss: 0.36031 | Regression loss: 0.73803 | Running loss: 0.95231\n",
      "Epoch: 3 | Iteration: 416 | Classification loss: 0.34816 | Regression loss: 0.47280 | Running loss: 0.95175\n",
      "Epoch: 3 | Iteration: 417 | Classification loss: 0.66815 | Regression loss: 0.41316 | Running loss: 0.95175\n",
      "Epoch: 3 | Iteration: 418 | Classification loss: 0.25006 | Regression loss: 0.64869 | Running loss: 0.95152\n",
      "Epoch: 3 | Iteration: 419 | Classification loss: 0.24893 | Regression loss: 0.64699 | Running loss: 0.95110\n",
      "Epoch: 3 | Iteration: 420 | Classification loss: 0.28166 | Regression loss: 0.60162 | Running loss: 0.95062\n",
      "Epoch: 3 | Iteration: 421 | Classification loss: 0.42905 | Regression loss: 0.49842 | Running loss: 0.95007\n",
      "Epoch: 3 | Iteration: 422 | Classification loss: 0.34050 | Regression loss: 0.78550 | Running loss: 0.95044\n",
      "Epoch: 3 | Iteration: 423 | Classification loss: 0.24633 | Regression loss: 0.60345 | Running loss: 0.94995\n",
      "Epoch: 3 | Iteration: 424 | Classification loss: 0.17503 | Regression loss: 0.49599 | Running loss: 0.94990\n",
      "Epoch: 3 | Iteration: 425 | Classification loss: 0.28412 | Regression loss: 0.58595 | Running loss: 0.94957\n",
      "Epoch: 3 | Iteration: 426 | Classification loss: 0.34513 | Regression loss: 0.72190 | Running loss: 0.94941\n",
      "Epoch: 3 | Iteration: 427 | Classification loss: 0.24274 | Regression loss: 0.52613 | Running loss: 0.94910\n",
      "Epoch: 3 | Iteration: 428 | Classification loss: 0.27699 | Regression loss: 0.67169 | Running loss: 0.94929\n",
      "Epoch: 3 | Iteration: 429 | Classification loss: 0.32434 | Regression loss: 0.61667 | Running loss: 0.94907\n",
      "Epoch: 3 | Iteration: 430 | Classification loss: 0.25801 | Regression loss: 0.42227 | Running loss: 0.94899\n",
      "Epoch: 3 | Iteration: 431 | Classification loss: 0.34897 | Regression loss: 0.68401 | Running loss: 0.94916\n",
      "Epoch: 3 | Iteration: 432 | Classification loss: 0.30318 | Regression loss: 0.66087 | Running loss: 0.94893\n",
      "Epoch: 3 | Iteration: 433 | Classification loss: 0.47858 | Regression loss: 0.84714 | Running loss: 0.94938\n",
      "Epoch: 3 | Iteration: 434 | Classification loss: 0.28054 | Regression loss: 0.60399 | Running loss: 0.94937\n",
      "Epoch: 3 | Iteration: 435 | Classification loss: 0.19518 | Regression loss: 0.50579 | Running loss: 0.94860\n",
      "Epoch: 3 | Iteration: 436 | Classification loss: 0.29405 | Regression loss: 0.52560 | Running loss: 0.94807\n",
      "Epoch: 3 | Iteration: 437 | Classification loss: 0.26761 | Regression loss: 0.55998 | Running loss: 0.94774\n",
      "Epoch: 3 | Iteration: 438 | Classification loss: 0.32462 | Regression loss: 0.72818 | Running loss: 0.94798\n",
      "Epoch: 3 | Iteration: 439 | Classification loss: 0.34829 | Regression loss: 0.69852 | Running loss: 0.94782\n",
      "Epoch: 3 | Iteration: 440 | Classification loss: 0.46429 | Regression loss: 0.69935 | Running loss: 0.94778\n",
      "Epoch: 3 | Iteration: 441 | Classification loss: 0.28463 | Regression loss: 0.58796 | Running loss: 0.94785\n",
      "Epoch: 3 | Iteration: 442 | Classification loss: 0.31123 | Regression loss: 0.66188 | Running loss: 0.94820\n",
      "Epoch: 3 | Iteration: 443 | Classification loss: 0.35542 | Regression loss: 0.72085 | Running loss: 0.94828\n",
      "Epoch: 3 | Iteration: 444 | Classification loss: 0.26847 | Regression loss: 0.61175 | Running loss: 0.94809\n",
      "Epoch: 3 | Iteration: 445 | Classification loss: 0.26143 | Regression loss: 0.70904 | Running loss: 0.94831\n",
      "Epoch: 3 | Iteration: 446 | Classification loss: 0.24350 | Regression loss: 0.54853 | Running loss: 0.94780\n",
      "Epoch: 3 | Iteration: 447 | Classification loss: 0.32113 | Regression loss: 0.70516 | Running loss: 0.94748\n",
      "Epoch: 3 | Iteration: 448 | Classification loss: 0.35359 | Regression loss: 0.77884 | Running loss: 0.94735\n",
      "Epoch: 3 | Iteration: 449 | Classification loss: 0.26080 | Regression loss: 0.54891 | Running loss: 0.94718\n",
      "Epoch: 3 | Iteration: 450 | Classification loss: 0.27901 | Regression loss: 0.50671 | Running loss: 0.94697\n",
      "Epoch: 3 | Iteration: 451 | Classification loss: 0.31896 | Regression loss: 0.62673 | Running loss: 0.94656\n",
      "Epoch: 3 | Iteration: 452 | Classification loss: 0.35604 | Regression loss: 0.74930 | Running loss: 0.94674\n",
      "Epoch: 3 | Iteration: 453 | Classification loss: 0.24974 | Regression loss: 0.51954 | Running loss: 0.94623\n",
      "Epoch: 3 | Iteration: 454 | Classification loss: 0.88246 | Regression loss: 0.68904 | Running loss: 0.94765\n",
      "Epoch: 3 | Iteration: 455 | Classification loss: 0.30909 | Regression loss: 0.65139 | Running loss: 0.94726\n",
      "Epoch: 3 | Iteration: 456 | Classification loss: 0.35583 | Regression loss: 0.73337 | Running loss: 0.94768\n",
      "Epoch: 3 | Iteration: 457 | Classification loss: 0.28198 | Regression loss: 0.61915 | Running loss: 0.94722\n",
      "Epoch: 3 | Iteration: 458 | Classification loss: 0.31156 | Regression loss: 0.65817 | Running loss: 0.94710\n",
      "Epoch: 3 | Iteration: 459 | Classification loss: 0.27350 | Regression loss: 0.55006 | Running loss: 0.94682\n",
      "Epoch: 3 | Iteration: 460 | Classification loss: 0.16481 | Regression loss: 0.46319 | Running loss: 0.94589\n",
      "Epoch: 3 | Iteration: 461 | Classification loss: 0.38264 | Regression loss: 0.74364 | Running loss: 0.94639\n",
      "Epoch: 3 | Iteration: 462 | Classification loss: 0.30888 | Regression loss: 0.63732 | Running loss: 0.94634\n",
      "Epoch: 3 | Iteration: 463 | Classification loss: 0.26368 | Regression loss: 0.66739 | Running loss: 0.94631\n",
      "Epoch: 3 | Iteration: 464 | Classification loss: 0.35725 | Regression loss: 0.77579 | Running loss: 0.94657\n",
      "Epoch: 3 | Iteration: 465 | Classification loss: 0.19797 | Regression loss: 0.50228 | Running loss: 0.94610\n",
      "Epoch: 3 | Iteration: 466 | Classification loss: 0.35267 | Regression loss: 0.80914 | Running loss: 0.94614\n",
      "Epoch: 3 | Iteration: 467 | Classification loss: 0.41170 | Regression loss: 0.76841 | Running loss: 0.94657\n",
      "Epoch: 3 | Iteration: 468 | Classification loss: 0.30973 | Regression loss: 0.75633 | Running loss: 0.94685\n",
      "Epoch: 3 | Iteration: 469 | Classification loss: 0.27461 | Regression loss: 0.57319 | Running loss: 0.94658\n",
      "Epoch: 3 | Iteration: 470 | Classification loss: 0.26037 | Regression loss: 0.65368 | Running loss: 0.94611\n",
      "Epoch: 3 | Iteration: 471 | Classification loss: 0.42604 | Regression loss: 0.58510 | Running loss: 0.94597\n",
      "Epoch: 3 | Iteration: 472 | Classification loss: 0.23887 | Regression loss: 0.60854 | Running loss: 0.94597\n",
      "Epoch: 3 | Iteration: 473 | Classification loss: 0.32771 | Regression loss: 0.78541 | Running loss: 0.94619\n",
      "Epoch: 3 | Iteration: 474 | Classification loss: 0.29226 | Regression loss: 0.61671 | Running loss: 0.94573\n",
      "Epoch: 3 | Iteration: 475 | Classification loss: 0.25778 | Regression loss: 0.74116 | Running loss: 0.94609\n",
      "Epoch: 3 | Iteration: 476 | Classification loss: 0.37464 | Regression loss: 0.66734 | Running loss: 0.94603\n",
      "Epoch: 3 | Iteration: 477 | Classification loss: 0.36151 | Regression loss: 0.61421 | Running loss: 0.94612\n",
      "Epoch: 3 | Iteration: 478 | Classification loss: 0.27109 | Regression loss: 0.51095 | Running loss: 0.94551\n",
      "Epoch: 3 | Iteration: 479 | Classification loss: 0.31081 | Regression loss: 0.65498 | Running loss: 0.94629\n",
      "Epoch: 3 | Iteration: 480 | Classification loss: 0.40643 | Regression loss: 0.77067 | Running loss: 0.94653\n",
      "Epoch: 3 | Iteration: 481 | Classification loss: 0.20508 | Regression loss: 0.41215 | Running loss: 0.94593\n",
      "Epoch: 3 | Iteration: 482 | Classification loss: 0.33227 | Regression loss: 0.68224 | Running loss: 0.94609\n",
      "Epoch: 3 | Iteration: 483 | Classification loss: 0.21728 | Regression loss: 0.50151 | Running loss: 0.94569\n",
      "Epoch: 3 | Iteration: 484 | Classification loss: 0.22472 | Regression loss: 0.53118 | Running loss: 0.94574\n",
      "Epoch: 3 | Iteration: 485 | Classification loss: 0.15110 | Regression loss: 0.43778 | Running loss: 0.94487\n",
      "Epoch: 3 | Iteration: 486 | Classification loss: 0.46206 | Regression loss: 0.77765 | Running loss: 0.94552\n",
      "Epoch: 3 | Iteration: 487 | Classification loss: 0.35731 | Regression loss: 0.80300 | Running loss: 0.94598\n",
      "Epoch: 3 | Iteration: 488 | Classification loss: 0.59949 | Regression loss: 0.70470 | Running loss: 0.94625\n",
      "Epoch: 3 | Iteration: 489 | Classification loss: 0.26974 | Regression loss: 0.62329 | Running loss: 0.94624\n",
      "Epoch: 3 | Iteration: 490 | Classification loss: 0.20745 | Regression loss: 0.67301 | Running loss: 0.94678\n",
      "Epoch: 3 | Iteration: 491 | Classification loss: 0.36820 | Regression loss: 0.76429 | Running loss: 0.94757\n",
      "Epoch: 3 | Iteration: 492 | Classification loss: 0.24842 | Regression loss: 0.58200 | Running loss: 0.94690\n",
      "Epoch: 3 | Iteration: 493 | Classification loss: 0.19656 | Regression loss: 0.35945 | Running loss: 0.94629\n",
      "Epoch: 3 | Iteration: 494 | Classification loss: 0.32340 | Regression loss: 0.72691 | Running loss: 0.94635\n",
      "Epoch: 3 | Iteration: 495 | Classification loss: 0.25978 | Regression loss: 0.72146 | Running loss: 0.94646\n",
      "Epoch: 3 | Iteration: 496 | Classification loss: 0.25185 | Regression loss: 0.46568 | Running loss: 0.94623\n",
      "Epoch: 3 | Iteration: 497 | Classification loss: 0.31229 | Regression loss: 0.62277 | Running loss: 0.94637\n",
      "Epoch: 3 | Iteration: 498 | Classification loss: 0.43180 | Regression loss: 0.70188 | Running loss: 0.94642\n",
      "Epoch: 3 | Iteration: 499 | Classification loss: 0.30522 | Regression loss: 0.64385 | Running loss: 0.94633\n",
      "Epoch: 3 | Iteration: 500 | Classification loss: 0.38289 | Regression loss: 0.76806 | Running loss: 0.94661\n",
      "Epoch: 3 | Iteration: 501 | Classification loss: 0.33270 | Regression loss: 0.64636 | Running loss: 0.94661\n",
      "Epoch: 3 | Iteration: 502 | Classification loss: 0.26419 | Regression loss: 0.40333 | Running loss: 0.94625\n",
      "Epoch: 3 | Iteration: 503 | Classification loss: 0.35136 | Regression loss: 0.67846 | Running loss: 0.94623\n",
      "Epoch: 3 | Iteration: 504 | Classification loss: 0.28086 | Regression loss: 0.49379 | Running loss: 0.94574\n",
      "Epoch: 3 | Iteration: 505 | Classification loss: 0.40720 | Regression loss: 0.59258 | Running loss: 0.94562\n",
      "Epoch: 3 | Iteration: 506 | Classification loss: 0.23664 | Regression loss: 0.54860 | Running loss: 0.94515\n",
      "Epoch: 3 | Iteration: 507 | Classification loss: 0.42430 | Regression loss: 0.74096 | Running loss: 0.94554\n",
      "Epoch: 3 | Iteration: 508 | Classification loss: 0.32536 | Regression loss: 0.67275 | Running loss: 0.94502\n",
      "Epoch: 3 | Iteration: 509 | Classification loss: 0.27818 | Regression loss: 0.50018 | Running loss: 0.94481\n",
      "Epoch: 3 | Iteration: 510 | Classification loss: 0.31390 | Regression loss: 0.59892 | Running loss: 0.94470\n",
      "Epoch: 3 | Iteration: 511 | Classification loss: 0.34243 | Regression loss: 0.59752 | Running loss: 0.94505\n",
      "Epoch: 3 | Iteration: 512 | Classification loss: 0.22533 | Regression loss: 0.52515 | Running loss: 0.94422\n",
      "Epoch: 3 | Iteration: 513 | Classification loss: 0.27693 | Regression loss: 0.67610 | Running loss: 0.94410\n",
      "Epoch: 3 | Iteration: 514 | Classification loss: 0.24618 | Regression loss: 0.54530 | Running loss: 0.94400\n",
      "Epoch: 3 | Iteration: 515 | Classification loss: 0.28206 | Regression loss: 0.62266 | Running loss: 0.94365\n",
      "Epoch: 3 | Iteration: 516 | Classification loss: 0.28364 | Regression loss: 0.64174 | Running loss: 0.94363\n",
      "Epoch: 3 | Iteration: 517 | Classification loss: 0.34763 | Regression loss: 0.52965 | Running loss: 0.94355\n",
      "Epoch: 3 | Iteration: 518 | Classification loss: 0.26474 | Regression loss: 0.76190 | Running loss: 0.94359\n",
      "Epoch: 3 | Iteration: 519 | Classification loss: 0.29513 | Regression loss: 0.66418 | Running loss: 0.94348\n",
      "Epoch: 3 | Iteration: 520 | Classification loss: 0.31661 | Regression loss: 0.66390 | Running loss: 0.94306\n",
      "Epoch: 3 | Iteration: 521 | Classification loss: 0.29355 | Regression loss: 0.67013 | Running loss: 0.94329\n",
      "Epoch: 3 | Iteration: 522 | Classification loss: 0.26194 | Regression loss: 0.52684 | Running loss: 0.94325\n",
      "Epoch: 3 | Iteration: 523 | Classification loss: 0.25550 | Regression loss: 0.54104 | Running loss: 0.94271\n",
      "Epoch: 3 | Iteration: 524 | Classification loss: 0.26633 | Regression loss: 0.60978 | Running loss: 0.94242\n",
      "Epoch: 3 | Iteration: 525 | Classification loss: 0.30334 | Regression loss: 0.66060 | Running loss: 0.94219\n",
      "Epoch: 3 | Iteration: 526 | Classification loss: 0.28985 | Regression loss: 0.64785 | Running loss: 0.94239\n",
      "Epoch: 3 | Iteration: 527 | Classification loss: 0.17439 | Regression loss: 0.51054 | Running loss: 0.94195\n",
      "Epoch: 3 | Iteration: 528 | Classification loss: 0.29628 | Regression loss: 0.70663 | Running loss: 0.94181\n",
      "Epoch: 3 | Iteration: 529 | Classification loss: 0.31102 | Regression loss: 0.68222 | Running loss: 0.94189\n",
      "Epoch: 3 | Iteration: 530 | Classification loss: 0.30542 | Regression loss: 0.68099 | Running loss: 0.94285\n",
      "Epoch: 3 | Iteration: 531 | Classification loss: 0.39728 | Regression loss: 0.81304 | Running loss: 0.94306\n",
      "Epoch: 3 | Iteration: 532 | Classification loss: 0.36326 | Regression loss: 0.77442 | Running loss: 0.94330\n",
      "Epoch: 3 | Iteration: 533 | Classification loss: 0.37006 | Regression loss: 0.57318 | Running loss: 0.94306\n",
      "Epoch: 3 | Iteration: 534 | Classification loss: 0.29546 | Regression loss: 0.69170 | Running loss: 0.94338\n",
      "Epoch: 3 | Iteration: 535 | Classification loss: 0.34477 | Regression loss: 0.71860 | Running loss: 0.94351\n",
      "Epoch: 3 | Iteration: 536 | Classification loss: 0.28006 | Regression loss: 0.61698 | Running loss: 0.94354\n",
      "Epoch: 3 | Iteration: 537 | Classification loss: 0.30580 | Regression loss: 0.64727 | Running loss: 0.94375\n",
      "Epoch: 3 | Iteration: 538 | Classification loss: 0.26714 | Regression loss: 0.65193 | Running loss: 0.94392\n",
      "Epoch: 3 | Iteration: 539 | Classification loss: 0.31243 | Regression loss: 0.79846 | Running loss: 0.94470\n",
      "Epoch: 3 | Iteration: 540 | Classification loss: 0.40739 | Regression loss: 0.65738 | Running loss: 0.94455\n",
      "Epoch: 3 | Iteration: 541 | Classification loss: 0.32271 | Regression loss: 0.76167 | Running loss: 0.94489\n",
      "Epoch: 3 | Iteration: 542 | Classification loss: 0.20628 | Regression loss: 0.56405 | Running loss: 0.94500\n",
      "Epoch: 3 | Iteration: 543 | Classification loss: 0.51314 | Regression loss: 0.69968 | Running loss: 0.94566\n",
      "Epoch: 3 | Iteration: 544 | Classification loss: 0.36436 | Regression loss: 0.68795 | Running loss: 0.94566\n",
      "Epoch: 3 | Iteration: 545 | Classification loss: 0.34349 | Regression loss: 0.77086 | Running loss: 0.94548\n",
      "Epoch: 3 | Iteration: 546 | Classification loss: 0.29631 | Regression loss: 0.60090 | Running loss: 0.94558\n",
      "Epoch: 3 | Iteration: 547 | Classification loss: 0.33348 | Regression loss: 0.59602 | Running loss: 0.94516\n",
      "Epoch: 3 | Iteration: 548 | Classification loss: 0.36239 | Regression loss: 0.62686 | Running loss: 0.94581\n",
      "Epoch: 3 | Iteration: 549 | Classification loss: 0.35748 | Regression loss: 0.73438 | Running loss: 0.94603\n",
      "Epoch: 3 | Iteration: 550 | Classification loss: 0.32146 | Regression loss: 0.61304 | Running loss: 0.94605\n",
      "Epoch: 3 | Iteration: 551 | Classification loss: 0.29327 | Regression loss: 0.65059 | Running loss: 0.94656\n",
      "Epoch: 3 | Iteration: 552 | Classification loss: 0.26866 | Regression loss: 0.66153 | Running loss: 0.94671\n",
      "Epoch: 3 | Iteration: 553 | Classification loss: 0.29049 | Regression loss: 0.56229 | Running loss: 0.94628\n",
      "Epoch: 3 | Iteration: 554 | Classification loss: 0.33629 | Regression loss: 0.61112 | Running loss: 0.94683\n",
      "Epoch: 3 | Iteration: 555 | Classification loss: 0.35666 | Regression loss: 0.64996 | Running loss: 0.94688\n",
      "Epoch: 3 | Iteration: 556 | Classification loss: 0.23530 | Regression loss: 0.56179 | Running loss: 0.94633\n",
      "Epoch: 3 | Iteration: 557 | Classification loss: 0.37485 | Regression loss: 0.63232 | Running loss: 0.94679\n",
      "Epoch: 3 | Iteration: 558 | Classification loss: 0.24870 | Regression loss: 0.57470 | Running loss: 0.94669\n",
      "Epoch: 3 | Iteration: 559 | Classification loss: 0.21795 | Regression loss: 0.52632 | Running loss: 0.94632\n",
      "Epoch: 3 | Iteration: 560 | Classification loss: 0.27435 | Regression loss: 0.54321 | Running loss: 0.94560\n",
      "Epoch: 3 | Iteration: 561 | Classification loss: 0.47644 | Regression loss: 0.87178 | Running loss: 0.94641\n",
      "Epoch: 3 | Iteration: 562 | Classification loss: 0.36413 | Regression loss: 0.80055 | Running loss: 0.94735\n",
      "Epoch: 3 | Iteration: 563 | Classification loss: 0.31618 | Regression loss: 0.77360 | Running loss: 0.94763\n",
      "Epoch: 3 | Iteration: 564 | Classification loss: 0.36848 | Regression loss: 0.65935 | Running loss: 0.94780\n",
      "Epoch: 3 | Iteration: 565 | Classification loss: 0.16000 | Regression loss: 0.47360 | Running loss: 0.94707\n",
      "Epoch: 3 | Iteration: 566 | Classification loss: 0.32340 | Regression loss: 0.47219 | Running loss: 0.94681\n",
      "Epoch: 3 | Iteration: 567 | Classification loss: 0.35015 | Regression loss: 0.70930 | Running loss: 0.94640\n",
      "Epoch: 3 | Iteration: 568 | Classification loss: 0.31816 | Regression loss: 0.43017 | Running loss: 0.94562\n",
      "Epoch: 3 | Iteration: 569 | Classification loss: 0.32943 | Regression loss: 0.58911 | Running loss: 0.94586\n",
      "Epoch: 3 | Iteration: 570 | Classification loss: 0.23088 | Regression loss: 0.55606 | Running loss: 0.94594\n",
      "Epoch: 3 | Iteration: 571 | Classification loss: 0.35828 | Regression loss: 0.60442 | Running loss: 0.94606\n",
      "Epoch: 3 | Iteration: 572 | Classification loss: 0.33380 | Regression loss: 0.74636 | Running loss: 0.94637\n",
      "Epoch: 3 | Iteration: 573 | Classification loss: 0.27634 | Regression loss: 0.54613 | Running loss: 0.94615\n",
      "Epoch: 3 | Iteration: 574 | Classification loss: 0.26259 | Regression loss: 0.73031 | Running loss: 0.94640\n",
      "Epoch: 3 | Iteration: 575 | Classification loss: 0.33823 | Regression loss: 0.69524 | Running loss: 0.94654\n",
      "Epoch: 3 | Iteration: 576 | Classification loss: 0.34859 | Regression loss: 0.69136 | Running loss: 0.94709\n",
      "Epoch: 3 | Iteration: 577 | Classification loss: 0.31474 | Regression loss: 0.68265 | Running loss: 0.94661\n",
      "Epoch: 3 | Iteration: 578 | Classification loss: 0.34768 | Regression loss: 0.60214 | Running loss: 0.94602\n",
      "Epoch: 3 | Iteration: 579 | Classification loss: 0.35711 | Regression loss: 0.75817 | Running loss: 0.94647\n",
      "Epoch: 3 | Iteration: 580 | Classification loss: 0.22966 | Regression loss: 0.51179 | Running loss: 0.94595\n",
      "Epoch: 3 | Iteration: 581 | Classification loss: 0.34809 | Regression loss: 0.55265 | Running loss: 0.94600\n",
      "Epoch: 3 | Iteration: 582 | Classification loss: 0.26059 | Regression loss: 0.64410 | Running loss: 0.94532\n",
      "Epoch: 3 | Iteration: 583 | Classification loss: 0.26518 | Regression loss: 0.49960 | Running loss: 0.94481\n",
      "Epoch: 3 | Iteration: 584 | Classification loss: 0.30401 | Regression loss: 0.66756 | Running loss: 0.94502\n",
      "Epoch: 3 | Iteration: 585 | Classification loss: 0.34841 | Regression loss: 0.63700 | Running loss: 0.94509\n",
      "Epoch: 3 | Iteration: 586 | Classification loss: 0.28725 | Regression loss: 0.68291 | Running loss: 0.94526\n",
      "Epoch: 3 | Iteration: 587 | Classification loss: 0.16760 | Regression loss: 0.51021 | Running loss: 0.94436\n",
      "Epoch: 3 | Iteration: 588 | Classification loss: 0.20452 | Regression loss: 0.47290 | Running loss: 0.94435\n",
      "Epoch: 3 | Iteration: 589 | Classification loss: 0.25491 | Regression loss: 0.54546 | Running loss: 0.94390\n",
      "Epoch: 3 | Iteration: 590 | Classification loss: 0.28404 | Regression loss: 0.63803 | Running loss: 0.94371\n",
      "Epoch: 3 | Iteration: 591 | Classification loss: 0.26646 | Regression loss: 0.62338 | Running loss: 0.94372\n",
      "Epoch: 3 | Iteration: 592 | Classification loss: 0.27905 | Regression loss: 0.52932 | Running loss: 0.94371\n",
      "Epoch: 3 | Iteration: 593 | Classification loss: 0.28459 | Regression loss: 0.64815 | Running loss: 0.94367\n",
      "Epoch: 3 | Iteration: 594 | Classification loss: 0.29834 | Regression loss: 0.60616 | Running loss: 0.94339\n",
      "Epoch: 3 | Iteration: 595 | Classification loss: 0.32092 | Regression loss: 0.60242 | Running loss: 0.94303\n",
      "Epoch: 3 | Iteration: 596 | Classification loss: 0.31660 | Regression loss: 0.63573 | Running loss: 0.94280\n",
      "Epoch: 3 | Iteration: 597 | Classification loss: 0.41141 | Regression loss: 0.71860 | Running loss: 0.94311\n",
      "Epoch: 3 | Iteration: 598 | Classification loss: 0.38559 | Regression loss: 0.78436 | Running loss: 0.94327\n",
      "Epoch: 3 | Iteration: 599 | Classification loss: 0.40689 | Regression loss: 0.71197 | Running loss: 0.94368\n",
      "Epoch: 3 | Iteration: 600 | Classification loss: 0.27323 | Regression loss: 0.72944 | Running loss: 0.94356\n",
      "Epoch: 3 | Iteration: 601 | Classification loss: 0.21707 | Regression loss: 0.61319 | Running loss: 0.94330\n",
      "Epoch: 3 | Iteration: 602 | Classification loss: 0.30236 | Regression loss: 0.72841 | Running loss: 0.94337\n",
      "Epoch: 3 | Iteration: 603 | Classification loss: 0.41002 | Regression loss: 0.72660 | Running loss: 0.94407\n",
      "Epoch: 3 | Iteration: 604 | Classification loss: 0.36869 | Regression loss: 0.76060 | Running loss: 0.94451\n",
      "Epoch: 3 | Iteration: 605 | Classification loss: 0.29060 | Regression loss: 0.70761 | Running loss: 0.94469\n",
      "Epoch: 3 | Iteration: 606 | Classification loss: 0.31347 | Regression loss: 0.66541 | Running loss: 0.94473\n",
      "Epoch: 3 | Iteration: 607 | Classification loss: 0.29288 | Regression loss: 0.67733 | Running loss: 0.94486\n",
      "Epoch: 3 | Iteration: 608 | Classification loss: 0.27622 | Regression loss: 0.54830 | Running loss: 0.94462\n",
      "Epoch: 3 | Iteration: 609 | Classification loss: 0.24095 | Regression loss: 0.57983 | Running loss: 0.94386\n",
      "Epoch: 3 | Iteration: 610 | Classification loss: 0.25990 | Regression loss: 0.65790 | Running loss: 0.94404\n",
      "Epoch: 3 | Iteration: 611 | Classification loss: 0.32769 | Regression loss: 0.67438 | Running loss: 0.94382\n",
      "Epoch: 3 | Iteration: 612 | Classification loss: 0.19722 | Regression loss: 0.51931 | Running loss: 0.94323\n",
      "Epoch: 3 | Iteration: 613 | Classification loss: 0.13219 | Regression loss: 0.45650 | Running loss: 0.94271\n",
      "Epoch: 3 | Iteration: 614 | Classification loss: 0.33127 | Regression loss: 0.72252 | Running loss: 0.94287\n",
      "Epoch: 3 | Iteration: 615 | Classification loss: 0.41149 | Regression loss: 0.63460 | Running loss: 0.94255\n",
      "Epoch: 3 | Iteration: 616 | Classification loss: 0.30908 | Regression loss: 0.70787 | Running loss: 0.94312\n",
      "Epoch: 3 | Iteration: 617 | Classification loss: 0.33732 | Regression loss: 0.71816 | Running loss: 0.94331\n",
      "Epoch: 3 | Iteration: 618 | Classification loss: 0.45457 | Regression loss: 0.75757 | Running loss: 0.94411\n",
      "Epoch: 3 | Iteration: 619 | Classification loss: 0.31739 | Regression loss: 0.66003 | Running loss: 0.94374\n",
      "Epoch: 3 | Iteration: 620 | Classification loss: 0.37363 | Regression loss: 0.79312 | Running loss: 0.94432\n",
      "Epoch: 3 | Iteration: 621 | Classification loss: 0.25172 | Regression loss: 0.50587 | Running loss: 0.94419\n",
      "Epoch: 3 | Iteration: 622 | Classification loss: 0.34045 | Regression loss: 0.70333 | Running loss: 0.94451\n",
      "Epoch: 3 | Iteration: 623 | Classification loss: 0.24299 | Regression loss: 0.58677 | Running loss: 0.94401\n",
      "Epoch: 3 | Iteration: 624 | Classification loss: 0.41931 | Regression loss: 0.81844 | Running loss: 0.94447\n",
      "Epoch: 3 | Iteration: 625 | Classification loss: 0.19831 | Regression loss: 0.56137 | Running loss: 0.94370\n",
      "Epoch: 3 | Iteration: 626 | Classification loss: 0.26340 | Regression loss: 0.62198 | Running loss: 0.94345\n",
      "Epoch: 3 | Iteration: 627 | Classification loss: 0.26446 | Regression loss: 0.51189 | Running loss: 0.94354\n",
      "Epoch: 3 | Iteration: 628 | Classification loss: 0.31641 | Regression loss: 0.66257 | Running loss: 0.94406\n",
      "Epoch: 3 | Iteration: 629 | Classification loss: 0.23895 | Regression loss: 0.62890 | Running loss: 0.94426\n",
      "Epoch: 3 | Iteration: 630 | Classification loss: 0.31863 | Regression loss: 0.71218 | Running loss: 0.94476\n",
      "Epoch: 3 | Iteration: 631 | Classification loss: 0.26254 | Regression loss: 0.74344 | Running loss: 0.94453\n",
      "Epoch: 3 | Iteration: 632 | Classification loss: 0.25434 | Regression loss: 0.49969 | Running loss: 0.94437\n",
      "Epoch: 3 | Iteration: 633 | Classification loss: 0.44313 | Regression loss: 0.78319 | Running loss: 0.94453\n",
      "Epoch: 3 | Iteration: 634 | Classification loss: 0.45354 | Regression loss: 0.59051 | Running loss: 0.94491\n",
      "Epoch: 3 | Iteration: 635 | Classification loss: 0.49717 | Regression loss: 0.82638 | Running loss: 0.94583\n",
      "Epoch: 3 | Iteration: 636 | Classification loss: 0.25847 | Regression loss: 0.56977 | Running loss: 0.94573\n",
      "Epoch: 3 | Iteration: 637 | Classification loss: 0.26430 | Regression loss: 0.62848 | Running loss: 0.94573\n",
      "Epoch: 3 | Iteration: 638 | Classification loss: 0.27186 | Regression loss: 0.57325 | Running loss: 0.94544\n",
      "Epoch: 3 | Iteration: 639 | Classification loss: 0.35048 | Regression loss: 0.63592 | Running loss: 0.94501\n",
      "Epoch: 3 | Iteration: 640 | Classification loss: 0.27074 | Regression loss: 0.60312 | Running loss: 0.94461\n",
      "Epoch: 3 | Iteration: 641 | Classification loss: 0.36148 | Regression loss: 0.58328 | Running loss: 0.94482\n",
      "Epoch: 3 | Iteration: 642 | Classification loss: 0.22388 | Regression loss: 0.50542 | Running loss: 0.94455\n",
      "Epoch: 3 | Iteration: 643 | Classification loss: 0.33573 | Regression loss: 0.69446 | Running loss: 0.94478\n",
      "Epoch: 3 | Iteration: 644 | Classification loss: 0.35171 | Regression loss: 0.68883 | Running loss: 0.94480\n",
      "Epoch: 3 | Iteration: 645 | Classification loss: 0.19605 | Regression loss: 0.51206 | Running loss: 0.94366\n",
      "Epoch: 3 | Iteration: 646 | Classification loss: 0.28409 | Regression loss: 0.62534 | Running loss: 0.94347\n",
      "Epoch: 3 | Iteration: 647 | Classification loss: 0.20739 | Regression loss: 0.53585 | Running loss: 0.94333\n",
      "Epoch: 3 | Iteration: 648 | Classification loss: 0.34594 | Regression loss: 0.79182 | Running loss: 0.94364\n",
      "Epoch: 3 | Iteration: 649 | Classification loss: 0.31915 | Regression loss: 0.39484 | Running loss: 0.94299\n",
      "Epoch: 3 | Iteration: 650 | Classification loss: 0.22489 | Regression loss: 0.54067 | Running loss: 0.94169\n",
      "Epoch: 3 | Iteration: 651 | Classification loss: 0.28006 | Regression loss: 0.52956 | Running loss: 0.94121\n",
      "Epoch: 3 | Iteration: 652 | Classification loss: 0.35063 | Regression loss: 0.65951 | Running loss: 0.94108\n",
      "Epoch: 3 | Iteration: 653 | Classification loss: 0.27882 | Regression loss: 0.55342 | Running loss: 0.94070\n",
      "Epoch: 3 | Iteration: 654 | Classification loss: 0.34712 | Regression loss: 0.71860 | Running loss: 0.94133\n",
      "Epoch: 3 | Iteration: 655 | Classification loss: 0.33460 | Regression loss: 0.70912 | Running loss: 0.94160\n",
      "Epoch: 3 | Iteration: 656 | Classification loss: 0.35849 | Regression loss: 0.67901 | Running loss: 0.94150\n",
      "Epoch: 3 | Iteration: 657 | Classification loss: 0.24306 | Regression loss: 0.64268 | Running loss: 0.94152\n",
      "Epoch: 3 | Iteration: 658 | Classification loss: 0.30960 | Regression loss: 0.61334 | Running loss: 0.94102\n",
      "Epoch: 3 | Iteration: 659 | Classification loss: 0.21768 | Regression loss: 0.48497 | Running loss: 0.94046\n",
      "Epoch: 3 | Iteration: 660 | Classification loss: 0.35394 | Regression loss: 0.61568 | Running loss: 0.94063\n",
      "Epoch: 3 | Iteration: 661 | Classification loss: 0.33044 | Regression loss: 0.61064 | Running loss: 0.94086\n",
      "Epoch: 3 | Iteration: 662 | Classification loss: 0.36219 | Regression loss: 0.70269 | Running loss: 0.94153\n",
      "Epoch: 3 | Iteration: 663 | Classification loss: 0.36891 | Regression loss: 0.68441 | Running loss: 0.94157\n",
      "Epoch: 3 | Iteration: 664 | Classification loss: 0.22080 | Regression loss: 0.46995 | Running loss: 0.94050\n",
      "Epoch: 3 | Iteration: 665 | Classification loss: 0.17221 | Regression loss: 0.40480 | Running loss: 0.94006\n",
      "Epoch: 3 | Iteration: 666 | Classification loss: 0.25717 | Regression loss: 0.63771 | Running loss: 0.94027\n",
      "Epoch: 3 | Iteration: 667 | Classification loss: 0.32733 | Regression loss: 0.67816 | Running loss: 0.94037\n",
      "Epoch: 3 | Iteration: 668 | Classification loss: 0.37005 | Regression loss: 0.67663 | Running loss: 0.94048\n",
      "Epoch: 3 | Iteration: 669 | Classification loss: 0.31124 | Regression loss: 0.71174 | Running loss: 0.94051\n",
      "Epoch: 3 | Iteration: 670 | Classification loss: 0.36122 | Regression loss: 0.64846 | Running loss: 0.94040\n",
      "Epoch: 3 | Iteration: 671 | Classification loss: 0.35260 | Regression loss: 0.69612 | Running loss: 0.94073\n",
      "Epoch: 3 | Iteration: 672 | Classification loss: 0.38573 | Regression loss: 0.68361 | Running loss: 0.94094\n",
      "Epoch: 3 | Iteration: 673 | Classification loss: 0.40382 | Regression loss: 0.69949 | Running loss: 0.94134\n",
      "Epoch: 3 | Iteration: 674 | Classification loss: 0.35269 | Regression loss: 0.67295 | Running loss: 0.94198\n",
      "Epoch: 3 | Iteration: 675 | Classification loss: 0.29977 | Regression loss: 0.56510 | Running loss: 0.94130\n",
      "Epoch: 3 | Iteration: 676 | Classification loss: 0.35347 | Regression loss: 0.72289 | Running loss: 0.94075\n",
      "Epoch: 3 | Iteration: 677 | Classification loss: 0.20958 | Regression loss: 0.48482 | Running loss: 0.93993\n",
      "Epoch: 3 | Iteration: 678 | Classification loss: 0.29513 | Regression loss: 0.53818 | Running loss: 0.93970\n",
      "Epoch: 3 | Iteration: 679 | Classification loss: 0.40072 | Regression loss: 0.88031 | Running loss: 0.94021\n",
      "Epoch: 3 | Iteration: 680 | Classification loss: 0.35587 | Regression loss: 0.82239 | Running loss: 0.94132\n",
      "Epoch: 3 | Iteration: 681 | Classification loss: 0.21039 | Regression loss: 0.54669 | Running loss: 0.94109\n",
      "Epoch: 3 | Iteration: 682 | Classification loss: 0.33398 | Regression loss: 0.59600 | Running loss: 0.94096\n",
      "Epoch: 3 | Iteration: 683 | Classification loss: 0.26257 | Regression loss: 0.64876 | Running loss: 0.94065\n",
      "Epoch: 3 | Iteration: 684 | Classification loss: 0.26131 | Regression loss: 0.64104 | Running loss: 0.94068\n",
      "Epoch: 3 | Iteration: 685 | Classification loss: 0.28921 | Regression loss: 0.75269 | Running loss: 0.94116\n",
      "Epoch: 3 | Iteration: 686 | Classification loss: 0.30952 | Regression loss: 0.78193 | Running loss: 0.94160\n",
      "Epoch: 3 | Iteration: 687 | Classification loss: 0.22923 | Regression loss: 0.59837 | Running loss: 0.94196\n",
      "Epoch: 3 | Iteration: 688 | Classification loss: 0.24350 | Regression loss: 0.56578 | Running loss: 0.94163\n",
      "Epoch: 3 | Iteration: 689 | Classification loss: 0.28215 | Regression loss: 0.59343 | Running loss: 0.94111\n",
      "Epoch: 3 | Iteration: 690 | Classification loss: 0.36232 | Regression loss: 0.72686 | Running loss: 0.94160\n",
      "Epoch: 3 | Iteration: 691 | Classification loss: 0.30530 | Regression loss: 0.66684 | Running loss: 0.94187\n",
      "Epoch: 3 | Iteration: 692 | Classification loss: 0.23030 | Regression loss: 0.63199 | Running loss: 0.94170\n",
      "Epoch: 3 | Iteration: 693 | Classification loss: 0.29875 | Regression loss: 0.65121 | Running loss: 0.94178\n",
      "Epoch: 3 | Iteration: 694 | Classification loss: 0.23164 | Regression loss: 0.63716 | Running loss: 0.94185\n",
      "Epoch: 3 | Iteration: 695 | Classification loss: 0.32706 | Regression loss: 0.73190 | Running loss: 0.94257\n",
      "Epoch: 3 | Iteration: 696 | Classification loss: 0.30624 | Regression loss: 0.64574 | Running loss: 0.94212\n",
      "Epoch: 3 | Iteration: 697 | Classification loss: 0.36161 | Regression loss: 0.64047 | Running loss: 0.94239\n",
      "Epoch: 3 | Iteration: 698 | Classification loss: 0.28940 | Regression loss: 0.61732 | Running loss: 0.94243\n",
      "Epoch: 3 | Iteration: 699 | Classification loss: 0.25162 | Regression loss: 0.63096 | Running loss: 0.94291\n",
      "Epoch: 3 | Iteration: 700 | Classification loss: 0.27385 | Regression loss: 0.56495 | Running loss: 0.94258\n",
      "Epoch: 3 | Iteration: 701 | Classification loss: 0.23589 | Regression loss: 0.51990 | Running loss: 0.94257\n",
      "Epoch: 3 | Iteration: 702 | Classification loss: 0.26189 | Regression loss: 0.65511 | Running loss: 0.94219\n",
      "Epoch: 3 | Iteration: 703 | Classification loss: 0.24785 | Regression loss: 0.46671 | Running loss: 0.94187\n",
      "Epoch: 3 | Iteration: 704 | Classification loss: 0.28741 | Regression loss: 0.74797 | Running loss: 0.94196\n",
      "Epoch: 3 | Iteration: 705 | Classification loss: 0.30310 | Regression loss: 0.61750 | Running loss: 0.94184\n",
      "Epoch: 3 | Iteration: 706 | Classification loss: 0.17498 | Regression loss: 0.54778 | Running loss: 0.94140\n",
      "Epoch: 3 | Iteration: 707 | Classification loss: 0.40473 | Regression loss: 0.76375 | Running loss: 0.94151\n",
      "Epoch: 3 | Iteration: 708 | Classification loss: 0.34035 | Regression loss: 0.87548 | Running loss: 0.94207\n",
      "Epoch: 3 | Iteration: 709 | Classification loss: 0.23681 | Regression loss: 0.61420 | Running loss: 0.94182\n",
      "Epoch: 3 | Iteration: 710 | Classification loss: 0.28549 | Regression loss: 0.50986 | Running loss: 0.94136\n",
      "Epoch: 3 | Iteration: 711 | Classification loss: 0.37053 | Regression loss: 0.73543 | Running loss: 0.94059\n",
      "Epoch: 3 | Iteration: 712 | Classification loss: 0.33555 | Regression loss: 0.69010 | Running loss: 0.94030\n",
      "Epoch: 3 | Iteration: 713 | Classification loss: 0.17067 | Regression loss: 0.44625 | Running loss: 0.93954\n",
      "Epoch: 3 | Iteration: 714 | Classification loss: 0.31461 | Regression loss: 0.67029 | Running loss: 0.93982\n",
      "Epoch: 3 | Iteration: 715 | Classification loss: 0.27443 | Regression loss: 0.58103 | Running loss: 0.93975\n",
      "Epoch: 3 | Iteration: 716 | Classification loss: 0.38536 | Regression loss: 0.80931 | Running loss: 0.94025\n",
      "Epoch: 3 | Iteration: 717 | Classification loss: 0.26144 | Regression loss: 0.66981 | Running loss: 0.93986\n",
      "Epoch: 3 | Iteration: 718 | Classification loss: 0.30554 | Regression loss: 0.49740 | Running loss: 0.94008\n",
      "Epoch: 3 | Iteration: 719 | Classification loss: 0.25749 | Regression loss: 0.67815 | Running loss: 0.94009\n",
      "Epoch: 3 | Iteration: 720 | Classification loss: 0.27379 | Regression loss: 0.53507 | Running loss: 0.93976\n",
      "Epoch: 3 | Iteration: 721 | Classification loss: 0.31863 | Regression loss: 0.45266 | Running loss: 0.93901\n",
      "Epoch: 3 | Iteration: 722 | Classification loss: 0.35653 | Regression loss: 0.60928 | Running loss: 0.93927\n",
      "Epoch: 3 | Iteration: 723 | Classification loss: 0.28517 | Regression loss: 0.61324 | Running loss: 0.93882\n",
      "Epoch: 3 | Iteration: 724 | Classification loss: 0.32940 | Regression loss: 0.66754 | Running loss: 0.93820\n",
      "Epoch: 3 | Iteration: 725 | Classification loss: 0.32735 | Regression loss: 0.74667 | Running loss: 0.93787\n",
      "Epoch: 3 | Iteration: 726 | Classification loss: 0.33273 | Regression loss: 0.70191 | Running loss: 0.93779\n",
      "Epoch: 3 | Iteration: 727 | Classification loss: 0.23236 | Regression loss: 0.51800 | Running loss: 0.93730\n",
      "Epoch: 3 | Iteration: 728 | Classification loss: 0.30406 | Regression loss: 0.65814 | Running loss: 0.93746\n",
      "Epoch: 3 | Iteration: 729 | Classification loss: 0.21704 | Regression loss: 0.62464 | Running loss: 0.93719\n",
      "Epoch: 3 | Iteration: 730 | Classification loss: 0.32596 | Regression loss: 0.75342 | Running loss: 0.93734\n",
      "Epoch: 3 | Iteration: 731 | Classification loss: 0.31935 | Regression loss: 0.67032 | Running loss: 0.93780\n",
      "Epoch: 3 | Iteration: 732 | Classification loss: 0.30137 | Regression loss: 0.55804 | Running loss: 0.93790\n",
      "Epoch: 3 | Iteration: 733 | Classification loss: 0.36323 | Regression loss: 0.72011 | Running loss: 0.93796\n",
      "Epoch: 3 | Iteration: 734 | Classification loss: 0.21967 | Regression loss: 0.66079 | Running loss: 0.93766\n",
      "Epoch: 3 | Iteration: 735 | Classification loss: 0.36862 | Regression loss: 0.80187 | Running loss: 0.93844\n",
      "Epoch: 3 | Iteration: 736 | Classification loss: 0.29198 | Regression loss: 0.65975 | Running loss: 0.93797\n",
      "Epoch: 3 | Iteration: 737 | Classification loss: 0.42133 | Regression loss: 0.56010 | Running loss: 0.93832\n",
      "Epoch: 3 | Iteration: 738 | Classification loss: 0.38996 | Regression loss: 0.63902 | Running loss: 0.93833\n",
      "Epoch: 3 | Iteration: 739 | Classification loss: 0.28877 | Regression loss: 0.63909 | Running loss: 0.93822\n",
      "Epoch: 3 | Iteration: 740 | Classification loss: 0.33720 | Regression loss: 0.73797 | Running loss: 0.93833\n",
      "Epoch: 3 | Iteration: 741 | Classification loss: 0.35926 | Regression loss: 0.63409 | Running loss: 0.93848\n",
      "Epoch: 3 | Iteration: 742 | Classification loss: 0.25345 | Regression loss: 0.62432 | Running loss: 0.93873\n",
      "Epoch: 3 | Iteration: 743 | Classification loss: 0.24454 | Regression loss: 0.52249 | Running loss: 0.93818\n",
      "Epoch: 3 | Iteration: 744 | Classification loss: 0.26943 | Regression loss: 0.50527 | Running loss: 0.93776\n",
      "Epoch: 3 | Iteration: 745 | Classification loss: 0.50820 | Regression loss: 0.71652 | Running loss: 0.93836\n",
      "Epoch: 3 | Iteration: 746 | Classification loss: 0.37545 | Regression loss: 0.67553 | Running loss: 0.93870\n",
      "Epoch: 3 | Iteration: 747 | Classification loss: 0.36567 | Regression loss: 0.74884 | Running loss: 0.93947\n",
      "Epoch: 3 | Iteration: 748 | Classification loss: 0.37040 | Regression loss: 0.72627 | Running loss: 0.93946\n",
      "Epoch: 3 | Iteration: 749 | Classification loss: 0.29965 | Regression loss: 0.69923 | Running loss: 0.93997\n",
      "Epoch: 3 | Iteration: 750 | Classification loss: 0.40134 | Regression loss: 0.80466 | Running loss: 0.94096\n",
      "Epoch: 3 | Iteration: 751 | Classification loss: 0.27059 | Regression loss: 0.53521 | Running loss: 0.94035\n",
      "Epoch: 3 | Iteration: 752 | Classification loss: 0.34020 | Regression loss: 0.67964 | Running loss: 0.94029\n",
      "Epoch: 3 | Iteration: 753 | Classification loss: 0.31276 | Regression loss: 0.63662 | Running loss: 0.94051\n",
      "Epoch: 3 | Iteration: 754 | Classification loss: 0.32547 | Regression loss: 0.52041 | Running loss: 0.94020\n",
      "Epoch: 3 | Iteration: 755 | Classification loss: 0.28957 | Regression loss: 0.73925 | Running loss: 0.94044\n",
      "Epoch: 3 | Iteration: 756 | Classification loss: 0.29696 | Regression loss: 0.55707 | Running loss: 0.93997\n",
      "Epoch: 3 | Iteration: 757 | Classification loss: 0.34065 | Regression loss: 0.69748 | Running loss: 0.94014\n",
      "Epoch: 3 | Iteration: 758 | Classification loss: 0.26042 | Regression loss: 0.55424 | Running loss: 0.94019\n",
      "Epoch: 3 | Iteration: 759 | Classification loss: 0.23087 | Regression loss: 0.59618 | Running loss: 0.93931\n",
      "Epoch: 3 | Iteration: 760 | Classification loss: 0.26756 | Regression loss: 0.69126 | Running loss: 0.93918\n",
      "Epoch: 3 | Iteration: 761 | Classification loss: 0.28758 | Regression loss: 0.61413 | Running loss: 0.93888\n",
      "Epoch: 3 | Iteration: 762 | Classification loss: 0.25327 | Regression loss: 0.59761 | Running loss: 0.93841\n",
      "Epoch: 3 | Iteration: 763 | Classification loss: 0.31136 | Regression loss: 0.51720 | Running loss: 0.93885\n",
      "Epoch: 3 | Iteration: 764 | Classification loss: 0.33139 | Regression loss: 0.74301 | Running loss: 0.93990\n",
      "Epoch: 3 | Iteration: 765 | Classification loss: 0.39713 | Regression loss: 0.69329 | Running loss: 0.94031\n",
      "Epoch: 3 | Iteration: 766 | Classification loss: 0.28300 | Regression loss: 0.61665 | Running loss: 0.94033\n",
      "Epoch: 3 | Iteration: 767 | Classification loss: 0.29109 | Regression loss: 0.63463 | Running loss: 0.94065\n",
      "Epoch: 3 | Iteration: 768 | Classification loss: 0.35286 | Regression loss: 0.73977 | Running loss: 0.94068\n",
      "Epoch: 3 | Iteration: 769 | Classification loss: 0.27992 | Regression loss: 0.63896 | Running loss: 0.94027\n",
      "Epoch: 3 | Iteration: 770 | Classification loss: 0.29101 | Regression loss: 0.66439 | Running loss: 0.94035\n",
      "Epoch: 3 | Iteration: 771 | Classification loss: 0.27192 | Regression loss: 0.60734 | Running loss: 0.94009\n",
      "Epoch: 3 | Iteration: 772 | Classification loss: 0.30747 | Regression loss: 0.64586 | Running loss: 0.94009\n",
      "Epoch: 3 | Iteration: 773 | Classification loss: 0.22379 | Regression loss: 0.47635 | Running loss: 0.93922\n",
      "Epoch: 3 | Iteration: 774 | Classification loss: 0.25008 | Regression loss: 0.53385 | Running loss: 0.93854\n",
      "Epoch: 3 | Iteration: 775 | Classification loss: 0.23980 | Regression loss: 0.46053 | Running loss: 0.93812\n",
      "Epoch: 3 | Iteration: 776 | Classification loss: 0.34256 | Regression loss: 0.74646 | Running loss: 0.93838\n",
      "Epoch: 3 | Iteration: 777 | Classification loss: 0.29843 | Regression loss: 0.62917 | Running loss: 0.93851\n",
      "Epoch: 3 | Iteration: 778 | Classification loss: 0.59943 | Regression loss: 0.64667 | Running loss: 0.93859\n",
      "Epoch: 3 | Iteration: 779 | Classification loss: 0.19186 | Regression loss: 0.44115 | Running loss: 0.93780\n",
      "Epoch: 3 | Iteration: 780 | Classification loss: 0.29100 | Regression loss: 0.71523 | Running loss: 0.93760\n",
      "Epoch: 3 | Iteration: 781 | Classification loss: 0.18462 | Regression loss: 0.40657 | Running loss: 0.93670\n",
      "Epoch: 3 | Iteration: 782 | Classification loss: 0.33432 | Regression loss: 0.74890 | Running loss: 0.93712\n",
      "Epoch: 3 | Iteration: 783 | Classification loss: 0.26212 | Regression loss: 0.42607 | Running loss: 0.93690\n",
      "Evaluating dataset\n",
      "\n",
      "mAP:\n",
      "person: 0.3792975298362664\n",
      "Precision:  0.04047505085557018\n",
      "Recall:  0.768313458262351\n",
      "car: 0.4746530852989523\n",
      "Precision:  0.04047505085557018\n",
      "Recall:  0.768313458262351\n",
      "Epoch: 4 | Iteration: 0 | Classification loss: 0.27442 | Regression loss: 0.57545 | Running loss: 0.93649\n",
      "Epoch: 4 | Iteration: 1 | Classification loss: 0.22330 | Regression loss: 0.47687 | Running loss: 0.93581\n",
      "Epoch: 4 | Iteration: 2 | Classification loss: 0.27534 | Regression loss: 0.54985 | Running loss: 0.93572\n",
      "Epoch: 4 | Iteration: 3 | Classification loss: 0.30726 | Regression loss: 0.68124 | Running loss: 0.93603\n",
      "Epoch: 4 | Iteration: 4 | Classification loss: 0.28086 | Regression loss: 0.55473 | Running loss: 0.93605\n",
      "Epoch: 4 | Iteration: 5 | Classification loss: 0.27361 | Regression loss: 0.53365 | Running loss: 0.93583\n",
      "Epoch: 4 | Iteration: 6 | Classification loss: 0.22777 | Regression loss: 0.55778 | Running loss: 0.93566\n",
      "Epoch: 4 | Iteration: 7 | Classification loss: 0.34188 | Regression loss: 0.68783 | Running loss: 0.93530\n",
      "Epoch: 4 | Iteration: 8 | Classification loss: 0.20003 | Regression loss: 0.48586 | Running loss: 0.93499\n",
      "Epoch: 4 | Iteration: 9 | Classification loss: 0.18115 | Regression loss: 0.50334 | Running loss: 0.93460\n",
      "Epoch: 4 | Iteration: 10 | Classification loss: 0.14043 | Regression loss: 0.46058 | Running loss: 0.93403\n",
      "Epoch: 4 | Iteration: 11 | Classification loss: 0.16599 | Regression loss: 0.40552 | Running loss: 0.93285\n",
      "Epoch: 4 | Iteration: 12 | Classification loss: 0.24216 | Regression loss: 0.53403 | Running loss: 0.93270\n",
      "Epoch: 4 | Iteration: 13 | Classification loss: 0.29720 | Regression loss: 0.63360 | Running loss: 0.93280\n",
      "Epoch: 4 | Iteration: 14 | Classification loss: 0.26528 | Regression loss: 0.53081 | Running loss: 0.93249\n",
      "Epoch: 4 | Iteration: 15 | Classification loss: 0.26116 | Regression loss: 0.60547 | Running loss: 0.93261\n",
      "Epoch: 4 | Iteration: 16 | Classification loss: 0.30862 | Regression loss: 0.63593 | Running loss: 0.93305\n",
      "Epoch: 4 | Iteration: 17 | Classification loss: 0.28401 | Regression loss: 0.54083 | Running loss: 0.93300\n",
      "Epoch: 4 | Iteration: 18 | Classification loss: 0.20830 | Regression loss: 0.58861 | Running loss: 0.93252\n",
      "Epoch: 4 | Iteration: 19 | Classification loss: 0.41698 | Regression loss: 0.52568 | Running loss: 0.93291\n",
      "Epoch: 4 | Iteration: 20 | Classification loss: 0.24099 | Regression loss: 0.52062 | Running loss: 0.93253\n",
      "Epoch: 4 | Iteration: 21 | Classification loss: 0.28495 | Regression loss: 0.71603 | Running loss: 0.93283\n",
      "Epoch: 4 | Iteration: 22 | Classification loss: 0.33776 | Regression loss: 0.69107 | Running loss: 0.93335\n",
      "Epoch: 4 | Iteration: 23 | Classification loss: 0.18254 | Regression loss: 0.56165 | Running loss: 0.93283\n",
      "Epoch: 4 | Iteration: 24 | Classification loss: 0.33343 | Regression loss: 0.68857 | Running loss: 0.93287\n",
      "Epoch: 4 | Iteration: 25 | Classification loss: 0.28105 | Regression loss: 0.58124 | Running loss: 0.93284\n",
      "Epoch: 4 | Iteration: 26 | Classification loss: 0.43244 | Regression loss: 0.80120 | Running loss: 0.93344\n",
      "Epoch: 4 | Iteration: 27 | Classification loss: 0.36161 | Regression loss: 0.63270 | Running loss: 0.93341\n",
      "Epoch: 4 | Iteration: 28 | Classification loss: 0.12822 | Regression loss: 0.39292 | Running loss: 0.93251\n",
      "Epoch: 4 | Iteration: 29 | Classification loss: 0.25666 | Regression loss: 0.61614 | Running loss: 0.93247\n",
      "Epoch: 4 | Iteration: 30 | Classification loss: 0.27122 | Regression loss: 0.62215 | Running loss: 0.93252\n",
      "Epoch: 4 | Iteration: 31 | Classification loss: 0.18434 | Regression loss: 0.49853 | Running loss: 0.93247\n",
      "Epoch: 4 | Iteration: 32 | Classification loss: 0.27189 | Regression loss: 0.68985 | Running loss: 0.93283\n",
      "Epoch: 4 | Iteration: 33 | Classification loss: 0.36228 | Regression loss: 0.68103 | Running loss: 0.93268\n",
      "Epoch: 4 | Iteration: 34 | Classification loss: 0.21490 | Regression loss: 0.43498 | Running loss: 0.93200\n",
      "Epoch: 4 | Iteration: 35 | Classification loss: 0.39359 | Regression loss: 0.61601 | Running loss: 0.93194\n",
      "Epoch: 4 | Iteration: 36 | Classification loss: 0.33915 | Regression loss: 0.79723 | Running loss: 0.93246\n",
      "Epoch: 4 | Iteration: 37 | Classification loss: 0.19146 | Regression loss: 0.50237 | Running loss: 0.93172\n",
      "Epoch: 4 | Iteration: 38 | Classification loss: 0.37036 | Regression loss: 0.71583 | Running loss: 0.93209\n",
      "Epoch: 4 | Iteration: 39 | Classification loss: 0.17374 | Regression loss: 0.55612 | Running loss: 0.93150\n",
      "Epoch: 4 | Iteration: 40 | Classification loss: 0.19731 | Regression loss: 0.50785 | Running loss: 0.93094\n",
      "Epoch: 4 | Iteration: 41 | Classification loss: 0.25572 | Regression loss: 0.65973 | Running loss: 0.93024\n",
      "Epoch: 4 | Iteration: 42 | Classification loss: 0.28920 | Regression loss: 0.62498 | Running loss: 0.93018\n",
      "Epoch: 4 | Iteration: 43 | Classification loss: 0.21589 | Regression loss: 0.57485 | Running loss: 0.92974\n",
      "Epoch: 4 | Iteration: 44 | Classification loss: 0.27741 | Regression loss: 0.64699 | Running loss: 0.92993\n",
      "Epoch: 4 | Iteration: 45 | Classification loss: 0.21400 | Regression loss: 0.51281 | Running loss: 0.92966\n",
      "Epoch: 4 | Iteration: 46 | Classification loss: 0.23427 | Regression loss: 0.56493 | Running loss: 0.92937\n",
      "Epoch: 4 | Iteration: 47 | Classification loss: 0.30595 | Regression loss: 0.60296 | Running loss: 0.92910\n",
      "Epoch: 4 | Iteration: 48 | Classification loss: 0.10284 | Regression loss: 0.30550 | Running loss: 0.92753\n",
      "Epoch: 4 | Iteration: 49 | Classification loss: 0.31114 | Regression loss: 0.77259 | Running loss: 0.92749\n",
      "Epoch: 4 | Iteration: 50 | Classification loss: 0.29510 | Regression loss: 0.58870 | Running loss: 0.92806\n",
      "Epoch: 4 | Iteration: 51 | Classification loss: 0.27912 | Regression loss: 0.61399 | Running loss: 0.92825\n",
      "Epoch: 4 | Iteration: 52 | Classification loss: 0.35473 | Regression loss: 0.71562 | Running loss: 0.92861\n",
      "Epoch: 4 | Iteration: 53 | Classification loss: 0.35245 | Regression loss: 0.69990 | Running loss: 0.92895\n",
      "Epoch: 4 | Iteration: 54 | Classification loss: 0.31107 | Regression loss: 0.72602 | Running loss: 0.92933\n",
      "Epoch: 4 | Iteration: 55 | Classification loss: 0.26596 | Regression loss: 0.62646 | Running loss: 0.92900\n",
      "Epoch: 4 | Iteration: 56 | Classification loss: 0.30852 | Regression loss: 0.66689 | Running loss: 0.92956\n",
      "Epoch: 4 | Iteration: 57 | Classification loss: 0.32804 | Regression loss: 0.65858 | Running loss: 0.92920\n",
      "Epoch: 4 | Iteration: 58 | Classification loss: 0.22872 | Regression loss: 0.54197 | Running loss: 0.92876\n",
      "Epoch: 4 | Iteration: 59 | Classification loss: 0.29273 | Regression loss: 0.69777 | Running loss: 0.92874\n",
      "Epoch: 4 | Iteration: 60 | Classification loss: 0.24820 | Regression loss: 0.63486 | Running loss: 0.92889\n",
      "Epoch: 4 | Iteration: 61 | Classification loss: 0.21931 | Regression loss: 0.60317 | Running loss: 0.92917\n",
      "Epoch: 4 | Iteration: 62 | Classification loss: 0.25612 | Regression loss: 0.62630 | Running loss: 0.92880\n",
      "Epoch: 4 | Iteration: 63 | Classification loss: 0.25447 | Regression loss: 0.72443 | Running loss: 0.92955\n",
      "Epoch: 4 | Iteration: 64 | Classification loss: 0.22712 | Regression loss: 0.45919 | Running loss: 0.92881\n",
      "Epoch: 4 | Iteration: 65 | Classification loss: 0.21816 | Regression loss: 0.55269 | Running loss: 0.92846\n",
      "Epoch: 4 | Iteration: 66 | Classification loss: 0.28457 | Regression loss: 0.54932 | Running loss: 0.92874\n",
      "Epoch: 4 | Iteration: 67 | Classification loss: 0.28042 | Regression loss: 0.72335 | Running loss: 0.92823\n",
      "Epoch: 4 | Iteration: 68 | Classification loss: 0.24160 | Regression loss: 0.52732 | Running loss: 0.92760\n",
      "Epoch: 4 | Iteration: 69 | Classification loss: 0.25016 | Regression loss: 0.53415 | Running loss: 0.92746\n",
      "Epoch: 4 | Iteration: 70 | Classification loss: 0.24271 | Regression loss: 0.59174 | Running loss: 0.92759\n",
      "Epoch: 4 | Iteration: 71 | Classification loss: 0.30538 | Regression loss: 0.70692 | Running loss: 0.92815\n",
      "Epoch: 4 | Iteration: 72 | Classification loss: 0.36258 | Regression loss: 0.61184 | Running loss: 0.92837\n",
      "Epoch: 4 | Iteration: 73 | Classification loss: 0.24394 | Regression loss: 0.66798 | Running loss: 0.92851\n",
      "Epoch: 4 | Iteration: 74 | Classification loss: 0.31940 | Regression loss: 0.69109 | Running loss: 0.92867\n",
      "Epoch: 4 | Iteration: 75 | Classification loss: 0.27754 | Regression loss: 0.64861 | Running loss: 0.92853\n",
      "Epoch: 4 | Iteration: 76 | Classification loss: 0.16942 | Regression loss: 0.42000 | Running loss: 0.92797\n",
      "Epoch: 4 | Iteration: 77 | Classification loss: 0.22779 | Regression loss: 0.58535 | Running loss: 0.92746\n",
      "Epoch: 4 | Iteration: 78 | Classification loss: 0.29773 | Regression loss: 0.56230 | Running loss: 0.92717\n",
      "Epoch: 4 | Iteration: 79 | Classification loss: 0.28698 | Regression loss: 0.71330 | Running loss: 0.92713\n",
      "Epoch: 4 | Iteration: 80 | Classification loss: 0.33879 | Regression loss: 0.70127 | Running loss: 0.92746\n",
      "Epoch: 4 | Iteration: 81 | Classification loss: 0.24067 | Regression loss: 0.60910 | Running loss: 0.92727\n",
      "Epoch: 4 | Iteration: 82 | Classification loss: 0.20390 | Regression loss: 0.58582 | Running loss: 0.92718\n",
      "Epoch: 4 | Iteration: 83 | Classification loss: 0.24937 | Regression loss: 0.65147 | Running loss: 0.92700\n",
      "Epoch: 4 | Iteration: 84 | Classification loss: 0.44170 | Regression loss: 0.61026 | Running loss: 0.92721\n",
      "Epoch: 4 | Iteration: 85 | Classification loss: 0.20201 | Regression loss: 0.52388 | Running loss: 0.92641\n",
      "Epoch: 4 | Iteration: 86 | Classification loss: 0.19804 | Regression loss: 0.64264 | Running loss: 0.92637\n",
      "Epoch: 4 | Iteration: 87 | Classification loss: 0.35806 | Regression loss: 0.78073 | Running loss: 0.92670\n",
      "Epoch: 4 | Iteration: 88 | Classification loss: 0.36870 | Regression loss: 0.63262 | Running loss: 0.92669\n",
      "Epoch: 4 | Iteration: 89 | Classification loss: 0.24060 | Regression loss: 0.58047 | Running loss: 0.92599\n",
      "Epoch: 4 | Iteration: 90 | Classification loss: 0.23917 | Regression loss: 0.56582 | Running loss: 0.92551\n",
      "Epoch: 4 | Iteration: 91 | Classification loss: 0.22358 | Regression loss: 0.54963 | Running loss: 0.92571\n",
      "Epoch: 4 | Iteration: 92 | Classification loss: 0.29570 | Regression loss: 0.56428 | Running loss: 0.92549\n",
      "Epoch: 4 | Iteration: 93 | Classification loss: 0.27009 | Regression loss: 0.69123 | Running loss: 0.92572\n",
      "Epoch: 4 | Iteration: 94 | Classification loss: 0.25073 | Regression loss: 0.63832 | Running loss: 0.92571\n",
      "Epoch: 4 | Iteration: 95 | Classification loss: 0.23234 | Regression loss: 0.56591 | Running loss: 0.92583\n",
      "Epoch: 4 | Iteration: 96 | Classification loss: 0.28865 | Regression loss: 0.64219 | Running loss: 0.92554\n",
      "Epoch: 4 | Iteration: 97 | Classification loss: 0.37105 | Regression loss: 0.78383 | Running loss: 0.92608\n",
      "Epoch: 4 | Iteration: 98 | Classification loss: 0.26839 | Regression loss: 0.59972 | Running loss: 0.92631\n",
      "Epoch: 4 | Iteration: 99 | Classification loss: 0.30791 | Regression loss: 0.45865 | Running loss: 0.92582\n",
      "Epoch: 4 | Iteration: 100 | Classification loss: 0.26859 | Regression loss: 0.52087 | Running loss: 0.92573\n",
      "Epoch: 4 | Iteration: 101 | Classification loss: 0.25842 | Regression loss: 0.53884 | Running loss: 0.92521\n",
      "Epoch: 4 | Iteration: 102 | Classification loss: 0.23027 | Regression loss: 0.63782 | Running loss: 0.92486\n",
      "Epoch: 4 | Iteration: 103 | Classification loss: 0.37259 | Regression loss: 0.55672 | Running loss: 0.92473\n",
      "Epoch: 4 | Iteration: 104 | Classification loss: 0.26636 | Regression loss: 0.48921 | Running loss: 0.92463\n",
      "Epoch: 4 | Iteration: 105 | Classification loss: 0.24523 | Regression loss: 0.54849 | Running loss: 0.92508\n",
      "Epoch: 4 | Iteration: 106 | Classification loss: 0.24672 | Regression loss: 0.41268 | Running loss: 0.92481\n",
      "Epoch: 4 | Iteration: 107 | Classification loss: 0.25939 | Regression loss: 0.61997 | Running loss: 0.92462\n",
      "Epoch: 4 | Iteration: 108 | Classification loss: 0.28987 | Regression loss: 0.59080 | Running loss: 0.92474\n",
      "Epoch: 4 | Iteration: 109 | Classification loss: 0.15755 | Regression loss: 0.49874 | Running loss: 0.92427\n",
      "Epoch: 4 | Iteration: 110 | Classification loss: 0.21644 | Regression loss: 0.52332 | Running loss: 0.92476\n",
      "Epoch: 4 | Iteration: 111 | Classification loss: 0.18346 | Regression loss: 0.44692 | Running loss: 0.92440\n",
      "Epoch: 4 | Iteration: 112 | Classification loss: 0.25200 | Regression loss: 0.59319 | Running loss: 0.92408\n",
      "Epoch: 4 | Iteration: 113 | Classification loss: 0.29374 | Regression loss: 0.56060 | Running loss: 0.92433\n",
      "Epoch: 4 | Iteration: 114 | Classification loss: 0.29091 | Regression loss: 0.56585 | Running loss: 0.92429\n",
      "Epoch: 4 | Iteration: 115 | Classification loss: 0.24043 | Regression loss: 0.57526 | Running loss: 0.92417\n",
      "Epoch: 4 | Iteration: 116 | Classification loss: 0.37796 | Regression loss: 0.73633 | Running loss: 0.92421\n",
      "Epoch: 4 | Iteration: 117 | Classification loss: 0.31115 | Regression loss: 0.62116 | Running loss: 0.92434\n",
      "Epoch: 4 | Iteration: 118 | Classification loss: 0.20483 | Regression loss: 0.58253 | Running loss: 0.92384\n",
      "Epoch: 4 | Iteration: 119 | Classification loss: 0.41919 | Regression loss: 0.68258 | Running loss: 0.92423\n",
      "Epoch: 4 | Iteration: 120 | Classification loss: 0.29976 | Regression loss: 0.65378 | Running loss: 0.92415\n",
      "Epoch: 4 | Iteration: 121 | Classification loss: 0.33220 | Regression loss: 0.71701 | Running loss: 0.92463\n",
      "Epoch: 4 | Iteration: 122 | Classification loss: 0.31376 | Regression loss: 0.62037 | Running loss: 0.92490\n",
      "Epoch: 4 | Iteration: 123 | Classification loss: 0.28194 | Regression loss: 0.59941 | Running loss: 0.92532\n",
      "Epoch: 4 | Iteration: 124 | Classification loss: 0.21458 | Regression loss: 0.53881 | Running loss: 0.92356\n",
      "Epoch: 4 | Iteration: 125 | Classification loss: 0.27281 | Regression loss: 0.60881 | Running loss: 0.92389\n",
      "Epoch: 4 | Iteration: 126 | Classification loss: 0.14577 | Regression loss: 0.36396 | Running loss: 0.92327\n",
      "Epoch: 4 | Iteration: 127 | Classification loss: 0.35501 | Regression loss: 0.60308 | Running loss: 0.92376\n",
      "Epoch: 4 | Iteration: 128 | Classification loss: 0.30700 | Regression loss: 0.72373 | Running loss: 0.92387\n",
      "Epoch: 4 | Iteration: 129 | Classification loss: 0.33795 | Regression loss: 0.65303 | Running loss: 0.92375\n",
      "Epoch: 4 | Iteration: 130 | Classification loss: 0.26853 | Regression loss: 0.57755 | Running loss: 0.92378\n",
      "Epoch: 4 | Iteration: 131 | Classification loss: 0.30168 | Regression loss: 0.56581 | Running loss: 0.92332\n",
      "Epoch: 4 | Iteration: 132 | Classification loss: 0.25500 | Regression loss: 0.62240 | Running loss: 0.92343\n",
      "Epoch: 4 | Iteration: 133 | Classification loss: 0.31256 | Regression loss: 0.69875 | Running loss: 0.92329\n",
      "Epoch: 4 | Iteration: 134 | Classification loss: 0.28860 | Regression loss: 0.53103 | Running loss: 0.92313\n",
      "Epoch: 4 | Iteration: 135 | Classification loss: 0.18594 | Regression loss: 0.50359 | Running loss: 0.92272\n",
      "Epoch: 4 | Iteration: 136 | Classification loss: 0.20972 | Regression loss: 0.48421 | Running loss: 0.92234\n",
      "Epoch: 4 | Iteration: 137 | Classification loss: 0.19080 | Regression loss: 0.50512 | Running loss: 0.92188\n",
      "Epoch: 4 | Iteration: 138 | Classification loss: 0.35085 | Regression loss: 0.79141 | Running loss: 0.92191\n",
      "Epoch: 4 | Iteration: 139 | Classification loss: 0.31648 | Regression loss: 0.57182 | Running loss: 0.92199\n",
      "Epoch: 4 | Iteration: 140 | Classification loss: 0.31746 | Regression loss: 0.74095 | Running loss: 0.92276\n",
      "Epoch: 4 | Iteration: 141 | Classification loss: 0.31365 | Regression loss: 0.68890 | Running loss: 0.92303\n",
      "Epoch: 4 | Iteration: 142 | Classification loss: 0.31771 | Regression loss: 0.75050 | Running loss: 0.92303\n",
      "Epoch: 4 | Iteration: 143 | Classification loss: 0.24092 | Regression loss: 0.56412 | Running loss: 0.92310\n",
      "Epoch: 4 | Iteration: 144 | Classification loss: 0.26620 | Regression loss: 0.65338 | Running loss: 0.92304\n",
      "Epoch: 4 | Iteration: 145 | Classification loss: 0.28605 | Regression loss: 0.64693 | Running loss: 0.92303\n",
      "Epoch: 4 | Iteration: 146 | Classification loss: 0.30128 | Regression loss: 0.66772 | Running loss: 0.92361\n",
      "Epoch: 4 | Iteration: 147 | Classification loss: 0.26046 | Regression loss: 0.57166 | Running loss: 0.92320\n",
      "Epoch: 4 | Iteration: 148 | Classification loss: 0.29399 | Regression loss: 0.64100 | Running loss: 0.92315\n",
      "Epoch: 4 | Iteration: 149 | Classification loss: 0.17669 | Regression loss: 0.50635 | Running loss: 0.92186\n",
      "Epoch: 4 | Iteration: 150 | Classification loss: 0.31625 | Regression loss: 0.70658 | Running loss: 0.92214\n",
      "Epoch: 4 | Iteration: 151 | Classification loss: 0.27286 | Regression loss: 0.71428 | Running loss: 0.92271\n",
      "Epoch: 4 | Iteration: 152 | Classification loss: 0.51912 | Regression loss: 0.54825 | Running loss: 0.92320\n",
      "Epoch: 4 | Iteration: 153 | Classification loss: 0.25632 | Regression loss: 0.52968 | Running loss: 0.92312\n",
      "Epoch: 4 | Iteration: 154 | Classification loss: 0.16662 | Regression loss: 0.40556 | Running loss: 0.92216\n",
      "Epoch: 4 | Iteration: 155 | Classification loss: 0.27893 | Regression loss: 0.52262 | Running loss: 0.92167\n",
      "Epoch: 4 | Iteration: 156 | Classification loss: 0.31386 | Regression loss: 0.69487 | Running loss: 0.92136\n",
      "Epoch: 4 | Iteration: 157 | Classification loss: 0.32361 | Regression loss: 0.72617 | Running loss: 0.92171\n",
      "Epoch: 4 | Iteration: 158 | Classification loss: 0.29760 | Regression loss: 0.56023 | Running loss: 0.92148\n",
      "Epoch: 4 | Iteration: 159 | Classification loss: 0.21632 | Regression loss: 0.61182 | Running loss: 0.92099\n",
      "Epoch: 4 | Iteration: 160 | Classification loss: 0.35724 | Regression loss: 0.68650 | Running loss: 0.92131\n",
      "Epoch: 4 | Iteration: 161 | Classification loss: 0.12090 | Regression loss: 0.28845 | Running loss: 0.92019\n",
      "Epoch: 4 | Iteration: 162 | Classification loss: 0.28358 | Regression loss: 0.61113 | Running loss: 0.92040\n",
      "Epoch: 4 | Iteration: 163 | Classification loss: 0.30394 | Regression loss: 0.63075 | Running loss: 0.92021\n",
      "Epoch: 4 | Iteration: 164 | Classification loss: 0.13120 | Regression loss: 0.37467 | Running loss: 0.91896\n",
      "Epoch: 4 | Iteration: 165 | Classification loss: 0.29526 | Regression loss: 0.61024 | Running loss: 0.91915\n",
      "Epoch: 4 | Iteration: 166 | Classification loss: 0.29744 | Regression loss: 0.77165 | Running loss: 0.91972\n",
      "Epoch: 4 | Iteration: 167 | Classification loss: 0.35578 | Regression loss: 0.82713 | Running loss: 0.92019\n",
      "Epoch: 4 | Iteration: 168 | Classification loss: 0.29106 | Regression loss: 0.41059 | Running loss: 0.91939\n",
      "Epoch: 4 | Iteration: 169 | Classification loss: 0.21116 | Regression loss: 0.67852 | Running loss: 0.91963\n",
      "Epoch: 4 | Iteration: 170 | Classification loss: 0.27978 | Regression loss: 0.59843 | Running loss: 0.91824\n",
      "Epoch: 4 | Iteration: 171 | Classification loss: 0.28518 | Regression loss: 0.68614 | Running loss: 0.91826\n",
      "Epoch: 4 | Iteration: 172 | Classification loss: 0.17089 | Regression loss: 0.44611 | Running loss: 0.91732\n",
      "Epoch: 4 | Iteration: 173 | Classification loss: 0.28625 | Regression loss: 0.68302 | Running loss: 0.91745\n",
      "Epoch: 4 | Iteration: 174 | Classification loss: 0.18879 | Regression loss: 0.51489 | Running loss: 0.91692\n",
      "Epoch: 4 | Iteration: 175 | Classification loss: 0.23584 | Regression loss: 0.63446 | Running loss: 0.91702\n",
      "Epoch: 4 | Iteration: 176 | Classification loss: 0.29865 | Regression loss: 0.54226 | Running loss: 0.91744\n",
      "Epoch: 4 | Iteration: 177 | Classification loss: 0.23917 | Regression loss: 0.52008 | Running loss: 0.91671\n",
      "Epoch: 4 | Iteration: 178 | Classification loss: 0.38927 | Regression loss: 0.61900 | Running loss: 0.91683\n",
      "Epoch: 4 | Iteration: 179 | Classification loss: 0.31812 | Regression loss: 0.62348 | Running loss: 0.91685\n",
      "Epoch: 4 | Iteration: 180 | Classification loss: 0.35248 | Regression loss: 0.61606 | Running loss: 0.91652\n",
      "Epoch: 4 | Iteration: 181 | Classification loss: 0.31473 | Regression loss: 0.66623 | Running loss: 0.91708\n",
      "Epoch: 4 | Iteration: 182 | Classification loss: 0.39502 | Regression loss: 0.66590 | Running loss: 0.91688\n",
      "Epoch: 4 | Iteration: 183 | Classification loss: 0.20136 | Regression loss: 0.48230 | Running loss: 0.91589\n",
      "Epoch: 4 | Iteration: 184 | Classification loss: 0.22763 | Regression loss: 0.58308 | Running loss: 0.91538\n",
      "Epoch: 4 | Iteration: 185 | Classification loss: 0.30805 | Regression loss: 0.64159 | Running loss: 0.91558\n",
      "Epoch: 4 | Iteration: 186 | Classification loss: 0.28935 | Regression loss: 0.66083 | Running loss: 0.91566\n",
      "Epoch: 4 | Iteration: 187 | Classification loss: 0.27841 | Regression loss: 0.57328 | Running loss: 0.91534\n",
      "Epoch: 4 | Iteration: 188 | Classification loss: 0.23742 | Regression loss: 0.74217 | Running loss: 0.91560\n",
      "Epoch: 4 | Iteration: 189 | Classification loss: 0.16047 | Regression loss: 0.33124 | Running loss: 0.91436\n",
      "Epoch: 4 | Iteration: 190 | Classification loss: 0.22157 | Regression loss: 0.58339 | Running loss: 0.91415\n",
      "Epoch: 4 | Iteration: 191 | Classification loss: 0.31748 | Regression loss: 0.64253 | Running loss: 0.91407\n",
      "Epoch: 4 | Iteration: 192 | Classification loss: 0.28829 | Regression loss: 0.65626 | Running loss: 0.91388\n",
      "Epoch: 4 | Iteration: 193 | Classification loss: 0.19933 | Regression loss: 0.40227 | Running loss: 0.91313\n",
      "Epoch: 4 | Iteration: 194 | Classification loss: 0.37232 | Regression loss: 0.75216 | Running loss: 0.91381\n",
      "Epoch: 4 | Iteration: 195 | Classification loss: 0.45066 | Regression loss: 0.77001 | Running loss: 0.91432\n",
      "Epoch: 4 | Iteration: 196 | Classification loss: 0.14368 | Regression loss: 0.46628 | Running loss: 0.91319\n",
      "Epoch: 4 | Iteration: 197 | Classification loss: 0.26296 | Regression loss: 0.70047 | Running loss: 0.91388\n",
      "Epoch: 4 | Iteration: 198 | Classification loss: 0.16219 | Regression loss: 0.32068 | Running loss: 0.91282\n",
      "Epoch: 4 | Iteration: 199 | Classification loss: 0.32610 | Regression loss: 0.68030 | Running loss: 0.91339\n",
      "Epoch: 4 | Iteration: 200 | Classification loss: 0.34211 | Regression loss: 0.60147 | Running loss: 0.91377\n",
      "Epoch: 4 | Iteration: 201 | Classification loss: 0.21649 | Regression loss: 0.57184 | Running loss: 0.91417\n",
      "Epoch: 4 | Iteration: 202 | Classification loss: 0.29202 | Regression loss: 0.63199 | Running loss: 0.91354\n",
      "Epoch: 4 | Iteration: 203 | Classification loss: 0.31824 | Regression loss: 0.70991 | Running loss: 0.91327\n",
      "Epoch: 4 | Iteration: 204 | Classification loss: 0.26636 | Regression loss: 0.61259 | Running loss: 0.91242\n",
      "Epoch: 4 | Iteration: 205 | Classification loss: 0.23483 | Regression loss: 0.57775 | Running loss: 0.91226\n",
      "Epoch: 4 | Iteration: 206 | Classification loss: 0.28968 | Regression loss: 0.75438 | Running loss: 0.91259\n",
      "Epoch: 4 | Iteration: 207 | Classification loss: 0.20629 | Regression loss: 0.51092 | Running loss: 0.91176\n",
      "Epoch: 4 | Iteration: 208 | Classification loss: 0.28019 | Regression loss: 0.60760 | Running loss: 0.91187\n",
      "Epoch: 4 | Iteration: 209 | Classification loss: 0.18468 | Regression loss: 0.49362 | Running loss: 0.91212\n",
      "Epoch: 4 | Iteration: 210 | Classification loss: 0.27173 | Regression loss: 0.58982 | Running loss: 0.91174\n",
      "Epoch: 4 | Iteration: 211 | Classification loss: 0.14197 | Regression loss: 0.32645 | Running loss: 0.91071\n",
      "Epoch: 4 | Iteration: 212 | Classification loss: 0.42134 | Regression loss: 0.71969 | Running loss: 0.91156\n",
      "Epoch: 4 | Iteration: 213 | Classification loss: 0.25107 | Regression loss: 0.54656 | Running loss: 0.91129\n",
      "Epoch: 4 | Iteration: 214 | Classification loss: 0.32131 | Regression loss: 0.57905 | Running loss: 0.91082\n",
      "Epoch: 4 | Iteration: 215 | Classification loss: 0.26777 | Regression loss: 0.66557 | Running loss: 0.91079\n",
      "Epoch: 4 | Iteration: 216 | Classification loss: 0.24465 | Regression loss: 0.55471 | Running loss: 0.91008\n",
      "Epoch: 4 | Iteration: 217 | Classification loss: 0.32987 | Regression loss: 0.67900 | Running loss: 0.91014\n",
      "Epoch: 4 | Iteration: 218 | Classification loss: 0.23529 | Regression loss: 0.62344 | Running loss: 0.91053\n",
      "Epoch: 4 | Iteration: 219 | Classification loss: 0.29015 | Regression loss: 0.64839 | Running loss: 0.91034\n",
      "Epoch: 4 | Iteration: 220 | Classification loss: 0.23804 | Regression loss: 0.50759 | Running loss: 0.91029\n",
      "Epoch: 4 | Iteration: 221 | Classification loss: 0.25001 | Regression loss: 0.58379 | Running loss: 0.90995\n",
      "Epoch: 4 | Iteration: 222 | Classification loss: 0.25207 | Regression loss: 0.54969 | Running loss: 0.90999\n",
      "Epoch: 4 | Iteration: 223 | Classification loss: 0.21944 | Regression loss: 0.52296 | Running loss: 0.90914\n",
      "Epoch: 4 | Iteration: 224 | Classification loss: 0.22231 | Regression loss: 0.51360 | Running loss: 0.90862\n",
      "Epoch: 4 | Iteration: 225 | Classification loss: 0.24423 | Regression loss: 0.59704 | Running loss: 0.90874\n",
      "Epoch: 4 | Iteration: 226 | Classification loss: 0.20097 | Regression loss: 0.48413 | Running loss: 0.90829\n",
      "Epoch: 4 | Iteration: 227 | Classification loss: 0.42663 | Regression loss: 0.58063 | Running loss: 0.90842\n",
      "Epoch: 4 | Iteration: 228 | Classification loss: 0.20094 | Regression loss: 0.46544 | Running loss: 0.90825\n",
      "Epoch: 4 | Iteration: 229 | Classification loss: 0.26889 | Regression loss: 0.65491 | Running loss: 0.90820\n",
      "Epoch: 4 | Iteration: 230 | Classification loss: 0.22577 | Regression loss: 0.56526 | Running loss: 0.90819\n",
      "Epoch: 4 | Iteration: 231 | Classification loss: 0.25115 | Regression loss: 0.62517 | Running loss: 0.90814\n",
      "Epoch: 4 | Iteration: 232 | Classification loss: 0.34932 | Regression loss: 0.69434 | Running loss: 0.90837\n",
      "Epoch: 4 | Iteration: 233 | Classification loss: 0.28470 | Regression loss: 0.70266 | Running loss: 0.90859\n",
      "Epoch: 4 | Iteration: 234 | Classification loss: 0.25691 | Regression loss: 0.68518 | Running loss: 0.90843\n",
      "Epoch: 4 | Iteration: 235 | Classification loss: 0.33907 | Regression loss: 0.74092 | Running loss: 0.90867\n",
      "Epoch: 4 | Iteration: 236 | Classification loss: 0.22467 | Regression loss: 0.57699 | Running loss: 0.90831\n",
      "Epoch: 4 | Iteration: 237 | Classification loss: 0.35139 | Regression loss: 0.73561 | Running loss: 0.90856\n",
      "Epoch: 4 | Iteration: 238 | Classification loss: 0.44749 | Regression loss: 0.70538 | Running loss: 0.90928\n",
      "Epoch: 4 | Iteration: 239 | Classification loss: 0.31618 | Regression loss: 0.70108 | Running loss: 0.90973\n",
      "Epoch: 4 | Iteration: 240 | Classification loss: 0.25843 | Regression loss: 0.64115 | Running loss: 0.90977\n",
      "Epoch: 4 | Iteration: 241 | Classification loss: 0.30533 | Regression loss: 0.45710 | Running loss: 0.90937\n",
      "Epoch: 4 | Iteration: 242 | Classification loss: 0.28215 | Regression loss: 0.67910 | Running loss: 0.90942\n",
      "Epoch: 4 | Iteration: 243 | Classification loss: 0.35105 | Regression loss: 0.61607 | Running loss: 0.90998\n",
      "Epoch: 4 | Iteration: 244 | Classification loss: 0.27198 | Regression loss: 0.68066 | Running loss: 0.90988\n",
      "Epoch: 4 | Iteration: 245 | Classification loss: 0.33312 | Regression loss: 0.70511 | Running loss: 0.90997\n",
      "Epoch: 4 | Iteration: 246 | Classification loss: 0.23122 | Regression loss: 0.51076 | Running loss: 0.90948\n",
      "Epoch: 4 | Iteration: 247 | Classification loss: 0.19692 | Regression loss: 0.48221 | Running loss: 0.90842\n",
      "Epoch: 4 | Iteration: 248 | Classification loss: 0.20333 | Regression loss: 0.35661 | Running loss: 0.90726\n",
      "Epoch: 4 | Iteration: 249 | Classification loss: 0.25868 | Regression loss: 0.59317 | Running loss: 0.90708\n",
      "Epoch: 4 | Iteration: 250 | Classification loss: 0.37811 | Regression loss: 0.61933 | Running loss: 0.90710\n",
      "Epoch: 4 | Iteration: 251 | Classification loss: 0.30602 | Regression loss: 0.62355 | Running loss: 0.90683\n",
      "Epoch: 4 | Iteration: 252 | Classification loss: 0.21687 | Regression loss: 0.51703 | Running loss: 0.90651\n",
      "Epoch: 4 | Iteration: 253 | Classification loss: 0.43007 | Regression loss: 0.64164 | Running loss: 0.90674\n",
      "Epoch: 4 | Iteration: 254 | Classification loss: 0.21424 | Regression loss: 0.69664 | Running loss: 0.90673\n",
      "Epoch: 4 | Iteration: 255 | Classification loss: 0.28255 | Regression loss: 0.63982 | Running loss: 0.90635\n",
      "Epoch: 4 | Iteration: 256 | Classification loss: 0.25961 | Regression loss: 0.57366 | Running loss: 0.90589\n",
      "Epoch: 4 | Iteration: 257 | Classification loss: 0.17404 | Regression loss: 0.46412 | Running loss: 0.90500\n",
      "Epoch: 4 | Iteration: 258 | Classification loss: 0.26348 | Regression loss: 0.55952 | Running loss: 0.90510\n",
      "Epoch: 4 | Iteration: 259 | Classification loss: 0.25991 | Regression loss: 0.55318 | Running loss: 0.90430\n",
      "Epoch: 4 | Iteration: 260 | Classification loss: 0.25392 | Regression loss: 0.61373 | Running loss: 0.90393\n",
      "Epoch: 4 | Iteration: 261 | Classification loss: 0.33824 | Regression loss: 0.68242 | Running loss: 0.90374\n",
      "Epoch: 4 | Iteration: 262 | Classification loss: 0.33110 | Regression loss: 0.58315 | Running loss: 0.90378\n",
      "Epoch: 4 | Iteration: 263 | Classification loss: 0.28661 | Regression loss: 0.57662 | Running loss: 0.90365\n",
      "Epoch: 4 | Iteration: 264 | Classification loss: 0.32649 | Regression loss: 0.70085 | Running loss: 0.90372\n",
      "Epoch: 4 | Iteration: 265 | Classification loss: 0.21368 | Regression loss: 0.66084 | Running loss: 0.90329\n",
      "Epoch: 4 | Iteration: 266 | Classification loss: 0.30723 | Regression loss: 0.76530 | Running loss: 0.90356\n",
      "Epoch: 4 | Iteration: 267 | Classification loss: 0.28208 | Regression loss: 0.54016 | Running loss: 0.90332\n",
      "Epoch: 4 | Iteration: 268 | Classification loss: 0.27324 | Regression loss: 0.58351 | Running loss: 0.90317\n",
      "Epoch: 4 | Iteration: 269 | Classification loss: 0.44986 | Regression loss: 0.66870 | Running loss: 0.90371\n",
      "Epoch: 4 | Iteration: 270 | Classification loss: 0.29285 | Regression loss: 0.62156 | Running loss: 0.90364\n",
      "Epoch: 4 | Iteration: 271 | Classification loss: 0.20147 | Regression loss: 0.40592 | Running loss: 0.90284\n",
      "Epoch: 4 | Iteration: 272 | Classification loss: 0.33542 | Regression loss: 0.63402 | Running loss: 0.90319\n",
      "Epoch: 4 | Iteration: 273 | Classification loss: 0.34543 | Regression loss: 0.70707 | Running loss: 0.90328\n",
      "Epoch: 4 | Iteration: 274 | Classification loss: 0.23971 | Regression loss: 0.64115 | Running loss: 0.90339\n",
      "Epoch: 4 | Iteration: 275 | Classification loss: 0.23100 | Regression loss: 0.45510 | Running loss: 0.90327\n",
      "Epoch: 4 | Iteration: 276 | Classification loss: 0.22238 | Regression loss: 0.67604 | Running loss: 0.90344\n",
      "Epoch: 4 | Iteration: 277 | Classification loss: 0.28028 | Regression loss: 0.55618 | Running loss: 0.90241\n",
      "Epoch: 4 | Iteration: 278 | Classification loss: 0.26483 | Regression loss: 0.66438 | Running loss: 0.90194\n",
      "Epoch: 4 | Iteration: 279 | Classification loss: 0.24183 | Regression loss: 0.55707 | Running loss: 0.90136\n",
      "Epoch: 4 | Iteration: 280 | Classification loss: 0.33386 | Regression loss: 0.69168 | Running loss: 0.90136\n",
      "Epoch: 4 | Iteration: 281 | Classification loss: 0.27582 | Regression loss: 0.59612 | Running loss: 0.90183\n",
      "Epoch: 4 | Iteration: 282 | Classification loss: 0.34581 | Regression loss: 0.62046 | Running loss: 0.90217\n",
      "Epoch: 4 | Iteration: 283 | Classification loss: 0.26212 | Regression loss: 0.61840 | Running loss: 0.90182\n",
      "Epoch: 4 | Iteration: 284 | Classification loss: 0.21842 | Regression loss: 0.57756 | Running loss: 0.90191\n",
      "Epoch: 4 | Iteration: 285 | Classification loss: 0.31458 | Regression loss: 0.70037 | Running loss: 0.90210\n",
      "Epoch: 4 | Iteration: 286 | Classification loss: 0.26026 | Regression loss: 0.63994 | Running loss: 0.90233\n",
      "Epoch: 4 | Iteration: 287 | Classification loss: 0.29193 | Regression loss: 0.64414 | Running loss: 0.90228\n",
      "Epoch: 4 | Iteration: 288 | Classification loss: 0.24337 | Regression loss: 0.56253 | Running loss: 0.90173\n",
      "Epoch: 4 | Iteration: 289 | Classification loss: 0.35678 | Regression loss: 0.71553 | Running loss: 0.90223\n",
      "Epoch: 4 | Iteration: 290 | Classification loss: 0.24285 | Regression loss: 0.50809 | Running loss: 0.90174\n",
      "Epoch: 4 | Iteration: 291 | Classification loss: 0.26237 | Regression loss: 0.57366 | Running loss: 0.90135\n",
      "Epoch: 4 | Iteration: 292 | Classification loss: 0.23899 | Regression loss: 0.61885 | Running loss: 0.90099\n",
      "Epoch: 4 | Iteration: 293 | Classification loss: 0.28113 | Regression loss: 0.55758 | Running loss: 0.90067\n",
      "Epoch: 4 | Iteration: 294 | Classification loss: 0.37697 | Regression loss: 0.70311 | Running loss: 0.90093\n",
      "Epoch: 4 | Iteration: 295 | Classification loss: 0.21560 | Regression loss: 0.58978 | Running loss: 0.90031\n",
      "Epoch: 4 | Iteration: 296 | Classification loss: 0.25732 | Regression loss: 0.40611 | Running loss: 0.90015\n",
      "Epoch: 4 | Iteration: 297 | Classification loss: 0.25378 | Regression loss: 0.68030 | Running loss: 0.90022\n",
      "Epoch: 4 | Iteration: 298 | Classification loss: 0.25960 | Regression loss: 0.59869 | Running loss: 0.90013\n",
      "Epoch: 4 | Iteration: 299 | Classification loss: 0.38227 | Regression loss: 0.64218 | Running loss: 0.90065\n",
      "Epoch: 4 | Iteration: 300 | Classification loss: 0.42300 | Regression loss: 0.71326 | Running loss: 0.90098\n",
      "Epoch: 4 | Iteration: 301 | Classification loss: 0.43273 | Regression loss: 0.68492 | Running loss: 0.90124\n",
      "Epoch: 4 | Iteration: 302 | Classification loss: 0.33612 | Regression loss: 0.65922 | Running loss: 0.90129\n",
      "Epoch: 4 | Iteration: 303 | Classification loss: 0.28327 | Regression loss: 0.52306 | Running loss: 0.90155\n",
      "Epoch: 4 | Iteration: 304 | Classification loss: 0.29385 | Regression loss: 0.64472 | Running loss: 0.90207\n",
      "Epoch: 4 | Iteration: 305 | Classification loss: 0.29125 | Regression loss: 0.51606 | Running loss: 0.90208\n",
      "Epoch: 4 | Iteration: 306 | Classification loss: 0.29538 | Regression loss: 0.65669 | Running loss: 0.90214\n",
      "Epoch: 4 | Iteration: 307 | Classification loss: 0.36027 | Regression loss: 0.71826 | Running loss: 0.90252\n",
      "Epoch: 4 | Iteration: 308 | Classification loss: 0.30092 | Regression loss: 0.67126 | Running loss: 0.90285\n",
      "Epoch: 4 | Iteration: 309 | Classification loss: 0.20973 | Regression loss: 0.65279 | Running loss: 0.90271\n",
      "Epoch: 4 | Iteration: 310 | Classification loss: 0.33950 | Regression loss: 0.61978 | Running loss: 0.90282\n",
      "Epoch: 4 | Iteration: 311 | Classification loss: 0.24150 | Regression loss: 0.61879 | Running loss: 0.90269\n",
      "Epoch: 4 | Iteration: 312 | Classification loss: 0.26135 | Regression loss: 0.53200 | Running loss: 0.90237\n",
      "Epoch: 4 | Iteration: 313 | Classification loss: 0.32445 | Regression loss: 0.65576 | Running loss: 0.90207\n",
      "Epoch: 4 | Iteration: 314 | Classification loss: 0.25533 | Regression loss: 0.43579 | Running loss: 0.90112\n",
      "Epoch: 4 | Iteration: 315 | Classification loss: 0.27559 | Regression loss: 0.58323 | Running loss: 0.90060\n",
      "Epoch: 4 | Iteration: 316 | Classification loss: 0.33837 | Regression loss: 0.66746 | Running loss: 0.90060\n",
      "Epoch: 4 | Iteration: 317 | Classification loss: 0.28023 | Regression loss: 0.62492 | Running loss: 0.90075\n",
      "Epoch: 4 | Iteration: 318 | Classification loss: 0.28623 | Regression loss: 0.67276 | Running loss: 0.90061\n",
      "Epoch: 4 | Iteration: 319 | Classification loss: 0.29849 | Regression loss: 0.53019 | Running loss: 0.89999\n",
      "Epoch: 4 | Iteration: 320 | Classification loss: 0.38144 | Regression loss: 0.53363 | Running loss: 0.89956\n",
      "Epoch: 4 | Iteration: 321 | Classification loss: 0.22859 | Regression loss: 0.53254 | Running loss: 0.89909\n",
      "Epoch: 4 | Iteration: 322 | Classification loss: 0.23238 | Regression loss: 0.54355 | Running loss: 0.89868\n",
      "Epoch: 4 | Iteration: 323 | Classification loss: 0.19035 | Regression loss: 0.50324 | Running loss: 0.89813\n",
      "Epoch: 4 | Iteration: 324 | Classification loss: 0.32060 | Regression loss: 0.56606 | Running loss: 0.89826\n",
      "Epoch: 4 | Iteration: 325 | Classification loss: 0.17451 | Regression loss: 0.48792 | Running loss: 0.89794\n",
      "Epoch: 4 | Iteration: 326 | Classification loss: 0.36875 | Regression loss: 0.66324 | Running loss: 0.89817\n",
      "Epoch: 4 | Iteration: 327 | Classification loss: 0.39960 | Regression loss: 0.63047 | Running loss: 0.89822\n",
      "Epoch: 4 | Iteration: 328 | Classification loss: 0.41803 | Regression loss: 0.64284 | Running loss: 0.89891\n",
      "Epoch: 4 | Iteration: 329 | Classification loss: 0.21034 | Regression loss: 0.46949 | Running loss: 0.89909\n",
      "Epoch: 4 | Iteration: 330 | Classification loss: 0.34136 | Regression loss: 0.61836 | Running loss: 0.89891\n",
      "Epoch: 4 | Iteration: 331 | Classification loss: 0.36311 | Regression loss: 0.80300 | Running loss: 0.89915\n",
      "Epoch: 4 | Iteration: 332 | Classification loss: 0.28251 | Regression loss: 0.65427 | Running loss: 0.89899\n",
      "Epoch: 4 | Iteration: 333 | Classification loss: 0.29010 | Regression loss: 0.61122 | Running loss: 0.89868\n",
      "Epoch: 4 | Iteration: 334 | Classification loss: 0.25120 | Regression loss: 0.46604 | Running loss: 0.89769\n",
      "Epoch: 4 | Iteration: 335 | Classification loss: 0.26808 | Regression loss: 0.53952 | Running loss: 0.89735\n",
      "Epoch: 4 | Iteration: 336 | Classification loss: 0.27203 | Regression loss: 0.51011 | Running loss: 0.89658\n",
      "Epoch: 4 | Iteration: 337 | Classification loss: 0.11872 | Regression loss: 0.45179 | Running loss: 0.89620\n",
      "Epoch: 4 | Iteration: 338 | Classification loss: 0.26420 | Regression loss: 0.63631 | Running loss: 0.89592\n",
      "Epoch: 4 | Iteration: 339 | Classification loss: 0.28751 | Regression loss: 0.56640 | Running loss: 0.89597\n",
      "Epoch: 4 | Iteration: 340 | Classification loss: 0.23090 | Regression loss: 0.50324 | Running loss: 0.89496\n",
      "Epoch: 4 | Iteration: 341 | Classification loss: 0.31116 | Regression loss: 0.55778 | Running loss: 0.89518\n",
      "Epoch: 4 | Iteration: 342 | Classification loss: 0.24726 | Regression loss: 0.61295 | Running loss: 0.89513\n",
      "Epoch: 4 | Iteration: 343 | Classification loss: 0.26692 | Regression loss: 0.55841 | Running loss: 0.89523\n",
      "Epoch: 4 | Iteration: 344 | Classification loss: 0.20933 | Regression loss: 0.52609 | Running loss: 0.89474\n",
      "Epoch: 4 | Iteration: 345 | Classification loss: 0.19248 | Regression loss: 0.48555 | Running loss: 0.89436\n",
      "Epoch: 4 | Iteration: 346 | Classification loss: 0.34670 | Regression loss: 0.72238 | Running loss: 0.89444\n",
      "Epoch: 4 | Iteration: 347 | Classification loss: 0.38993 | Regression loss: 0.75955 | Running loss: 0.89472\n",
      "Epoch: 4 | Iteration: 348 | Classification loss: 0.33907 | Regression loss: 0.73070 | Running loss: 0.89535\n",
      "Epoch: 4 | Iteration: 349 | Classification loss: 0.32735 | Regression loss: 0.65187 | Running loss: 0.89486\n",
      "Epoch: 4 | Iteration: 350 | Classification loss: 0.22446 | Regression loss: 0.50301 | Running loss: 0.89423\n",
      "Epoch: 4 | Iteration: 351 | Classification loss: 0.26085 | Regression loss: 0.69316 | Running loss: 0.89349\n",
      "Epoch: 4 | Iteration: 352 | Classification loss: 0.24540 | Regression loss: 0.53645 | Running loss: 0.89339\n",
      "Epoch: 4 | Iteration: 353 | Classification loss: 0.21488 | Regression loss: 0.69657 | Running loss: 0.89343\n",
      "Epoch: 4 | Iteration: 354 | Classification loss: 0.30054 | Regression loss: 0.29277 | Running loss: 0.89293\n",
      "Epoch: 4 | Iteration: 355 | Classification loss: 0.25810 | Regression loss: 0.57999 | Running loss: 0.89263\n",
      "Epoch: 4 | Iteration: 356 | Classification loss: 0.49540 | Regression loss: 0.70747 | Running loss: 0.89329\n",
      "Epoch: 4 | Iteration: 357 | Classification loss: 0.15443 | Regression loss: 0.37171 | Running loss: 0.89245\n",
      "Epoch: 4 | Iteration: 358 | Classification loss: 0.24374 | Regression loss: 0.45930 | Running loss: 0.89240\n",
      "Epoch: 4 | Iteration: 359 | Classification loss: 0.27651 | Regression loss: 0.57617 | Running loss: 0.89204\n",
      "Epoch: 4 | Iteration: 360 | Classification loss: 0.26455 | Regression loss: 0.69772 | Running loss: 0.89189\n",
      "Epoch: 4 | Iteration: 361 | Classification loss: 0.32790 | Regression loss: 0.75266 | Running loss: 0.89263\n",
      "Epoch: 4 | Iteration: 362 | Classification loss: 0.23629 | Regression loss: 0.53620 | Running loss: 0.89236\n",
      "Epoch: 4 | Iteration: 363 | Classification loss: 0.27043 | Regression loss: 0.55135 | Running loss: 0.89252\n",
      "Epoch: 4 | Iteration: 364 | Classification loss: 0.41373 | Regression loss: 0.87147 | Running loss: 0.89281\n",
      "Epoch: 4 | Iteration: 365 | Classification loss: 0.24387 | Regression loss: 0.50459 | Running loss: 0.89288\n",
      "Epoch: 4 | Iteration: 366 | Classification loss: 0.29095 | Regression loss: 0.68464 | Running loss: 0.89330\n",
      "Epoch: 4 | Iteration: 367 | Classification loss: 0.29586 | Regression loss: 0.55414 | Running loss: 0.89338\n",
      "Epoch: 4 | Iteration: 368 | Classification loss: 0.35845 | Regression loss: 0.75569 | Running loss: 0.89359\n",
      "Epoch: 4 | Iteration: 369 | Classification loss: 0.26999 | Regression loss: 0.55931 | Running loss: 0.89358\n",
      "Epoch: 4 | Iteration: 370 | Classification loss: 0.21189 | Regression loss: 0.55750 | Running loss: 0.89299\n",
      "Epoch: 4 | Iteration: 371 | Classification loss: 0.29812 | Regression loss: 0.72097 | Running loss: 0.89294\n",
      "Epoch: 4 | Iteration: 372 | Classification loss: 0.22189 | Regression loss: 0.57763 | Running loss: 0.89247\n",
      "Epoch: 4 | Iteration: 373 | Classification loss: 0.96218 | Regression loss: 0.69563 | Running loss: 0.89401\n",
      "Epoch: 4 | Iteration: 374 | Classification loss: 0.25698 | Regression loss: 0.54093 | Running loss: 0.89376\n",
      "Epoch: 4 | Iteration: 375 | Classification loss: 0.32126 | Regression loss: 0.63883 | Running loss: 0.89427\n",
      "Epoch: 4 | Iteration: 376 | Classification loss: 0.23854 | Regression loss: 0.54076 | Running loss: 0.89389\n",
      "Epoch: 4 | Iteration: 377 | Classification loss: 0.31673 | Regression loss: 0.76992 | Running loss: 0.89418\n",
      "Epoch: 4 | Iteration: 378 | Classification loss: 0.26457 | Regression loss: 0.62148 | Running loss: 0.89383\n",
      "Epoch: 4 | Iteration: 379 | Classification loss: 0.39937 | Regression loss: 0.70784 | Running loss: 0.89393\n",
      "Epoch: 4 | Iteration: 380 | Classification loss: 0.29021 | Regression loss: 0.55216 | Running loss: 0.89424\n",
      "Epoch: 4 | Iteration: 381 | Classification loss: 0.19615 | Regression loss: 0.46804 | Running loss: 0.89441\n",
      "Epoch: 4 | Iteration: 382 | Classification loss: 0.37381 | Regression loss: 0.76419 | Running loss: 0.89490\n",
      "Epoch: 4 | Iteration: 383 | Classification loss: 0.25298 | Regression loss: 0.69576 | Running loss: 0.89479\n",
      "Epoch: 4 | Iteration: 384 | Classification loss: 0.25093 | Regression loss: 0.62105 | Running loss: 0.89444\n",
      "Epoch: 4 | Iteration: 385 | Classification loss: 0.22130 | Regression loss: 0.38077 | Running loss: 0.89359\n",
      "Epoch: 4 | Iteration: 386 | Classification loss: 0.38838 | Regression loss: 0.62535 | Running loss: 0.89360\n",
      "Epoch: 4 | Iteration: 387 | Classification loss: 0.26084 | Regression loss: 0.55700 | Running loss: 0.89314\n",
      "Epoch: 4 | Iteration: 388 | Classification loss: 0.22959 | Regression loss: 0.59580 | Running loss: 0.89265\n",
      "Epoch: 4 | Iteration: 389 | Classification loss: 0.19802 | Regression loss: 0.42003 | Running loss: 0.89168\n",
      "Epoch: 4 | Iteration: 390 | Classification loss: 0.44063 | Regression loss: 0.64988 | Running loss: 0.89181\n",
      "Epoch: 4 | Iteration: 391 | Classification loss: 0.21434 | Regression loss: 0.46097 | Running loss: 0.89143\n",
      "Epoch: 4 | Iteration: 392 | Classification loss: 0.33668 | Regression loss: 0.65488 | Running loss: 0.89126\n",
      "Epoch: 4 | Iteration: 393 | Classification loss: 0.30229 | Regression loss: 0.45031 | Running loss: 0.89138\n",
      "Epoch: 4 | Iteration: 394 | Classification loss: 0.34092 | Regression loss: 0.75820 | Running loss: 0.89191\n",
      "Epoch: 4 | Iteration: 395 | Classification loss: 0.27498 | Regression loss: 0.49358 | Running loss: 0.89089\n",
      "Epoch: 4 | Iteration: 396 | Classification loss: 0.24714 | Regression loss: 0.62231 | Running loss: 0.89027\n",
      "Epoch: 4 | Iteration: 397 | Classification loss: 0.25898 | Regression loss: 0.57366 | Running loss: 0.89042\n",
      "Epoch: 4 | Iteration: 398 | Classification loss: 0.28752 | Regression loss: 0.60434 | Running loss: 0.89034\n",
      "Epoch: 4 | Iteration: 399 | Classification loss: 0.22510 | Regression loss: 0.59080 | Running loss: 0.89015\n",
      "Epoch: 4 | Iteration: 400 | Classification loss: 0.38799 | Regression loss: 0.36544 | Running loss: 0.88985\n",
      "Epoch: 4 | Iteration: 401 | Classification loss: 0.20328 | Regression loss: 0.40768 | Running loss: 0.88899\n",
      "Epoch: 4 | Iteration: 402 | Classification loss: 0.34334 | Regression loss: 0.63377 | Running loss: 0.88876\n",
      "Epoch: 4 | Iteration: 403 | Classification loss: 0.36265 | Regression loss: 0.60440 | Running loss: 0.88904\n",
      "Epoch: 4 | Iteration: 404 | Classification loss: 0.28282 | Regression loss: 0.67785 | Running loss: 0.88935\n",
      "Epoch: 4 | Iteration: 405 | Classification loss: 0.24556 | Regression loss: 0.54335 | Running loss: 0.88917\n",
      "Epoch: 4 | Iteration: 406 | Classification loss: 0.28182 | Regression loss: 0.67628 | Running loss: 0.88891\n",
      "Epoch: 4 | Iteration: 407 | Classification loss: 0.32999 | Regression loss: 0.68406 | Running loss: 0.88899\n",
      "Epoch: 4 | Iteration: 408 | Classification loss: 0.38062 | Regression loss: 0.35903 | Running loss: 0.88875\n",
      "Epoch: 4 | Iteration: 409 | Classification loss: 0.34628 | Regression loss: 0.57838 | Running loss: 0.88870\n",
      "Epoch: 4 | Iteration: 410 | Classification loss: 0.18986 | Regression loss: 0.53647 | Running loss: 0.88841\n",
      "Epoch: 4 | Iteration: 411 | Classification loss: 0.32182 | Regression loss: 0.53476 | Running loss: 0.88801\n",
      "Epoch: 4 | Iteration: 412 | Classification loss: 0.24806 | Regression loss: 0.61302 | Running loss: 0.88783\n",
      "Epoch: 4 | Iteration: 413 | Classification loss: 0.26624 | Regression loss: 0.63056 | Running loss: 0.88762\n",
      "Epoch: 4 | Iteration: 414 | Classification loss: 0.37095 | Regression loss: 0.78921 | Running loss: 0.88812\n",
      "Epoch: 4 | Iteration: 415 | Classification loss: 0.27172 | Regression loss: 0.53989 | Running loss: 0.88798\n",
      "Epoch: 4 | Iteration: 416 | Classification loss: 0.41538 | Regression loss: 0.65458 | Running loss: 0.88844\n",
      "Epoch: 4 | Iteration: 417 | Classification loss: 0.27403 | Regression loss: 0.58275 | Running loss: 0.88865\n",
      "Epoch: 4 | Iteration: 418 | Classification loss: 0.20386 | Regression loss: 0.45737 | Running loss: 0.88813\n",
      "Epoch: 4 | Iteration: 419 | Classification loss: 0.29202 | Regression loss: 0.60032 | Running loss: 0.88849\n",
      "Epoch: 4 | Iteration: 420 | Classification loss: 0.21037 | Regression loss: 0.58953 | Running loss: 0.88802\n",
      "Epoch: 4 | Iteration: 421 | Classification loss: 0.32012 | Regression loss: 0.61924 | Running loss: 0.88806\n",
      "Epoch: 4 | Iteration: 422 | Classification loss: 0.30638 | Regression loss: 0.71174 | Running loss: 0.88865\n",
      "Epoch: 4 | Iteration: 423 | Classification loss: 0.26426 | Regression loss: 0.61320 | Running loss: 0.88806\n",
      "Epoch: 4 | Iteration: 424 | Classification loss: 0.27263 | Regression loss: 0.68540 | Running loss: 0.88755\n",
      "Epoch: 4 | Iteration: 425 | Classification loss: 0.41751 | Regression loss: 0.64932 | Running loss: 0.88798\n",
      "Epoch: 4 | Iteration: 426 | Classification loss: 0.24986 | Regression loss: 0.55450 | Running loss: 0.88800\n",
      "Epoch: 4 | Iteration: 427 | Classification loss: 0.21598 | Regression loss: 0.54647 | Running loss: 0.88731\n",
      "Epoch: 4 | Iteration: 428 | Classification loss: 0.35058 | Regression loss: 0.66428 | Running loss: 0.88729\n",
      "Epoch: 4 | Iteration: 429 | Classification loss: 0.27205 | Regression loss: 0.59873 | Running loss: 0.88780\n",
      "Epoch: 4 | Iteration: 430 | Classification loss: 0.26117 | Regression loss: 0.57491 | Running loss: 0.88750\n",
      "Epoch: 4 | Iteration: 431 | Classification loss: 0.22517 | Regression loss: 0.55471 | Running loss: 0.88735\n",
      "Epoch: 4 | Iteration: 432 | Classification loss: 0.31873 | Regression loss: 0.74474 | Running loss: 0.88709\n",
      "Epoch: 4 | Iteration: 433 | Classification loss: 0.25455 | Regression loss: 0.62803 | Running loss: 0.88699\n",
      "Epoch: 4 | Iteration: 434 | Classification loss: 0.36081 | Regression loss: 0.46487 | Running loss: 0.88703\n",
      "Epoch: 4 | Iteration: 435 | Classification loss: 0.27232 | Regression loss: 0.67561 | Running loss: 0.88706\n",
      "Epoch: 4 | Iteration: 436 | Classification loss: 0.30297 | Regression loss: 0.69850 | Running loss: 0.88744\n",
      "Epoch: 4 | Iteration: 437 | Classification loss: 0.20162 | Regression loss: 0.51131 | Running loss: 0.88733\n",
      "Epoch: 4 | Iteration: 438 | Classification loss: 0.29328 | Regression loss: 0.72619 | Running loss: 0.88743\n",
      "Epoch: 4 | Iteration: 439 | Classification loss: 0.21033 | Regression loss: 0.49783 | Running loss: 0.88705\n",
      "Epoch: 4 | Iteration: 440 | Classification loss: 0.22931 | Regression loss: 0.60278 | Running loss: 0.88672\n",
      "Epoch: 4 | Iteration: 441 | Classification loss: 0.23848 | Regression loss: 0.45886 | Running loss: 0.88597\n",
      "Epoch: 4 | Iteration: 442 | Classification loss: 0.24721 | Regression loss: 0.56539 | Running loss: 0.88553\n",
      "Epoch: 4 | Iteration: 443 | Classification loss: 0.32354 | Regression loss: 0.65959 | Running loss: 0.88599\n",
      "Epoch: 4 | Iteration: 444 | Classification loss: 0.28990 | Regression loss: 0.70016 | Running loss: 0.88605\n",
      "Epoch: 4 | Iteration: 445 | Classification loss: 0.28199 | Regression loss: 0.60461 | Running loss: 0.88614\n",
      "Epoch: 4 | Iteration: 446 | Classification loss: 0.27596 | Regression loss: 0.61335 | Running loss: 0.88576\n",
      "Epoch: 4 | Iteration: 447 | Classification loss: 0.18934 | Regression loss: 0.58320 | Running loss: 0.88532\n",
      "Epoch: 4 | Iteration: 448 | Classification loss: 0.50108 | Regression loss: 0.55094 | Running loss: 0.88571\n",
      "Epoch: 4 | Iteration: 449 | Classification loss: 0.36391 | Regression loss: 0.70708 | Running loss: 0.88568\n",
      "Epoch: 4 | Iteration: 450 | Classification loss: 0.31578 | Regression loss: 0.62496 | Running loss: 0.88580\n",
      "Epoch: 4 | Iteration: 451 | Classification loss: 0.28665 | Regression loss: 0.63270 | Running loss: 0.88530\n",
      "Epoch: 4 | Iteration: 452 | Classification loss: 0.35187 | Regression loss: 0.63762 | Running loss: 0.88538\n",
      "Epoch: 4 | Iteration: 453 | Classification loss: 0.19427 | Regression loss: 0.50899 | Running loss: 0.88482\n",
      "Epoch: 4 | Iteration: 454 | Classification loss: 0.23387 | Regression loss: 0.57363 | Running loss: 0.88438\n",
      "Epoch: 4 | Iteration: 455 | Classification loss: 0.25984 | Regression loss: 0.61019 | Running loss: 0.88426\n",
      "Epoch: 4 | Iteration: 456 | Classification loss: 0.24777 | Regression loss: 0.50975 | Running loss: 0.88363\n",
      "Epoch: 4 | Iteration: 457 | Classification loss: 0.27055 | Regression loss: 0.72781 | Running loss: 0.88364\n",
      "Epoch: 4 | Iteration: 458 | Classification loss: 0.27695 | Regression loss: 0.68002 | Running loss: 0.88380\n",
      "Epoch: 4 | Iteration: 459 | Classification loss: 0.42692 | Regression loss: 0.78158 | Running loss: 0.88468\n",
      "Epoch: 4 | Iteration: 460 | Classification loss: 0.21821 | Regression loss: 0.49340 | Running loss: 0.88455\n",
      "Epoch: 4 | Iteration: 461 | Classification loss: 0.30104 | Regression loss: 0.62199 | Running loss: 0.88395\n",
      "Epoch: 4 | Iteration: 462 | Classification loss: 0.26785 | Regression loss: 0.53591 | Running loss: 0.88346\n",
      "Epoch: 4 | Iteration: 463 | Classification loss: 0.34611 | Regression loss: 0.66121 | Running loss: 0.88324\n",
      "Epoch: 4 | Iteration: 464 | Classification loss: 0.26419 | Regression loss: 0.57673 | Running loss: 0.88273\n",
      "Epoch: 4 | Iteration: 465 | Classification loss: 0.38728 | Regression loss: 0.75864 | Running loss: 0.88302\n",
      "Epoch: 4 | Iteration: 466 | Classification loss: 0.23602 | Regression loss: 0.46480 | Running loss: 0.88201\n",
      "Epoch: 4 | Iteration: 467 | Classification loss: 0.26339 | Regression loss: 0.66910 | Running loss: 0.88227\n",
      "Epoch: 4 | Iteration: 468 | Classification loss: 0.32129 | Regression loss: 0.69129 | Running loss: 0.88225\n",
      "Epoch: 4 | Iteration: 469 | Classification loss: 0.27062 | Regression loss: 0.62795 | Running loss: 0.88215\n",
      "Epoch: 4 | Iteration: 470 | Classification loss: 0.22525 | Regression loss: 0.53982 | Running loss: 0.88199\n",
      "Epoch: 4 | Iteration: 471 | Classification loss: 0.33331 | Regression loss: 0.59567 | Running loss: 0.88179\n",
      "Epoch: 4 | Iteration: 472 | Classification loss: 0.18638 | Regression loss: 0.52562 | Running loss: 0.88151\n",
      "Epoch: 4 | Iteration: 473 | Classification loss: 0.37601 | Regression loss: 0.58435 | Running loss: 0.88135\n",
      "Epoch: 4 | Iteration: 474 | Classification loss: 0.17080 | Regression loss: 0.46768 | Running loss: 0.88100\n",
      "Epoch: 4 | Iteration: 475 | Classification loss: 0.33365 | Regression loss: 0.53227 | Running loss: 0.88107\n",
      "Epoch: 4 | Iteration: 476 | Classification loss: 0.35665 | Regression loss: 0.61336 | Running loss: 0.88110\n",
      "Epoch: 4 | Iteration: 477 | Classification loss: 0.34890 | Regression loss: 0.76250 | Running loss: 0.88152\n",
      "Epoch: 4 | Iteration: 478 | Classification loss: 0.32624 | Regression loss: 0.64940 | Running loss: 0.88177\n",
      "Epoch: 4 | Iteration: 479 | Classification loss: 0.24004 | Regression loss: 0.54225 | Running loss: 0.88167\n",
      "Epoch: 4 | Iteration: 480 | Classification loss: 0.22330 | Regression loss: 0.50717 | Running loss: 0.88099\n",
      "Epoch: 4 | Iteration: 481 | Classification loss: 0.38177 | Regression loss: 0.84582 | Running loss: 0.88126\n",
      "Epoch: 4 | Iteration: 482 | Classification loss: 0.25041 | Regression loss: 0.55735 | Running loss: 0.88108\n",
      "Epoch: 4 | Iteration: 483 | Classification loss: 0.23813 | Regression loss: 0.47915 | Running loss: 0.88066\n",
      "Epoch: 4 | Iteration: 484 | Classification loss: 0.17759 | Regression loss: 0.48752 | Running loss: 0.87980\n",
      "Epoch: 4 | Iteration: 485 | Classification loss: 0.18512 | Regression loss: 0.51836 | Running loss: 0.87937\n",
      "Epoch: 4 | Iteration: 486 | Classification loss: 0.26404 | Regression loss: 0.65601 | Running loss: 0.87930\n",
      "Epoch: 4 | Iteration: 487 | Classification loss: 0.30133 | Regression loss: 0.67350 | Running loss: 0.87949\n",
      "Epoch: 4 | Iteration: 488 | Classification loss: 0.23930 | Regression loss: 0.55596 | Running loss: 0.87918\n",
      "Epoch: 4 | Iteration: 489 | Classification loss: 0.33608 | Regression loss: 0.63666 | Running loss: 0.87972\n",
      "Epoch: 4 | Iteration: 490 | Classification loss: 0.41157 | Regression loss: 0.62658 | Running loss: 0.88023\n",
      "Epoch: 4 | Iteration: 491 | Classification loss: 0.20378 | Regression loss: 0.57987 | Running loss: 0.88040\n",
      "Epoch: 4 | Iteration: 492 | Classification loss: 0.20135 | Regression loss: 0.44398 | Running loss: 0.87951\n",
      "Epoch: 4 | Iteration: 493 | Classification loss: 0.12039 | Regression loss: 0.31567 | Running loss: 0.87853\n",
      "Epoch: 4 | Iteration: 494 | Classification loss: 0.27413 | Regression loss: 0.58267 | Running loss: 0.87775\n",
      "Epoch: 4 | Iteration: 495 | Classification loss: 0.18394 | Regression loss: 0.51304 | Running loss: 0.87788\n",
      "Epoch: 4 | Iteration: 496 | Classification loss: 0.33335 | Regression loss: 0.72620 | Running loss: 0.87798\n",
      "Epoch: 4 | Iteration: 497 | Classification loss: 0.24274 | Regression loss: 0.49959 | Running loss: 0.87829\n",
      "Epoch: 4 | Iteration: 498 | Classification loss: 0.18301 | Regression loss: 0.47885 | Running loss: 0.87744\n",
      "Epoch: 4 | Iteration: 499 | Classification loss: 0.32175 | Regression loss: 0.72105 | Running loss: 0.87815\n",
      "Epoch: 4 | Iteration: 500 | Classification loss: 0.36173 | Regression loss: 0.75666 | Running loss: 0.87869\n",
      "Epoch: 4 | Iteration: 501 | Classification loss: 0.27882 | Regression loss: 0.48493 | Running loss: 0.87882\n",
      "Epoch: 4 | Iteration: 502 | Classification loss: 0.22323 | Regression loss: 0.58503 | Running loss: 0.87878\n",
      "Epoch: 4 | Iteration: 503 | Classification loss: 0.27239 | Regression loss: 0.53868 | Running loss: 0.87843\n",
      "Epoch: 4 | Iteration: 504 | Classification loss: 0.31117 | Regression loss: 0.65183 | Running loss: 0.87868\n",
      "Epoch: 4 | Iteration: 505 | Classification loss: 0.37755 | Regression loss: 0.74695 | Running loss: 0.87932\n",
      "Epoch: 4 | Iteration: 506 | Classification loss: 0.19785 | Regression loss: 0.43902 | Running loss: 0.87902\n",
      "Epoch: 4 | Iteration: 507 | Classification loss: 0.24032 | Regression loss: 0.55486 | Running loss: 0.87855\n",
      "Epoch: 4 | Iteration: 508 | Classification loss: 0.22372 | Regression loss: 0.54531 | Running loss: 0.87872\n",
      "Epoch: 4 | Iteration: 509 | Classification loss: 0.31739 | Regression loss: 0.79675 | Running loss: 0.87958\n",
      "Epoch: 4 | Iteration: 510 | Classification loss: 0.20887 | Regression loss: 0.48568 | Running loss: 0.87976\n",
      "Epoch: 4 | Iteration: 511 | Classification loss: 0.27279 | Regression loss: 0.59169 | Running loss: 0.88035\n",
      "Epoch: 4 | Iteration: 512 | Classification loss: 0.21434 | Regression loss: 0.51574 | Running loss: 0.88026\n",
      "Epoch: 4 | Iteration: 513 | Classification loss: 0.29899 | Regression loss: 0.68969 | Running loss: 0.88037\n",
      "Epoch: 4 | Iteration: 514 | Classification loss: 0.30483 | Regression loss: 0.55221 | Running loss: 0.88049\n",
      "Epoch: 4 | Iteration: 515 | Classification loss: 0.27496 | Regression loss: 0.66238 | Running loss: 0.88064\n",
      "Epoch: 4 | Iteration: 516 | Classification loss: 0.34512 | Regression loss: 0.67146 | Running loss: 0.88078\n",
      "Epoch: 4 | Iteration: 517 | Classification loss: 0.33004 | Regression loss: 0.46966 | Running loss: 0.88073\n",
      "Epoch: 4 | Iteration: 518 | Classification loss: 0.20734 | Regression loss: 0.52054 | Running loss: 0.88059\n",
      "Epoch: 4 | Iteration: 519 | Classification loss: 0.27790 | Regression loss: 0.48243 | Running loss: 0.88023\n",
      "Epoch: 4 | Iteration: 520 | Classification loss: 0.22464 | Regression loss: 0.45431 | Running loss: 0.88006\n",
      "Epoch: 4 | Iteration: 521 | Classification loss: 0.30256 | Regression loss: 0.72090 | Running loss: 0.88011\n",
      "Epoch: 4 | Iteration: 522 | Classification loss: 0.35436 | Regression loss: 0.51520 | Running loss: 0.87979\n",
      "Epoch: 4 | Iteration: 523 | Classification loss: 0.22256 | Regression loss: 0.58544 | Running loss: 0.87992\n",
      "Epoch: 4 | Iteration: 524 | Classification loss: 0.37988 | Regression loss: 0.73479 | Running loss: 0.88010\n",
      "Epoch: 4 | Iteration: 525 | Classification loss: 0.24503 | Regression loss: 0.59483 | Running loss: 0.88006\n",
      "Epoch: 4 | Iteration: 526 | Classification loss: 0.18607 | Regression loss: 0.54909 | Running loss: 0.87906\n",
      "Epoch: 4 | Iteration: 527 | Classification loss: 0.23821 | Regression loss: 0.57983 | Running loss: 0.87871\n",
      "Epoch: 4 | Iteration: 528 | Classification loss: 0.27069 | Regression loss: 0.60975 | Running loss: 0.87943\n",
      "Epoch: 4 | Iteration: 529 | Classification loss: 0.37098 | Regression loss: 0.76841 | Running loss: 0.87996\n",
      "Epoch: 4 | Iteration: 530 | Classification loss: 0.20068 | Regression loss: 0.41361 | Running loss: 0.87940\n",
      "Epoch: 4 | Iteration: 531 | Classification loss: 0.30959 | Regression loss: 0.61564 | Running loss: 0.87989\n",
      "Epoch: 4 | Iteration: 532 | Classification loss: 0.23702 | Regression loss: 0.63018 | Running loss: 0.87970\n",
      "Epoch: 4 | Iteration: 533 | Classification loss: 0.31688 | Regression loss: 0.58671 | Running loss: 0.87942\n",
      "Epoch: 4 | Iteration: 534 | Classification loss: 0.25687 | Regression loss: 0.60256 | Running loss: 0.87984\n",
      "Epoch: 4 | Iteration: 535 | Classification loss: 0.35300 | Regression loss: 0.76851 | Running loss: 0.88006\n",
      "Epoch: 4 | Iteration: 536 | Classification loss: 0.23643 | Regression loss: 0.47911 | Running loss: 0.87922\n",
      "Epoch: 4 | Iteration: 537 | Classification loss: 0.24012 | Regression loss: 0.55829 | Running loss: 0.87943\n",
      "Epoch: 4 | Iteration: 538 | Classification loss: 0.26692 | Regression loss: 0.67080 | Running loss: 0.87913\n",
      "Epoch: 4 | Iteration: 539 | Classification loss: 0.30279 | Regression loss: 0.50082 | Running loss: 0.87928\n",
      "Epoch: 4 | Iteration: 540 | Classification loss: 0.35177 | Regression loss: 0.71929 | Running loss: 0.88001\n",
      "Epoch: 4 | Iteration: 541 | Classification loss: 0.19875 | Regression loss: 0.53283 | Running loss: 0.87964\n",
      "Epoch: 4 | Iteration: 542 | Classification loss: 0.32804 | Regression loss: 0.57748 | Running loss: 0.87962\n",
      "Epoch: 4 | Iteration: 543 | Classification loss: 0.32111 | Regression loss: 0.70756 | Running loss: 0.88010\n",
      "Epoch: 4 | Iteration: 544 | Classification loss: 0.25895 | Regression loss: 0.68094 | Running loss: 0.88013\n",
      "Epoch: 4 | Iteration: 545 | Classification loss: 0.31130 | Regression loss: 0.71908 | Running loss: 0.88074\n",
      "Epoch: 4 | Iteration: 546 | Classification loss: 0.21059 | Regression loss: 0.58907 | Running loss: 0.88074\n",
      "Epoch: 4 | Iteration: 547 | Classification loss: 0.33907 | Regression loss: 0.68124 | Running loss: 0.88096\n",
      "Epoch: 4 | Iteration: 548 | Classification loss: 0.26799 | Regression loss: 0.52195 | Running loss: 0.88173\n",
      "Epoch: 4 | Iteration: 549 | Classification loss: 0.23586 | Regression loss: 0.51156 | Running loss: 0.88105\n",
      "Epoch: 4 | Iteration: 550 | Classification loss: 0.17772 | Regression loss: 0.48119 | Running loss: 0.88060\n",
      "Epoch: 4 | Iteration: 551 | Classification loss: 0.20475 | Regression loss: 0.55735 | Running loss: 0.88034\n",
      "Epoch: 4 | Iteration: 552 | Classification loss: 0.20257 | Regression loss: 0.50527 | Running loss: 0.87962\n",
      "Epoch: 4 | Iteration: 553 | Classification loss: 0.26043 | Regression loss: 0.54517 | Running loss: 0.87912\n",
      "Epoch: 4 | Iteration: 554 | Classification loss: 0.22686 | Regression loss: 0.59516 | Running loss: 0.87869\n",
      "Epoch: 4 | Iteration: 555 | Classification loss: 0.26515 | Regression loss: 0.58082 | Running loss: 0.87860\n",
      "Epoch: 4 | Iteration: 556 | Classification loss: 0.18875 | Regression loss: 0.46770 | Running loss: 0.87796\n",
      "Epoch: 4 | Iteration: 557 | Classification loss: 0.26619 | Regression loss: 0.47309 | Running loss: 0.87747\n",
      "Epoch: 4 | Iteration: 558 | Classification loss: 0.29370 | Regression loss: 0.71430 | Running loss: 0.87794\n",
      "Epoch: 4 | Iteration: 559 | Classification loss: 0.15979 | Regression loss: 0.48492 | Running loss: 0.87725\n",
      "Epoch: 4 | Iteration: 560 | Classification loss: 0.26037 | Regression loss: 0.58346 | Running loss: 0.87717\n",
      "Epoch: 4 | Iteration: 561 | Classification loss: 0.30393 | Regression loss: 0.66876 | Running loss: 0.87747\n",
      "Epoch: 4 | Iteration: 562 | Classification loss: 0.29144 | Regression loss: 0.63748 | Running loss: 0.87756\n",
      "Epoch: 4 | Iteration: 563 | Classification loss: 0.25091 | Regression loss: 0.52225 | Running loss: 0.87715\n",
      "Epoch: 4 | Iteration: 564 | Classification loss: 0.35629 | Regression loss: 0.64483 | Running loss: 0.87778\n",
      "Epoch: 4 | Iteration: 565 | Classification loss: 0.27003 | Regression loss: 0.62917 | Running loss: 0.87804\n",
      "Epoch: 4 | Iteration: 566 | Classification loss: 0.29999 | Regression loss: 0.57914 | Running loss: 0.87813\n",
      "Epoch: 4 | Iteration: 567 | Classification loss: 0.23102 | Regression loss: 0.58165 | Running loss: 0.87775\n",
      "Epoch: 4 | Iteration: 568 | Classification loss: 0.37356 | Regression loss: 0.29191 | Running loss: 0.87754\n",
      "Epoch: 4 | Iteration: 569 | Classification loss: 0.29709 | Regression loss: 0.62704 | Running loss: 0.87782\n",
      "Epoch: 4 | Iteration: 570 | Classification loss: 0.20112 | Regression loss: 0.61066 | Running loss: 0.87778\n",
      "Epoch: 4 | Iteration: 571 | Classification loss: 0.32828 | Regression loss: 0.58779 | Running loss: 0.87758\n",
      "Epoch: 4 | Iteration: 572 | Classification loss: 0.25429 | Regression loss: 0.49905 | Running loss: 0.87714\n",
      "Epoch: 4 | Iteration: 573 | Classification loss: 0.36263 | Regression loss: 0.75797 | Running loss: 0.87756\n",
      "Epoch: 4 | Iteration: 574 | Classification loss: 0.25365 | Regression loss: 0.69407 | Running loss: 0.87743\n",
      "Epoch: 4 | Iteration: 575 | Classification loss: 0.34685 | Regression loss: 0.69488 | Running loss: 0.87766\n",
      "Epoch: 4 | Iteration: 576 | Classification loss: 0.28158 | Regression loss: 0.61010 | Running loss: 0.87827\n",
      "Epoch: 4 | Iteration: 577 | Classification loss: 0.41722 | Regression loss: 0.74629 | Running loss: 0.87897\n",
      "Epoch: 4 | Iteration: 578 | Classification loss: 0.12977 | Regression loss: 0.45666 | Running loss: 0.87842\n",
      "Epoch: 4 | Iteration: 579 | Classification loss: 0.26560 | Regression loss: 0.51677 | Running loss: 0.87799\n",
      "Epoch: 4 | Iteration: 580 | Classification loss: 0.37030 | Regression loss: 0.70957 | Running loss: 0.87807\n",
      "Epoch: 4 | Iteration: 581 | Classification loss: 0.20916 | Regression loss: 0.55418 | Running loss: 0.87789\n",
      "Epoch: 4 | Iteration: 582 | Classification loss: 0.28836 | Regression loss: 0.44389 | Running loss: 0.87778\n",
      "Epoch: 4 | Iteration: 583 | Classification loss: 0.26977 | Regression loss: 0.46414 | Running loss: 0.87744\n",
      "Epoch: 4 | Iteration: 584 | Classification loss: 0.44005 | Regression loss: 0.82301 | Running loss: 0.87787\n",
      "Epoch: 4 | Iteration: 585 | Classification loss: 0.24731 | Regression loss: 0.52962 | Running loss: 0.87797\n",
      "Epoch: 4 | Iteration: 586 | Classification loss: 0.24664 | Regression loss: 0.60225 | Running loss: 0.87798\n",
      "Epoch: 4 | Iteration: 587 | Classification loss: 0.26375 | Regression loss: 0.60396 | Running loss: 0.87744\n",
      "Epoch: 4 | Iteration: 588 | Classification loss: 0.36427 | Regression loss: 0.72304 | Running loss: 0.87761\n",
      "Epoch: 4 | Iteration: 589 | Classification loss: 0.26723 | Regression loss: 0.65059 | Running loss: 0.87781\n",
      "Epoch: 4 | Iteration: 590 | Classification loss: 0.53182 | Regression loss: 0.65607 | Running loss: 0.87857\n",
      "Epoch: 4 | Iteration: 591 | Classification loss: 0.24123 | Regression loss: 0.55315 | Running loss: 0.87862\n",
      "Epoch: 4 | Iteration: 592 | Classification loss: 0.26610 | Regression loss: 0.60506 | Running loss: 0.87864\n",
      "Epoch: 4 | Iteration: 593 | Classification loss: 0.21807 | Regression loss: 0.55118 | Running loss: 0.87825\n",
      "Epoch: 4 | Iteration: 594 | Classification loss: 0.23519 | Regression loss: 0.63341 | Running loss: 0.87821\n",
      "Epoch: 4 | Iteration: 595 | Classification loss: 0.23007 | Regression loss: 0.57901 | Running loss: 0.87824\n",
      "Epoch: 4 | Iteration: 596 | Classification loss: 0.28637 | Regression loss: 0.56596 | Running loss: 0.87808\n",
      "Epoch: 4 | Iteration: 597 | Classification loss: 0.18953 | Regression loss: 0.50386 | Running loss: 0.87716\n",
      "Epoch: 4 | Iteration: 598 | Classification loss: 0.15648 | Regression loss: 0.36036 | Running loss: 0.87645\n",
      "Epoch: 4 | Iteration: 599 | Classification loss: 0.54090 | Regression loss: 0.80581 | Running loss: 0.87761\n",
      "Epoch: 4 | Iteration: 600 | Classification loss: 0.30379 | Regression loss: 0.77506 | Running loss: 0.87819\n",
      "Epoch: 4 | Iteration: 601 | Classification loss: 0.34510 | Regression loss: 0.62833 | Running loss: 0.87854\n",
      "Epoch: 4 | Iteration: 602 | Classification loss: 0.25288 | Regression loss: 0.58870 | Running loss: 0.87849\n",
      "Epoch: 4 | Iteration: 603 | Classification loss: 0.27009 | Regression loss: 0.55957 | Running loss: 0.87829\n",
      "Epoch: 4 | Iteration: 604 | Classification loss: 0.16388 | Regression loss: 0.47149 | Running loss: 0.87805\n",
      "Epoch: 4 | Iteration: 605 | Classification loss: 0.25544 | Regression loss: 0.58421 | Running loss: 0.87814\n",
      "Epoch: 4 | Iteration: 606 | Classification loss: 0.37115 | Regression loss: 0.71190 | Running loss: 0.87899\n",
      "Epoch: 4 | Iteration: 607 | Classification loss: 0.42010 | Regression loss: 0.78579 | Running loss: 0.87964\n",
      "Epoch: 4 | Iteration: 608 | Classification loss: 0.26236 | Regression loss: 0.62015 | Running loss: 0.87965\n",
      "Epoch: 4 | Iteration: 609 | Classification loss: 0.25667 | Regression loss: 0.59134 | Running loss: 0.88003\n",
      "Epoch: 4 | Iteration: 610 | Classification loss: 0.24797 | Regression loss: 0.57347 | Running loss: 0.88019\n",
      "Epoch: 4 | Iteration: 611 | Classification loss: 0.35217 | Regression loss: 0.56023 | Running loss: 0.88076\n",
      "Epoch: 4 | Iteration: 612 | Classification loss: 0.32470 | Regression loss: 0.74640 | Running loss: 0.88121\n",
      "Epoch: 4 | Iteration: 613 | Classification loss: 0.19333 | Regression loss: 0.50775 | Running loss: 0.88090\n",
      "Epoch: 4 | Iteration: 614 | Classification loss: 0.19325 | Regression loss: 0.36325 | Running loss: 0.88030\n",
      "Epoch: 4 | Iteration: 615 | Classification loss: 0.28513 | Regression loss: 0.59443 | Running loss: 0.88043\n",
      "Epoch: 4 | Iteration: 616 | Classification loss: 0.41930 | Regression loss: 0.64186 | Running loss: 0.88032\n",
      "Epoch: 4 | Iteration: 617 | Classification loss: 0.23629 | Regression loss: 0.53533 | Running loss: 0.88000\n",
      "Epoch: 4 | Iteration: 618 | Classification loss: 0.32406 | Regression loss: 0.62935 | Running loss: 0.88034\n",
      "Epoch: 4 | Iteration: 619 | Classification loss: 0.35317 | Regression loss: 0.66399 | Running loss: 0.88017\n",
      "Epoch: 4 | Iteration: 620 | Classification loss: 0.29334 | Regression loss: 0.59031 | Running loss: 0.88003\n",
      "Epoch: 4 | Iteration: 621 | Classification loss: 0.29324 | Regression loss: 0.65792 | Running loss: 0.87983\n",
      "Epoch: 4 | Iteration: 622 | Classification loss: 0.25214 | Regression loss: 0.62277 | Running loss: 0.87971\n",
      "Epoch: 4 | Iteration: 623 | Classification loss: 0.35058 | Regression loss: 0.69462 | Running loss: 0.88004\n",
      "Epoch: 4 | Iteration: 624 | Classification loss: 0.34176 | Regression loss: 0.71948 | Running loss: 0.88065\n",
      "Epoch: 4 | Iteration: 625 | Classification loss: 0.38557 | Regression loss: 0.77703 | Running loss: 0.88122\n",
      "Epoch: 4 | Iteration: 626 | Classification loss: 0.31815 | Regression loss: 0.64804 | Running loss: 0.88213\n",
      "Epoch: 4 | Iteration: 627 | Classification loss: 0.25082 | Regression loss: 0.51462 | Running loss: 0.88174\n",
      "Epoch: 4 | Iteration: 628 | Classification loss: 0.25819 | Regression loss: 0.49026 | Running loss: 0.88118\n",
      "Epoch: 4 | Iteration: 629 | Classification loss: 0.33787 | Regression loss: 0.50470 | Running loss: 0.88088\n",
      "Epoch: 4 | Iteration: 630 | Classification loss: 0.23908 | Regression loss: 0.52393 | Running loss: 0.88072\n",
      "Epoch: 4 | Iteration: 631 | Classification loss: 0.25950 | Regression loss: 0.60623 | Running loss: 0.88071\n",
      "Epoch: 4 | Iteration: 632 | Classification loss: 0.45897 | Regression loss: 0.60514 | Running loss: 0.88109\n",
      "Epoch: 4 | Iteration: 633 | Classification loss: 0.20902 | Regression loss: 0.66302 | Running loss: 0.88081\n",
      "Epoch: 4 | Iteration: 634 | Classification loss: 0.40746 | Regression loss: 0.73815 | Running loss: 0.88146\n",
      "Epoch: 4 | Iteration: 635 | Classification loss: 0.39316 | Regression loss: 0.85053 | Running loss: 0.88257\n",
      "Epoch: 4 | Iteration: 636 | Classification loss: 0.32725 | Regression loss: 0.64908 | Running loss: 0.88313\n",
      "Epoch: 4 | Iteration: 637 | Classification loss: 0.32508 | Regression loss: 0.71805 | Running loss: 0.88383\n",
      "Epoch: 4 | Iteration: 638 | Classification loss: 0.21694 | Regression loss: 0.50992 | Running loss: 0.88300\n",
      "Epoch: 4 | Iteration: 639 | Classification loss: 0.28146 | Regression loss: 0.57386 | Running loss: 0.88293\n",
      "Epoch: 4 | Iteration: 640 | Classification loss: 0.30568 | Regression loss: 0.66448 | Running loss: 0.88275\n",
      "Epoch: 4 | Iteration: 641 | Classification loss: 0.32056 | Regression loss: 0.48099 | Running loss: 0.88235\n",
      "Epoch: 4 | Iteration: 642 | Classification loss: 0.24487 | Regression loss: 0.59367 | Running loss: 0.88189\n",
      "Epoch: 4 | Iteration: 643 | Classification loss: 0.40060 | Regression loss: 0.63283 | Running loss: 0.88235\n",
      "Epoch: 4 | Iteration: 644 | Classification loss: 0.25829 | Regression loss: 0.70382 | Running loss: 0.88243\n",
      "Epoch: 4 | Iteration: 645 | Classification loss: 0.43689 | Regression loss: 0.82135 | Running loss: 0.88309\n",
      "Epoch: 4 | Iteration: 646 | Classification loss: 0.34298 | Regression loss: 0.72030 | Running loss: 0.88327\n",
      "Epoch: 4 | Iteration: 647 | Classification loss: 0.30154 | Regression loss: 0.67430 | Running loss: 0.88356\n",
      "Epoch: 4 | Iteration: 648 | Classification loss: 0.38080 | Regression loss: 0.80753 | Running loss: 0.88407\n",
      "Epoch: 4 | Iteration: 649 | Classification loss: 0.32269 | Regression loss: 0.49306 | Running loss: 0.88433\n",
      "Epoch: 4 | Iteration: 650 | Classification loss: 0.28602 | Regression loss: 0.48973 | Running loss: 0.88384\n",
      "Epoch: 4 | Iteration: 651 | Classification loss: 0.32447 | Regression loss: 0.65633 | Running loss: 0.88383\n",
      "Epoch: 4 | Iteration: 652 | Classification loss: 0.36800 | Regression loss: 0.67828 | Running loss: 0.88378\n",
      "Epoch: 4 | Iteration: 653 | Classification loss: 0.24619 | Regression loss: 0.62103 | Running loss: 0.88395\n",
      "Epoch: 4 | Iteration: 654 | Classification loss: 0.25755 | Regression loss: 0.56654 | Running loss: 0.88445\n",
      "Epoch: 4 | Iteration: 655 | Classification loss: 0.33803 | Regression loss: 0.67840 | Running loss: 0.88488\n",
      "Epoch: 4 | Iteration: 656 | Classification loss: 0.41376 | Regression loss: 0.71375 | Running loss: 0.88512\n",
      "Epoch: 4 | Iteration: 657 | Classification loss: 0.32233 | Regression loss: 0.70501 | Running loss: 0.88507\n",
      "Epoch: 4 | Iteration: 658 | Classification loss: 0.21393 | Regression loss: 0.62605 | Running loss: 0.88504\n",
      "Epoch: 4 | Iteration: 659 | Classification loss: 0.35704 | Regression loss: 0.58038 | Running loss: 0.88526\n",
      "Epoch: 4 | Iteration: 660 | Classification loss: 0.23001 | Regression loss: 0.58976 | Running loss: 0.88481\n",
      "Epoch: 4 | Iteration: 661 | Classification loss: 0.24183 | Regression loss: 0.64016 | Running loss: 0.88575\n",
      "Epoch: 4 | Iteration: 662 | Classification loss: 0.28217 | Regression loss: 0.69171 | Running loss: 0.88591\n",
      "Epoch: 4 | Iteration: 663 | Classification loss: 0.34842 | Regression loss: 0.70508 | Running loss: 0.88615\n",
      "Epoch: 4 | Iteration: 664 | Classification loss: 0.31246 | Regression loss: 0.60825 | Running loss: 0.88698\n",
      "Epoch: 4 | Iteration: 665 | Classification loss: 0.25500 | Regression loss: 0.48960 | Running loss: 0.88666\n",
      "Epoch: 4 | Iteration: 666 | Classification loss: 0.26609 | Regression loss: 0.69257 | Running loss: 0.88644\n",
      "Epoch: 4 | Iteration: 667 | Classification loss: 0.23252 | Regression loss: 0.58924 | Running loss: 0.88571\n",
      "Epoch: 4 | Iteration: 668 | Classification loss: 0.29395 | Regression loss: 0.70050 | Running loss: 0.88630\n",
      "Epoch: 4 | Iteration: 669 | Classification loss: 0.36887 | Regression loss: 0.60805 | Running loss: 0.88647\n",
      "Epoch: 4 | Iteration: 670 | Classification loss: 0.31113 | Regression loss: 0.75167 | Running loss: 0.88684\n",
      "Epoch: 4 | Iteration: 671 | Classification loss: 0.27879 | Regression loss: 0.55218 | Running loss: 0.88656\n",
      "Epoch: 4 | Iteration: 672 | Classification loss: 0.34406 | Regression loss: 0.65023 | Running loss: 0.88732\n",
      "Epoch: 4 | Iteration: 673 | Classification loss: 0.27600 | Regression loss: 0.42901 | Running loss: 0.88679\n",
      "Epoch: 4 | Iteration: 674 | Classification loss: 0.27316 | Regression loss: 0.53755 | Running loss: 0.88700\n",
      "Epoch: 4 | Iteration: 675 | Classification loss: 0.23982 | Regression loss: 0.65868 | Running loss: 0.88706\n",
      "Epoch: 4 | Iteration: 676 | Classification loss: 0.18444 | Regression loss: 0.45564 | Running loss: 0.88666\n",
      "Epoch: 4 | Iteration: 677 | Classification loss: 0.30658 | Regression loss: 0.69121 | Running loss: 0.88713\n",
      "Epoch: 4 | Iteration: 678 | Classification loss: 0.37493 | Regression loss: 0.74236 | Running loss: 0.88735\n",
      "Epoch: 4 | Iteration: 679 | Classification loss: 0.27623 | Regression loss: 0.59908 | Running loss: 0.88722\n",
      "Epoch: 4 | Iteration: 680 | Classification loss: 0.16991 | Regression loss: 0.46893 | Running loss: 0.88656\n",
      "Epoch: 4 | Iteration: 681 | Classification loss: 0.25488 | Regression loss: 0.62286 | Running loss: 0.88635\n",
      "Epoch: 4 | Iteration: 682 | Classification loss: 0.22268 | Regression loss: 0.55600 | Running loss: 0.88579\n",
      "Epoch: 4 | Iteration: 683 | Classification loss: 0.28602 | Regression loss: 0.40309 | Running loss: 0.88580\n",
      "Epoch: 4 | Iteration: 684 | Classification loss: 0.30484 | Regression loss: 0.62337 | Running loss: 0.88604\n",
      "Epoch: 4 | Iteration: 685 | Classification loss: 0.29015 | Regression loss: 0.58629 | Running loss: 0.88589\n",
      "Epoch: 4 | Iteration: 686 | Classification loss: 0.32297 | Regression loss: 0.51219 | Running loss: 0.88566\n",
      "Epoch: 4 | Iteration: 687 | Classification loss: 0.23190 | Regression loss: 0.53757 | Running loss: 0.88549\n",
      "Epoch: 4 | Iteration: 688 | Classification loss: 0.30680 | Regression loss: 0.57279 | Running loss: 0.88529\n",
      "Epoch: 4 | Iteration: 689 | Classification loss: 0.25860 | Regression loss: 0.59278 | Running loss: 0.88601\n",
      "Epoch: 4 | Iteration: 690 | Classification loss: 0.34179 | Regression loss: 0.57452 | Running loss: 0.88624\n",
      "Epoch: 4 | Iteration: 691 | Classification loss: 0.34275 | Regression loss: 0.58644 | Running loss: 0.88618\n",
      "Epoch: 4 | Iteration: 692 | Classification loss: 0.16431 | Regression loss: 0.49477 | Running loss: 0.88560\n",
      "Epoch: 4 | Iteration: 693 | Classification loss: 0.26855 | Regression loss: 0.64671 | Running loss: 0.88623\n",
      "Epoch: 4 | Iteration: 694 | Classification loss: 0.37104 | Regression loss: 0.65314 | Running loss: 0.88603\n",
      "Epoch: 4 | Iteration: 695 | Classification loss: 0.23709 | Regression loss: 0.47229 | Running loss: 0.88501\n",
      "Epoch: 4 | Iteration: 696 | Classification loss: 0.32640 | Regression loss: 0.57123 | Running loss: 0.88558\n",
      "Epoch: 4 | Iteration: 697 | Classification loss: 0.27212 | Regression loss: 0.63938 | Running loss: 0.88548\n",
      "Epoch: 4 | Iteration: 698 | Classification loss: 0.27261 | Regression loss: 0.68199 | Running loss: 0.88642\n",
      "Epoch: 4 | Iteration: 699 | Classification loss: 0.26628 | Regression loss: 0.55681 | Running loss: 0.88606\n",
      "Epoch: 4 | Iteration: 700 | Classification loss: 0.19955 | Regression loss: 0.53954 | Running loss: 0.88565\n",
      "Epoch: 4 | Iteration: 701 | Classification loss: 0.28861 | Regression loss: 0.64521 | Running loss: 0.88594\n",
      "Epoch: 4 | Iteration: 702 | Classification loss: 0.23977 | Regression loss: 0.44579 | Running loss: 0.88546\n",
      "Epoch: 4 | Iteration: 703 | Classification loss: 0.19521 | Regression loss: 0.45682 | Running loss: 0.88471\n",
      "Epoch: 4 | Iteration: 704 | Classification loss: 0.22408 | Regression loss: 0.54230 | Running loss: 0.88448\n",
      "Epoch: 4 | Iteration: 705 | Classification loss: 0.33092 | Regression loss: 0.49961 | Running loss: 0.88452\n",
      "Epoch: 4 | Iteration: 706 | Classification loss: 0.35331 | Regression loss: 0.77471 | Running loss: 0.88469\n",
      "Epoch: 4 | Iteration: 707 | Classification loss: 0.30752 | Regression loss: 0.48409 | Running loss: 0.88484\n",
      "Epoch: 4 | Iteration: 708 | Classification loss: 0.34883 | Regression loss: 0.54276 | Running loss: 0.88484\n",
      "Epoch: 4 | Iteration: 709 | Classification loss: 0.30983 | Regression loss: 0.65060 | Running loss: 0.88541\n",
      "Epoch: 4 | Iteration: 710 | Classification loss: 0.39267 | Regression loss: 0.75723 | Running loss: 0.88599\n",
      "Epoch: 4 | Iteration: 711 | Classification loss: 0.27453 | Regression loss: 0.57066 | Running loss: 0.88674\n",
      "Epoch: 4 | Iteration: 712 | Classification loss: 0.29158 | Regression loss: 0.61079 | Running loss: 0.88626\n",
      "Epoch: 4 | Iteration: 713 | Classification loss: 0.31339 | Regression loss: 0.68662 | Running loss: 0.88667\n",
      "Epoch: 4 | Iteration: 714 | Classification loss: 0.35002 | Regression loss: 0.67522 | Running loss: 0.88692\n",
      "Epoch: 4 | Iteration: 715 | Classification loss: 0.23014 | Regression loss: 0.44957 | Running loss: 0.88641\n",
      "Epoch: 4 | Iteration: 716 | Classification loss: 0.27562 | Regression loss: 0.59676 | Running loss: 0.88655\n",
      "Epoch: 4 | Iteration: 717 | Classification loss: 0.35210 | Regression loss: 0.60076 | Running loss: 0.88644\n",
      "Epoch: 4 | Iteration: 718 | Classification loss: 0.27973 | Regression loss: 0.62433 | Running loss: 0.88653\n",
      "Epoch: 4 | Iteration: 719 | Classification loss: 0.22935 | Regression loss: 0.67149 | Running loss: 0.88646\n",
      "Epoch: 4 | Iteration: 720 | Classification loss: 0.34701 | Regression loss: 0.74195 | Running loss: 0.88714\n",
      "Epoch: 4 | Iteration: 721 | Classification loss: 0.28764 | Regression loss: 0.49960 | Running loss: 0.88705\n",
      "Epoch: 4 | Iteration: 722 | Classification loss: 0.33997 | Regression loss: 0.56303 | Running loss: 0.88725\n",
      "Epoch: 4 | Iteration: 723 | Classification loss: 0.29419 | Regression loss: 0.61041 | Running loss: 0.88758\n",
      "Epoch: 4 | Iteration: 724 | Classification loss: 0.15943 | Regression loss: 0.42146 | Running loss: 0.88727\n",
      "Epoch: 4 | Iteration: 725 | Classification loss: 0.24274 | Regression loss: 0.53124 | Running loss: 0.88713\n",
      "Epoch: 4 | Iteration: 726 | Classification loss: 0.28859 | Regression loss: 0.56265 | Running loss: 0.88747\n",
      "Epoch: 4 | Iteration: 727 | Classification loss: 0.19711 | Regression loss: 0.55836 | Running loss: 0.88696\n",
      "Epoch: 4 | Iteration: 728 | Classification loss: 0.34508 | Regression loss: 0.66361 | Running loss: 0.88765\n",
      "Epoch: 4 | Iteration: 729 | Classification loss: 0.33854 | Regression loss: 0.70305 | Running loss: 0.88788\n",
      "Epoch: 4 | Iteration: 730 | Classification loss: 0.30706 | Regression loss: 0.56390 | Running loss: 0.88804\n",
      "Epoch: 4 | Iteration: 731 | Classification loss: 0.57355 | Regression loss: 0.62492 | Running loss: 0.88869\n",
      "Epoch: 4 | Iteration: 732 | Classification loss: 0.48941 | Regression loss: 0.80083 | Running loss: 0.88918\n",
      "Epoch: 4 | Iteration: 733 | Classification loss: 0.27651 | Regression loss: 0.60824 | Running loss: 0.88898\n",
      "Epoch: 4 | Iteration: 734 | Classification loss: 0.33697 | Regression loss: 0.61568 | Running loss: 0.88900\n",
      "Epoch: 4 | Iteration: 735 | Classification loss: 0.27163 | Regression loss: 0.58329 | Running loss: 0.88855\n",
      "Epoch: 4 | Iteration: 736 | Classification loss: 0.25194 | Regression loss: 0.50693 | Running loss: 0.88846\n",
      "Epoch: 4 | Iteration: 737 | Classification loss: 0.39703 | Regression loss: 0.69700 | Running loss: 0.88847\n",
      "Epoch: 4 | Iteration: 738 | Classification loss: 0.35759 | Regression loss: 0.64788 | Running loss: 0.88818\n",
      "Epoch: 4 | Iteration: 739 | Classification loss: 0.35275 | Regression loss: 0.65798 | Running loss: 0.88817\n",
      "Epoch: 4 | Iteration: 740 | Classification loss: 0.21409 | Regression loss: 0.61609 | Running loss: 0.88803\n",
      "Epoch: 4 | Iteration: 741 | Classification loss: 0.28699 | Regression loss: 0.66932 | Running loss: 0.88842\n",
      "Epoch: 4 | Iteration: 742 | Classification loss: 0.28328 | Regression loss: 0.69222 | Running loss: 0.88844\n",
      "Epoch: 4 | Iteration: 743 | Classification loss: 0.28128 | Regression loss: 0.61786 | Running loss: 0.88831\n",
      "Epoch: 4 | Iteration: 744 | Classification loss: 0.28050 | Regression loss: 0.59729 | Running loss: 0.88816\n",
      "Epoch: 4 | Iteration: 745 | Classification loss: 0.37113 | Regression loss: 0.62055 | Running loss: 0.88807\n",
      "Epoch: 4 | Iteration: 746 | Classification loss: 0.33438 | Regression loss: 0.60729 | Running loss: 0.88846\n",
      "Epoch: 4 | Iteration: 747 | Classification loss: 0.20875 | Regression loss: 0.42893 | Running loss: 0.88838\n",
      "Epoch: 4 | Iteration: 748 | Classification loss: 0.30925 | Regression loss: 0.65099 | Running loss: 0.88918\n",
      "Epoch: 4 | Iteration: 749 | Classification loss: 0.29627 | Regression loss: 0.56566 | Running loss: 0.88920\n",
      "Epoch: 4 | Iteration: 750 | Classification loss: 0.24674 | Regression loss: 0.48832 | Running loss: 0.88868\n",
      "Epoch: 4 | Iteration: 751 | Classification loss: 0.26544 | Regression loss: 0.61498 | Running loss: 0.88858\n",
      "Epoch: 4 | Iteration: 752 | Classification loss: 0.21886 | Regression loss: 0.45847 | Running loss: 0.88847\n",
      "Epoch: 4 | Iteration: 753 | Classification loss: 0.29696 | Regression loss: 0.58278 | Running loss: 0.88808\n",
      "Epoch: 4 | Iteration: 754 | Classification loss: 0.23593 | Regression loss: 0.43635 | Running loss: 0.88761\n",
      "Epoch: 4 | Iteration: 755 | Classification loss: 0.23311 | Regression loss: 0.53156 | Running loss: 0.88729\n",
      "Epoch: 4 | Iteration: 756 | Classification loss: 0.31606 | Regression loss: 0.60415 | Running loss: 0.88746\n",
      "Epoch: 4 | Iteration: 757 | Classification loss: 0.30353 | Regression loss: 0.66501 | Running loss: 0.88812\n",
      "Epoch: 4 | Iteration: 758 | Classification loss: 0.30063 | Regression loss: 0.66008 | Running loss: 0.88840\n",
      "Epoch: 4 | Iteration: 759 | Classification loss: 0.21988 | Regression loss: 0.48469 | Running loss: 0.88818\n",
      "Epoch: 4 | Iteration: 760 | Classification loss: 0.27603 | Regression loss: 0.59149 | Running loss: 0.88818\n",
      "Epoch: 4 | Iteration: 761 | Classification loss: 0.44254 | Regression loss: 0.67925 | Running loss: 0.88838\n",
      "Epoch: 4 | Iteration: 762 | Classification loss: 0.25369 | Regression loss: 0.64238 | Running loss: 0.88835\n",
      "Epoch: 4 | Iteration: 763 | Classification loss: 0.33075 | Regression loss: 0.71062 | Running loss: 0.88870\n",
      "Epoch: 4 | Iteration: 764 | Classification loss: 0.27721 | Regression loss: 0.61967 | Running loss: 0.88844\n",
      "Epoch: 4 | Iteration: 765 | Classification loss: 0.34765 | Regression loss: 0.68177 | Running loss: 0.88875\n",
      "Epoch: 4 | Iteration: 766 | Classification loss: 0.17351 | Regression loss: 0.53081 | Running loss: 0.88802\n",
      "Epoch: 4 | Iteration: 767 | Classification loss: 0.85913 | Regression loss: 0.80818 | Running loss: 0.88971\n",
      "Epoch: 4 | Iteration: 768 | Classification loss: 0.24859 | Regression loss: 0.48835 | Running loss: 0.88947\n",
      "Epoch: 4 | Iteration: 769 | Classification loss: 0.19762 | Regression loss: 0.48250 | Running loss: 0.88859\n",
      "Epoch: 4 | Iteration: 770 | Classification loss: 0.29256 | Regression loss: 0.62179 | Running loss: 0.88859\n",
      "Epoch: 4 | Iteration: 771 | Classification loss: 0.18375 | Regression loss: 0.44871 | Running loss: 0.88864\n",
      "Epoch: 4 | Iteration: 772 | Classification loss: 0.15278 | Regression loss: 0.46807 | Running loss: 0.88794\n",
      "Epoch: 4 | Iteration: 773 | Classification loss: 0.25421 | Regression loss: 0.50337 | Running loss: 0.88735\n",
      "Epoch: 4 | Iteration: 774 | Classification loss: 0.17263 | Regression loss: 0.52492 | Running loss: 0.88699\n",
      "Epoch: 4 | Iteration: 775 | Classification loss: 0.24374 | Regression loss: 0.55523 | Running loss: 0.88721\n",
      "Epoch: 4 | Iteration: 776 | Classification loss: 0.25027 | Regression loss: 0.59776 | Running loss: 0.88711\n",
      "Epoch: 4 | Iteration: 777 | Classification loss: 0.32199 | Regression loss: 0.68344 | Running loss: 0.88745\n",
      "Epoch: 4 | Iteration: 778 | Classification loss: 0.23667 | Regression loss: 0.49866 | Running loss: 0.88706\n",
      "Epoch: 4 | Iteration: 779 | Classification loss: 0.31645 | Regression loss: 0.55089 | Running loss: 0.88720\n",
      "Epoch: 4 | Iteration: 780 | Classification loss: 0.34858 | Regression loss: 0.74919 | Running loss: 0.88734\n",
      "Epoch: 4 | Iteration: 781 | Classification loss: 0.30290 | Regression loss: 0.61020 | Running loss: 0.88743\n",
      "Epoch: 4 | Iteration: 782 | Classification loss: 0.18073 | Regression loss: 0.44543 | Running loss: 0.88675\n",
      "Epoch: 4 | Iteration: 783 | Classification loss: 0.20989 | Regression loss: 0.64530 | Running loss: 0.88670\n",
      "Evaluating dataset\n",
      "\n",
      "mAP:\n",
      "person: 0.41963800887006825\n",
      "Precision:  0.04790227224161265\n",
      "Recall:  0.7637705848949461\n",
      "car: 0.5053834865103343\n",
      "Precision:  0.04790227224161265\n",
      "Recall:  0.7637705848949461\n",
      "Epoch: 5 | Iteration: 0 | Classification loss: 0.30285 | Regression loss: 0.65336 | Running loss: 0.88702\n",
      "Epoch: 5 | Iteration: 1 | Classification loss: 0.30043 | Regression loss: 0.84796 | Running loss: 0.88728\n",
      "Epoch: 5 | Iteration: 2 | Classification loss: 0.25939 | Regression loss: 0.63796 | Running loss: 0.88728\n",
      "Epoch: 5 | Iteration: 3 | Classification loss: 0.29284 | Regression loss: 0.52250 | Running loss: 0.88704\n",
      "Epoch: 5 | Iteration: 4 | Classification loss: 0.27741 | Regression loss: 0.71902 | Running loss: 0.88742\n",
      "Epoch: 5 | Iteration: 5 | Classification loss: 0.37040 | Regression loss: 0.60746 | Running loss: 0.88723\n",
      "Epoch: 5 | Iteration: 6 | Classification loss: 0.29109 | Regression loss: 0.57801 | Running loss: 0.88746\n",
      "Epoch: 5 | Iteration: 7 | Classification loss: 0.11390 | Regression loss: 0.32528 | Running loss: 0.88667\n",
      "Epoch: 5 | Iteration: 8 | Classification loss: 0.25894 | Regression loss: 0.55956 | Running loss: 0.88659\n",
      "Epoch: 5 | Iteration: 9 | Classification loss: 0.19818 | Regression loss: 0.63759 | Running loss: 0.88659\n",
      "Epoch: 5 | Iteration: 10 | Classification loss: 0.21330 | Regression loss: 0.49268 | Running loss: 0.88584\n",
      "Epoch: 5 | Iteration: 11 | Classification loss: 0.32152 | Regression loss: 0.49933 | Running loss: 0.88587\n",
      "Epoch: 5 | Iteration: 12 | Classification loss: 0.20582 | Regression loss: 0.56511 | Running loss: 0.88608\n",
      "Epoch: 5 | Iteration: 13 | Classification loss: 0.31842 | Regression loss: 0.66153 | Running loss: 0.88618\n",
      "Epoch: 5 | Iteration: 14 | Classification loss: 0.10279 | Regression loss: 0.33302 | Running loss: 0.88533\n",
      "Epoch: 5 | Iteration: 15 | Classification loss: 0.35138 | Regression loss: 0.73936 | Running loss: 0.88546\n",
      "Epoch: 5 | Iteration: 16 | Classification loss: 0.27454 | Regression loss: 0.64237 | Running loss: 0.88502\n",
      "Epoch: 5 | Iteration: 17 | Classification loss: 0.37552 | Regression loss: 0.68567 | Running loss: 0.88491\n",
      "Epoch: 5 | Iteration: 18 | Classification loss: 0.32158 | Regression loss: 0.59225 | Running loss: 0.88475\n",
      "Epoch: 5 | Iteration: 19 | Classification loss: 0.17441 | Regression loss: 0.61970 | Running loss: 0.88472\n",
      "Epoch: 5 | Iteration: 20 | Classification loss: 0.23425 | Regression loss: 0.61564 | Running loss: 0.88455\n",
      "Epoch: 5 | Iteration: 21 | Classification loss: 0.27992 | Regression loss: 0.44442 | Running loss: 0.88438\n",
      "Epoch: 5 | Iteration: 22 | Classification loss: 0.28561 | Regression loss: 0.57217 | Running loss: 0.88419\n",
      "Epoch: 5 | Iteration: 23 | Classification loss: 0.19014 | Regression loss: 0.46000 | Running loss: 0.88333\n",
      "Epoch: 5 | Iteration: 24 | Classification loss: 0.20195 | Regression loss: 0.56173 | Running loss: 0.88292\n",
      "Epoch: 5 | Iteration: 25 | Classification loss: 0.36313 | Regression loss: 0.77019 | Running loss: 0.88346\n",
      "Epoch: 5 | Iteration: 26 | Classification loss: 0.28852 | Regression loss: 0.61498 | Running loss: 0.88335\n",
      "Epoch: 5 | Iteration: 27 | Classification loss: 0.23768 | Regression loss: 0.57435 | Running loss: 0.88325\n",
      "Epoch: 5 | Iteration: 28 | Classification loss: 0.22363 | Regression loss: 0.38367 | Running loss: 0.88288\n",
      "Epoch: 5 | Iteration: 29 | Classification loss: 0.21427 | Regression loss: 0.63393 | Running loss: 0.88262\n",
      "Epoch: 5 | Iteration: 30 | Classification loss: 0.52109 | Regression loss: 0.73692 | Running loss: 0.88375\n",
      "Epoch: 5 | Iteration: 31 | Classification loss: 0.14810 | Regression loss: 0.52874 | Running loss: 0.88339\n",
      "Epoch: 5 | Iteration: 32 | Classification loss: 0.11786 | Regression loss: 0.32086 | Running loss: 0.88225\n",
      "Epoch: 5 | Iteration: 33 | Classification loss: 0.26090 | Regression loss: 0.62329 | Running loss: 0.88221\n",
      "Epoch: 5 | Iteration: 34 | Classification loss: 0.21257 | Regression loss: 0.51797 | Running loss: 0.88175\n",
      "Epoch: 5 | Iteration: 35 | Classification loss: 0.27122 | Regression loss: 0.58067 | Running loss: 0.88180\n",
      "Epoch: 5 | Iteration: 36 | Classification loss: 0.23001 | Regression loss: 0.48978 | Running loss: 0.88141\n",
      "Epoch: 5 | Iteration: 37 | Classification loss: 0.18069 | Regression loss: 0.49565 | Running loss: 0.88124\n",
      "Epoch: 5 | Iteration: 38 | Classification loss: 0.22298 | Regression loss: 0.60013 | Running loss: 0.88133\n",
      "Epoch: 5 | Iteration: 39 | Classification loss: 0.27421 | Regression loss: 0.64553 | Running loss: 0.88179\n",
      "Epoch: 5 | Iteration: 40 | Classification loss: 0.33335 | Regression loss: 0.67126 | Running loss: 0.88202\n",
      "Epoch: 5 | Iteration: 41 | Classification loss: 0.24222 | Regression loss: 0.56893 | Running loss: 0.88232\n",
      "Epoch: 5 | Iteration: 42 | Classification loss: 0.22484 | Regression loss: 0.58268 | Running loss: 0.88187\n",
      "Epoch: 5 | Iteration: 43 | Classification loss: 0.27116 | Regression loss: 0.68316 | Running loss: 0.88172\n",
      "Epoch: 5 | Iteration: 44 | Classification loss: 0.16597 | Regression loss: 0.52191 | Running loss: 0.88097\n",
      "Epoch: 5 | Iteration: 45 | Classification loss: 0.24678 | Regression loss: 0.65349 | Running loss: 0.88141\n",
      "Epoch: 5 | Iteration: 46 | Classification loss: 0.17898 | Regression loss: 0.50137 | Running loss: 0.88085\n",
      "Epoch: 5 | Iteration: 47 | Classification loss: 0.19861 | Regression loss: 0.48029 | Running loss: 0.87988\n",
      "Epoch: 5 | Iteration: 48 | Classification loss: 0.19976 | Regression loss: 0.51207 | Running loss: 0.87943\n",
      "Epoch: 5 | Iteration: 49 | Classification loss: 0.15000 | Regression loss: 0.46282 | Running loss: 0.87885\n",
      "Epoch: 5 | Iteration: 50 | Classification loss: 0.15933 | Regression loss: 0.42391 | Running loss: 0.87858\n",
      "Epoch: 5 | Iteration: 51 | Classification loss: 0.25421 | Regression loss: 0.52395 | Running loss: 0.87853\n",
      "Epoch: 5 | Iteration: 52 | Classification loss: 0.34211 | Regression loss: 0.63304 | Running loss: 0.87891\n",
      "Epoch: 5 | Iteration: 53 | Classification loss: 0.32494 | Regression loss: 0.52326 | Running loss: 0.87947\n",
      "Epoch: 5 | Iteration: 54 | Classification loss: 0.31179 | Regression loss: 0.66597 | Running loss: 0.87962\n",
      "Epoch: 5 | Iteration: 55 | Classification loss: 0.26509 | Regression loss: 0.57366 | Running loss: 0.87959\n",
      "Epoch: 5 | Iteration: 56 | Classification loss: 0.21800 | Regression loss: 0.57076 | Running loss: 0.87970\n",
      "Epoch: 5 | Iteration: 57 | Classification loss: 0.31280 | Regression loss: 0.67548 | Running loss: 0.87994\n",
      "Epoch: 5 | Iteration: 58 | Classification loss: 0.33977 | Regression loss: 0.66176 | Running loss: 0.88022\n",
      "Epoch: 5 | Iteration: 59 | Classification loss: 0.28748 | Regression loss: 0.70987 | Running loss: 0.88057\n",
      "Epoch: 5 | Iteration: 60 | Classification loss: 0.12898 | Regression loss: 0.39990 | Running loss: 0.88015\n",
      "Epoch: 5 | Iteration: 61 | Classification loss: 0.20655 | Regression loss: 0.57643 | Running loss: 0.88036\n",
      "Epoch: 5 | Iteration: 62 | Classification loss: 0.36673 | Regression loss: 0.59139 | Running loss: 0.88014\n",
      "Epoch: 5 | Iteration: 63 | Classification loss: 0.24588 | Regression loss: 0.56391 | Running loss: 0.87946\n",
      "Epoch: 5 | Iteration: 64 | Classification loss: 0.24500 | Regression loss: 0.60161 | Running loss: 0.87902\n",
      "Epoch: 5 | Iteration: 65 | Classification loss: 0.28928 | Regression loss: 0.60576 | Running loss: 0.87885\n",
      "Epoch: 5 | Iteration: 66 | Classification loss: 0.35030 | Regression loss: 0.69225 | Running loss: 0.87948\n",
      "Epoch: 5 | Iteration: 67 | Classification loss: 0.34113 | Regression loss: 0.72896 | Running loss: 0.87971\n",
      "Epoch: 5 | Iteration: 68 | Classification loss: 0.25890 | Regression loss: 0.57908 | Running loss: 0.87982\n",
      "Epoch: 5 | Iteration: 69 | Classification loss: 0.27158 | Regression loss: 0.63059 | Running loss: 0.87980\n",
      "Epoch: 5 | Iteration: 70 | Classification loss: 0.14676 | Regression loss: 0.39328 | Running loss: 0.87970\n",
      "Epoch: 5 | Iteration: 71 | Classification loss: 0.23688 | Regression loss: 0.62605 | Running loss: 0.87975\n",
      "Epoch: 5 | Iteration: 72 | Classification loss: 0.31111 | Regression loss: 0.62072 | Running loss: 0.87920\n",
      "Epoch: 5 | Iteration: 73 | Classification loss: 0.22013 | Regression loss: 0.52930 | Running loss: 0.87965\n",
      "Epoch: 5 | Iteration: 74 | Classification loss: 0.28172 | Regression loss: 0.70683 | Running loss: 0.88022\n",
      "Epoch: 5 | Iteration: 75 | Classification loss: 0.26973 | Regression loss: 0.58319 | Running loss: 0.88022\n",
      "Epoch: 5 | Iteration: 76 | Classification loss: 0.24998 | Regression loss: 0.55510 | Running loss: 0.87991\n",
      "Epoch: 5 | Iteration: 77 | Classification loss: 0.28622 | Regression loss: 0.66987 | Running loss: 0.87966\n",
      "Epoch: 5 | Iteration: 78 | Classification loss: 0.30081 | Regression loss: 0.55574 | Running loss: 0.87983\n",
      "Epoch: 5 | Iteration: 79 | Classification loss: 0.35775 | Regression loss: 0.68023 | Running loss: 0.88026\n",
      "Epoch: 5 | Iteration: 80 | Classification loss: 0.24939 | Regression loss: 0.57651 | Running loss: 0.87934\n",
      "Epoch: 5 | Iteration: 81 | Classification loss: 0.21163 | Regression loss: 0.58940 | Running loss: 0.87945\n",
      "Epoch: 5 | Iteration: 82 | Classification loss: 0.23910 | Regression loss: 0.59862 | Running loss: 0.87917\n",
      "Epoch: 5 | Iteration: 83 | Classification loss: 0.29895 | Regression loss: 0.51834 | Running loss: 0.87910\n",
      "Epoch: 5 | Iteration: 84 | Classification loss: 0.34191 | Regression loss: 0.60057 | Running loss: 0.87876\n",
      "Epoch: 5 | Iteration: 85 | Classification loss: 0.30137 | Regression loss: 0.66513 | Running loss: 0.87904\n",
      "Epoch: 5 | Iteration: 86 | Classification loss: 0.30592 | Regression loss: 0.57524 | Running loss: 0.87926\n",
      "Epoch: 5 | Iteration: 87 | Classification loss: 0.26525 | Regression loss: 0.61688 | Running loss: 0.87899\n",
      "Epoch: 5 | Iteration: 88 | Classification loss: 0.26423 | Regression loss: 0.37005 | Running loss: 0.87865\n",
      "Epoch: 5 | Iteration: 89 | Classification loss: 0.37281 | Regression loss: 0.62840 | Running loss: 0.87734\n",
      "Epoch: 5 | Iteration: 90 | Classification loss: 0.28139 | Regression loss: 0.61764 | Running loss: 0.87754\n",
      "Epoch: 5 | Iteration: 91 | Classification loss: 0.17568 | Regression loss: 0.50076 | Running loss: 0.87698\n",
      "Epoch: 5 | Iteration: 92 | Classification loss: 0.27587 | Regression loss: 0.54743 | Running loss: 0.87706\n",
      "Epoch: 5 | Iteration: 93 | Classification loss: 0.19568 | Regression loss: 0.50204 | Running loss: 0.87629\n",
      "Epoch: 5 | Iteration: 94 | Classification loss: 0.35148 | Regression loss: 0.66021 | Running loss: 0.87654\n",
      "Epoch: 5 | Iteration: 95 | Classification loss: 0.28886 | Regression loss: 0.67273 | Running loss: 0.87625\n",
      "Epoch: 5 | Iteration: 96 | Classification loss: 0.21831 | Regression loss: 0.58869 | Running loss: 0.87618\n",
      "Epoch: 5 | Iteration: 97 | Classification loss: 0.18978 | Regression loss: 0.54927 | Running loss: 0.87633\n",
      "Epoch: 5 | Iteration: 98 | Classification loss: 0.24127 | Regression loss: 0.57904 | Running loss: 0.87569\n",
      "Epoch: 5 | Iteration: 99 | Classification loss: 0.25972 | Regression loss: 0.47864 | Running loss: 0.87527\n",
      "Epoch: 5 | Iteration: 100 | Classification loss: 0.25484 | Regression loss: 0.45476 | Running loss: 0.87495\n",
      "Epoch: 5 | Iteration: 101 | Classification loss: 0.27291 | Regression loss: 0.68667 | Running loss: 0.87566\n",
      "Epoch: 5 | Iteration: 102 | Classification loss: 0.20639 | Regression loss: 0.43773 | Running loss: 0.87492\n",
      "Epoch: 5 | Iteration: 103 | Classification loss: 0.30871 | Regression loss: 0.64565 | Running loss: 0.87519\n",
      "Epoch: 5 | Iteration: 104 | Classification loss: 0.29325 | Regression loss: 0.56186 | Running loss: 0.87525\n",
      "Epoch: 5 | Iteration: 105 | Classification loss: 0.20489 | Regression loss: 0.59911 | Running loss: 0.87563\n",
      "Epoch: 5 | Iteration: 106 | Classification loss: 0.24613 | Regression loss: 0.49845 | Running loss: 0.87493\n",
      "Epoch: 5 | Iteration: 107 | Classification loss: 0.22204 | Regression loss: 0.52314 | Running loss: 0.87507\n",
      "Epoch: 5 | Iteration: 108 | Classification loss: 0.20049 | Regression loss: 0.47346 | Running loss: 0.87444\n",
      "Epoch: 5 | Iteration: 109 | Classification loss: 0.26876 | Regression loss: 0.72141 | Running loss: 0.87491\n",
      "Epoch: 5 | Iteration: 110 | Classification loss: 0.26911 | Regression loss: 0.53685 | Running loss: 0.87433\n",
      "Epoch: 5 | Iteration: 111 | Classification loss: 0.31324 | Regression loss: 0.66025 | Running loss: 0.87474\n",
      "Epoch: 5 | Iteration: 112 | Classification loss: 0.50253 | Regression loss: 0.65504 | Running loss: 0.87531\n",
      "Epoch: 5 | Iteration: 113 | Classification loss: 0.29510 | Regression loss: 0.56888 | Running loss: 0.87538\n",
      "Epoch: 5 | Iteration: 114 | Classification loss: 0.25569 | Regression loss: 0.55876 | Running loss: 0.87522\n",
      "Epoch: 5 | Iteration: 115 | Classification loss: 0.22593 | Regression loss: 0.55491 | Running loss: 0.87515\n",
      "Epoch: 5 | Iteration: 116 | Classification loss: 0.20321 | Regression loss: 0.43106 | Running loss: 0.87491\n",
      "Epoch: 5 | Iteration: 117 | Classification loss: 0.24206 | Regression loss: 0.50567 | Running loss: 0.87519\n",
      "Epoch: 5 | Iteration: 118 | Classification loss: 0.29665 | Regression loss: 0.75795 | Running loss: 0.87534\n",
      "Epoch: 5 | Iteration: 119 | Classification loss: 0.27212 | Regression loss: 0.59903 | Running loss: 0.87515\n",
      "Epoch: 5 | Iteration: 120 | Classification loss: 0.29333 | Regression loss: 0.70656 | Running loss: 0.87523\n",
      "Epoch: 5 | Iteration: 121 | Classification loss: 0.32442 | Regression loss: 0.57253 | Running loss: 0.87544\n",
      "Epoch: 5 | Iteration: 122 | Classification loss: 0.15321 | Regression loss: 0.49697 | Running loss: 0.87483\n",
      "Epoch: 5 | Iteration: 123 | Classification loss: 0.25415 | Regression loss: 0.58511 | Running loss: 0.87448\n",
      "Epoch: 5 | Iteration: 124 | Classification loss: 0.23873 | Regression loss: 0.47097 | Running loss: 0.87442\n",
      "Epoch: 5 | Iteration: 125 | Classification loss: 0.27312 | Regression loss: 0.58971 | Running loss: 0.87429\n",
      "Epoch: 5 | Iteration: 126 | Classification loss: 0.41172 | Regression loss: 0.68567 | Running loss: 0.87504\n",
      "Epoch: 5 | Iteration: 127 | Classification loss: 0.34894 | Regression loss: 0.77876 | Running loss: 0.87558\n",
      "Epoch: 5 | Iteration: 128 | Classification loss: 0.41523 | Regression loss: 0.78015 | Running loss: 0.87625\n",
      "Epoch: 5 | Iteration: 129 | Classification loss: 0.17120 | Regression loss: 0.50346 | Running loss: 0.87580\n",
      "Epoch: 5 | Iteration: 130 | Classification loss: 0.18387 | Regression loss: 0.47613 | Running loss: 0.87480\n",
      "Epoch: 5 | Iteration: 131 | Classification loss: 0.21344 | Regression loss: 0.50196 | Running loss: 0.87461\n",
      "Epoch: 5 | Iteration: 132 | Classification loss: 0.22772 | Regression loss: 0.59000 | Running loss: 0.87411\n",
      "Epoch: 5 | Iteration: 133 | Classification loss: 0.24867 | Regression loss: 0.60098 | Running loss: 0.87409\n",
      "Epoch: 5 | Iteration: 134 | Classification loss: 0.35104 | Regression loss: 0.66103 | Running loss: 0.87479\n",
      "Epoch: 5 | Iteration: 135 | Classification loss: 0.22340 | Regression loss: 0.56126 | Running loss: 0.87458\n",
      "Epoch: 5 | Iteration: 136 | Classification loss: 0.30682 | Regression loss: 0.67002 | Running loss: 0.87493\n",
      "Epoch: 5 | Iteration: 137 | Classification loss: 0.29558 | Regression loss: 0.57670 | Running loss: 0.87480\n",
      "Epoch: 5 | Iteration: 138 | Classification loss: 0.20349 | Regression loss: 0.38756 | Running loss: 0.87394\n",
      "Epoch: 5 | Iteration: 139 | Classification loss: 0.22527 | Regression loss: 0.56616 | Running loss: 0.87377\n",
      "Epoch: 5 | Iteration: 140 | Classification loss: 0.19987 | Regression loss: 0.50198 | Running loss: 0.87326\n",
      "Epoch: 5 | Iteration: 141 | Classification loss: 0.28011 | Regression loss: 0.56985 | Running loss: 0.87283\n",
      "Epoch: 5 | Iteration: 142 | Classification loss: 0.20362 | Regression loss: 0.50161 | Running loss: 0.87263\n",
      "Epoch: 5 | Iteration: 143 | Classification loss: 0.23695 | Regression loss: 0.59357 | Running loss: 0.87276\n",
      "Epoch: 5 | Iteration: 144 | Classification loss: 0.28783 | Regression loss: 0.63100 | Running loss: 0.87257\n",
      "Epoch: 5 | Iteration: 145 | Classification loss: 0.20989 | Regression loss: 0.49815 | Running loss: 0.87225\n",
      "Epoch: 5 | Iteration: 146 | Classification loss: 0.21540 | Regression loss: 0.43954 | Running loss: 0.87188\n",
      "Epoch: 5 | Iteration: 147 | Classification loss: 0.26825 | Regression loss: 0.70025 | Running loss: 0.87226\n",
      "Epoch: 5 | Iteration: 148 | Classification loss: 0.23053 | Regression loss: 0.62303 | Running loss: 0.87184\n",
      "Epoch: 5 | Iteration: 149 | Classification loss: 0.17276 | Regression loss: 0.45925 | Running loss: 0.87134\n",
      "Epoch: 5 | Iteration: 150 | Classification loss: 0.17623 | Regression loss: 0.48692 | Running loss: 0.87101\n",
      "Epoch: 5 | Iteration: 151 | Classification loss: 0.30769 | Regression loss: 0.64321 | Running loss: 0.87102\n",
      "Epoch: 5 | Iteration: 152 | Classification loss: 0.21226 | Regression loss: 0.49686 | Running loss: 0.87044\n",
      "Epoch: 5 | Iteration: 153 | Classification loss: 0.26617 | Regression loss: 0.59392 | Running loss: 0.87073\n",
      "Epoch: 5 | Iteration: 154 | Classification loss: 0.29889 | Regression loss: 0.54769 | Running loss: 0.87038\n",
      "Epoch: 5 | Iteration: 155 | Classification loss: 0.16635 | Regression loss: 0.46082 | Running loss: 0.87022\n",
      "Epoch: 5 | Iteration: 156 | Classification loss: 0.35965 | Regression loss: 0.57288 | Running loss: 0.87042\n",
      "Epoch: 5 | Iteration: 157 | Classification loss: 0.26349 | Regression loss: 0.50361 | Running loss: 0.87056\n",
      "Epoch: 5 | Iteration: 158 | Classification loss: 0.19270 | Regression loss: 0.52989 | Running loss: 0.87038\n",
      "Epoch: 5 | Iteration: 159 | Classification loss: 0.24158 | Regression loss: 0.53173 | Running loss: 0.86996\n",
      "Epoch: 5 | Iteration: 160 | Classification loss: 0.26183 | Regression loss: 0.51643 | Running loss: 0.86954\n",
      "Epoch: 5 | Iteration: 161 | Classification loss: 0.25312 | Regression loss: 0.62067 | Running loss: 0.86951\n",
      "Epoch: 5 | Iteration: 162 | Classification loss: 0.23525 | Regression loss: 0.47847 | Running loss: 0.86916\n",
      "Epoch: 5 | Iteration: 163 | Classification loss: 0.33134 | Regression loss: 0.58962 | Running loss: 0.86946\n",
      "Epoch: 5 | Iteration: 164 | Classification loss: 0.25851 | Regression loss: 0.59267 | Running loss: 0.86906\n",
      "Epoch: 5 | Iteration: 165 | Classification loss: 0.29986 | Regression loss: 0.52956 | Running loss: 0.86857\n",
      "Epoch: 5 | Iteration: 166 | Classification loss: 0.25866 | Regression loss: 0.54898 | Running loss: 0.86831\n",
      "Epoch: 5 | Iteration: 167 | Classification loss: 0.12723 | Regression loss: 0.35351 | Running loss: 0.86743\n",
      "Epoch: 5 | Iteration: 168 | Classification loss: 0.22313 | Regression loss: 0.47103 | Running loss: 0.86684\n",
      "Epoch: 5 | Iteration: 169 | Classification loss: 0.31620 | Regression loss: 0.61259 | Running loss: 0.86729\n",
      "Epoch: 5 | Iteration: 170 | Classification loss: 0.16993 | Regression loss: 0.50282 | Running loss: 0.86702\n",
      "Epoch: 5 | Iteration: 171 | Classification loss: 0.25512 | Regression loss: 0.62224 | Running loss: 0.86704\n",
      "Epoch: 5 | Iteration: 172 | Classification loss: 0.26769 | Regression loss: 0.63140 | Running loss: 0.86732\n",
      "Epoch: 5 | Iteration: 173 | Classification loss: 0.22494 | Regression loss: 0.56788 | Running loss: 0.86691\n",
      "Epoch: 5 | Iteration: 174 | Classification loss: 0.29294 | Regression loss: 0.62439 | Running loss: 0.86683\n",
      "Epoch: 5 | Iteration: 175 | Classification loss: 0.27078 | Regression loss: 0.48777 | Running loss: 0.86593\n",
      "Epoch: 5 | Iteration: 176 | Classification loss: 0.28647 | Regression loss: 0.56368 | Running loss: 0.86621\n",
      "Epoch: 5 | Iteration: 177 | Classification loss: 0.25359 | Regression loss: 0.55684 | Running loss: 0.86598\n",
      "Epoch: 5 | Iteration: 178 | Classification loss: 0.26554 | Regression loss: 0.43463 | Running loss: 0.86577\n",
      "Epoch: 5 | Iteration: 179 | Classification loss: 0.24024 | Regression loss: 0.54139 | Running loss: 0.86532\n",
      "Epoch: 5 | Iteration: 180 | Classification loss: 0.33886 | Regression loss: 0.52006 | Running loss: 0.86536\n",
      "Epoch: 5 | Iteration: 181 | Classification loss: 0.19899 | Regression loss: 0.46963 | Running loss: 0.86440\n",
      "Epoch: 5 | Iteration: 182 | Classification loss: 0.19392 | Regression loss: 0.49891 | Running loss: 0.86439\n",
      "Epoch: 5 | Iteration: 183 | Classification loss: 0.23094 | Regression loss: 0.59080 | Running loss: 0.86417\n",
      "Epoch: 5 | Iteration: 184 | Classification loss: 0.63287 | Regression loss: 0.84760 | Running loss: 0.86510\n",
      "Epoch: 5 | Iteration: 185 | Classification loss: 0.28845 | Regression loss: 0.62322 | Running loss: 0.86513\n",
      "Epoch: 5 | Iteration: 186 | Classification loss: 0.33852 | Regression loss: 0.54233 | Running loss: 0.86536\n",
      "Epoch: 5 | Iteration: 187 | Classification loss: 0.24018 | Regression loss: 0.51888 | Running loss: 0.86502\n",
      "Epoch: 5 | Iteration: 188 | Classification loss: 0.30167 | Regression loss: 0.56903 | Running loss: 0.86534\n",
      "Epoch: 5 | Iteration: 189 | Classification loss: 0.22777 | Regression loss: 0.53556 | Running loss: 0.86494\n",
      "Epoch: 5 | Iteration: 190 | Classification loss: 0.36408 | Regression loss: 0.74930 | Running loss: 0.86589\n",
      "Epoch: 5 | Iteration: 191 | Classification loss: 0.26682 | Regression loss: 0.57011 | Running loss: 0.86584\n",
      "Epoch: 5 | Iteration: 192 | Classification loss: 0.26967 | Regression loss: 0.64814 | Running loss: 0.86573\n",
      "Epoch: 5 | Iteration: 193 | Classification loss: 0.25032 | Regression loss: 0.63645 | Running loss: 0.86528\n",
      "Epoch: 5 | Iteration: 194 | Classification loss: 0.22591 | Regression loss: 0.54060 | Running loss: 0.86486\n",
      "Epoch: 5 | Iteration: 195 | Classification loss: 0.19741 | Regression loss: 0.58978 | Running loss: 0.86487\n",
      "Epoch: 5 | Iteration: 196 | Classification loss: 0.23860 | Regression loss: 0.43110 | Running loss: 0.86475\n",
      "Epoch: 5 | Iteration: 197 | Classification loss: 0.25754 | Regression loss: 0.58878 | Running loss: 0.86399\n",
      "Epoch: 5 | Iteration: 198 | Classification loss: 0.20260 | Regression loss: 0.54462 | Running loss: 0.86387\n",
      "Epoch: 5 | Iteration: 199 | Classification loss: 0.33236 | Regression loss: 0.37228 | Running loss: 0.86384\n",
      "Epoch: 5 | Iteration: 200 | Classification loss: 0.31484 | Regression loss: 0.64118 | Running loss: 0.86443\n",
      "Epoch: 5 | Iteration: 201 | Classification loss: 0.17168 | Regression loss: 0.42637 | Running loss: 0.86421\n",
      "Epoch: 5 | Iteration: 202 | Classification loss: 0.26322 | Regression loss: 0.58749 | Running loss: 0.86408\n",
      "Epoch: 5 | Iteration: 203 | Classification loss: 0.14205 | Regression loss: 0.29434 | Running loss: 0.86300\n",
      "Epoch: 5 | Iteration: 204 | Classification loss: 0.23796 | Regression loss: 0.60035 | Running loss: 0.86308\n",
      "Epoch: 5 | Iteration: 205 | Classification loss: 0.25130 | Regression loss: 0.69639 | Running loss: 0.86303\n",
      "Epoch: 5 | Iteration: 206 | Classification loss: 0.28937 | Regression loss: 0.67320 | Running loss: 0.86288\n",
      "Epoch: 5 | Iteration: 207 | Classification loss: 0.41741 | Regression loss: 0.61035 | Running loss: 0.86337\n",
      "Epoch: 5 | Iteration: 208 | Classification loss: 0.18607 | Regression loss: 0.47311 | Running loss: 0.86340\n",
      "Epoch: 5 | Iteration: 209 | Classification loss: 0.24133 | Regression loss: 0.68482 | Running loss: 0.86438\n",
      "Epoch: 5 | Iteration: 210 | Classification loss: 0.27385 | Regression loss: 0.55495 | Running loss: 0.86432\n",
      "Epoch: 5 | Iteration: 211 | Classification loss: 0.21653 | Regression loss: 0.57296 | Running loss: 0.86451\n",
      "Epoch: 5 | Iteration: 212 | Classification loss: 0.25852 | Regression loss: 0.57605 | Running loss: 0.86406\n",
      "Epoch: 5 | Iteration: 213 | Classification loss: 0.27374 | Regression loss: 0.55903 | Running loss: 0.86424\n",
      "Epoch: 5 | Iteration: 214 | Classification loss: 0.25066 | Regression loss: 0.53347 | Running loss: 0.86448\n",
      "Epoch: 5 | Iteration: 215 | Classification loss: 0.25340 | Regression loss: 0.47399 | Running loss: 0.86385\n",
      "Epoch: 5 | Iteration: 216 | Classification loss: 0.55806 | Regression loss: 0.53068 | Running loss: 0.86379\n",
      "Epoch: 5 | Iteration: 217 | Classification loss: 0.19953 | Regression loss: 0.45661 | Running loss: 0.86358\n",
      "Epoch: 5 | Iteration: 218 | Classification loss: 0.21389 | Regression loss: 0.57746 | Running loss: 0.86354\n",
      "Epoch: 5 | Iteration: 219 | Classification loss: 0.35156 | Regression loss: 0.67832 | Running loss: 0.86398\n",
      "Epoch: 5 | Iteration: 220 | Classification loss: 0.26703 | Regression loss: 0.61277 | Running loss: 0.86382\n",
      "Epoch: 5 | Iteration: 221 | Classification loss: 0.28595 | Regression loss: 0.51049 | Running loss: 0.86316\n",
      "Epoch: 5 | Iteration: 222 | Classification loss: 0.24445 | Regression loss: 0.47405 | Running loss: 0.86332\n",
      "Epoch: 5 | Iteration: 223 | Classification loss: 0.30221 | Regression loss: 0.68779 | Running loss: 0.86371\n",
      "Epoch: 5 | Iteration: 224 | Classification loss: 0.27525 | Regression loss: 0.65322 | Running loss: 0.86403\n",
      "Epoch: 5 | Iteration: 225 | Classification loss: 0.21700 | Regression loss: 0.57165 | Running loss: 0.86338\n",
      "Epoch: 5 | Iteration: 226 | Classification loss: 0.25439 | Regression loss: 0.67423 | Running loss: 0.86385\n",
      "Epoch: 5 | Iteration: 227 | Classification loss: 0.34636 | Regression loss: 0.69141 | Running loss: 0.86420\n",
      "Epoch: 5 | Iteration: 228 | Classification loss: 0.31752 | Regression loss: 0.67952 | Running loss: 0.86473\n",
      "Epoch: 5 | Iteration: 229 | Classification loss: 0.31523 | Regression loss: 0.67356 | Running loss: 0.86473\n",
      "Epoch: 5 | Iteration: 230 | Classification loss: 0.33665 | Regression loss: 0.79461 | Running loss: 0.86528\n",
      "Epoch: 5 | Iteration: 231 | Classification loss: 0.30900 | Regression loss: 0.65801 | Running loss: 0.86534\n",
      "Epoch: 5 | Iteration: 232 | Classification loss: 0.26269 | Regression loss: 0.52968 | Running loss: 0.86489\n",
      "Epoch: 5 | Iteration: 233 | Classification loss: 0.41123 | Regression loss: 0.75740 | Running loss: 0.86563\n",
      "Epoch: 5 | Iteration: 234 | Classification loss: 0.24340 | Regression loss: 0.66044 | Running loss: 0.86598\n",
      "Epoch: 5 | Iteration: 235 | Classification loss: 0.38650 | Regression loss: 0.46073 | Running loss: 0.86615\n",
      "Epoch: 5 | Iteration: 236 | Classification loss: 0.32135 | Regression loss: 0.64637 | Running loss: 0.86673\n",
      "Epoch: 5 | Iteration: 237 | Classification loss: 0.24295 | Regression loss: 0.58538 | Running loss: 0.86634\n",
      "Epoch: 5 | Iteration: 238 | Classification loss: 0.32476 | Regression loss: 0.71755 | Running loss: 0.86669\n",
      "Epoch: 5 | Iteration: 239 | Classification loss: 0.35129 | Regression loss: 0.54153 | Running loss: 0.86686\n",
      "Epoch: 5 | Iteration: 240 | Classification loss: 0.26880 | Regression loss: 0.61925 | Running loss: 0.86640\n",
      "Epoch: 5 | Iteration: 241 | Classification loss: 0.26552 | Regression loss: 0.64758 | Running loss: 0.86655\n",
      "Epoch: 5 | Iteration: 242 | Classification loss: 0.33266 | Regression loss: 0.65856 | Running loss: 0.86706\n",
      "Epoch: 5 | Iteration: 243 | Classification loss: 0.28948 | Regression loss: 0.55470 | Running loss: 0.86711\n",
      "Epoch: 5 | Iteration: 244 | Classification loss: 0.26643 | Regression loss: 0.64852 | Running loss: 0.86718\n",
      "Epoch: 5 | Iteration: 245 | Classification loss: 0.23499 | Regression loss: 0.53088 | Running loss: 0.86643\n",
      "Epoch: 5 | Iteration: 246 | Classification loss: 0.26857 | Regression loss: 0.61583 | Running loss: 0.86697\n",
      "Epoch: 5 | Iteration: 247 | Classification loss: 0.25765 | Regression loss: 0.50432 | Running loss: 0.86665\n",
      "Epoch: 5 | Iteration: 248 | Classification loss: 0.23786 | Regression loss: 0.67472 | Running loss: 0.86674\n",
      "Epoch: 5 | Iteration: 249 | Classification loss: 0.18012 | Regression loss: 0.49946 | Running loss: 0.86629\n",
      "Epoch: 5 | Iteration: 250 | Classification loss: 0.34937 | Regression loss: 0.73964 | Running loss: 0.86675\n",
      "Epoch: 5 | Iteration: 251 | Classification loss: 0.22976 | Regression loss: 0.44809 | Running loss: 0.86586\n",
      "Epoch: 5 | Iteration: 252 | Classification loss: 0.51831 | Regression loss: 0.32767 | Running loss: 0.86612\n",
      "Epoch: 5 | Iteration: 253 | Classification loss: 0.40200 | Regression loss: 0.85716 | Running loss: 0.86705\n",
      "Epoch: 5 | Iteration: 254 | Classification loss: 0.30140 | Regression loss: 0.69288 | Running loss: 0.86716\n",
      "Epoch: 5 | Iteration: 255 | Classification loss: 0.31592 | Regression loss: 0.58223 | Running loss: 0.86735\n",
      "Epoch: 5 | Iteration: 256 | Classification loss: 0.33553 | Regression loss: 0.47670 | Running loss: 0.86683\n",
      "Epoch: 5 | Iteration: 257 | Classification loss: 0.28932 | Regression loss: 0.54757 | Running loss: 0.86704\n",
      "Epoch: 5 | Iteration: 258 | Classification loss: 0.30123 | Regression loss: 0.67264 | Running loss: 0.86718\n",
      "Epoch: 5 | Iteration: 259 | Classification loss: 0.29363 | Regression loss: 0.61454 | Running loss: 0.86694\n",
      "Epoch: 5 | Iteration: 260 | Classification loss: 0.26024 | Regression loss: 0.60990 | Running loss: 0.86680\n",
      "Epoch: 5 | Iteration: 261 | Classification loss: 0.26588 | Regression loss: 0.62450 | Running loss: 0.86652\n",
      "Epoch: 5 | Iteration: 262 | Classification loss: 0.24617 | Regression loss: 0.53221 | Running loss: 0.86647\n",
      "Epoch: 5 | Iteration: 263 | Classification loss: 0.30129 | Regression loss: 0.61550 | Running loss: 0.86627\n",
      "Epoch: 5 | Iteration: 264 | Classification loss: 0.31880 | Regression loss: 0.71806 | Running loss: 0.86676\n",
      "Epoch: 5 | Iteration: 265 | Classification loss: 0.21882 | Regression loss: 0.58530 | Running loss: 0.86687\n",
      "Epoch: 5 | Iteration: 266 | Classification loss: 0.25851 | Regression loss: 0.53979 | Running loss: 0.86715\n",
      "Epoch: 5 | Iteration: 267 | Classification loss: 0.23875 | Regression loss: 0.49784 | Running loss: 0.86710\n",
      "Epoch: 5 | Iteration: 268 | Classification loss: 0.34993 | Regression loss: 0.74931 | Running loss: 0.86788\n",
      "Epoch: 5 | Iteration: 269 | Classification loss: 0.29940 | Regression loss: 0.70078 | Running loss: 0.86827\n",
      "Epoch: 5 | Iteration: 270 | Classification loss: 0.27871 | Regression loss: 0.58419 | Running loss: 0.86836\n",
      "Epoch: 5 | Iteration: 271 | Classification loss: 0.35709 | Regression loss: 0.70738 | Running loss: 0.86879\n",
      "Epoch: 5 | Iteration: 272 | Classification loss: 0.20788 | Regression loss: 0.43625 | Running loss: 0.86877\n",
      "Epoch: 5 | Iteration: 273 | Classification loss: 0.22309 | Regression loss: 0.53948 | Running loss: 0.86881\n",
      "Epoch: 5 | Iteration: 274 | Classification loss: 0.24298 | Regression loss: 0.40322 | Running loss: 0.86809\n",
      "Epoch: 5 | Iteration: 275 | Classification loss: 0.24657 | Regression loss: 0.57282 | Running loss: 0.86844\n",
      "Epoch: 5 | Iteration: 276 | Classification loss: 0.24398 | Regression loss: 0.69883 | Running loss: 0.86864\n",
      "Epoch: 5 | Iteration: 277 | Classification loss: 0.25550 | Regression loss: 0.56044 | Running loss: 0.86832\n",
      "Epoch: 5 | Iteration: 278 | Classification loss: 0.22471 | Regression loss: 0.41231 | Running loss: 0.86774\n",
      "Epoch: 5 | Iteration: 279 | Classification loss: 0.26398 | Regression loss: 0.56832 | Running loss: 0.86786\n",
      "Epoch: 5 | Iteration: 280 | Classification loss: 0.22973 | Regression loss: 0.50215 | Running loss: 0.86732\n",
      "Epoch: 5 | Iteration: 281 | Classification loss: 0.32802 | Regression loss: 0.52689 | Running loss: 0.86723\n",
      "Epoch: 5 | Iteration: 282 | Classification loss: 0.42883 | Regression loss: 0.64114 | Running loss: 0.86761\n",
      "Epoch: 5 | Iteration: 283 | Classification loss: 0.26348 | Regression loss: 0.59023 | Running loss: 0.86770\n",
      "Epoch: 5 | Iteration: 284 | Classification loss: 0.24990 | Regression loss: 0.51353 | Running loss: 0.86789\n",
      "Epoch: 5 | Iteration: 285 | Classification loss: 0.31426 | Regression loss: 0.65056 | Running loss: 0.86797\n",
      "Epoch: 5 | Iteration: 286 | Classification loss: 0.36875 | Regression loss: 0.65414 | Running loss: 0.86840\n",
      "Epoch: 5 | Iteration: 287 | Classification loss: 0.12033 | Regression loss: 0.40004 | Running loss: 0.86760\n",
      "Epoch: 5 | Iteration: 288 | Classification loss: 0.27311 | Regression loss: 0.60975 | Running loss: 0.86786\n",
      "Epoch: 5 | Iteration: 289 | Classification loss: 0.14009 | Regression loss: 0.41965 | Running loss: 0.86674\n",
      "Epoch: 5 | Iteration: 290 | Classification loss: 0.25013 | Regression loss: 0.56741 | Running loss: 0.86648\n",
      "Epoch: 5 | Iteration: 291 | Classification loss: 0.30207 | Regression loss: 0.66945 | Running loss: 0.86634\n",
      "Epoch: 5 | Iteration: 292 | Classification loss: 0.18915 | Regression loss: 0.46385 | Running loss: 0.86586\n",
      "Epoch: 5 | Iteration: 293 | Classification loss: 0.32758 | Regression loss: 0.60202 | Running loss: 0.86540\n",
      "Epoch: 5 | Iteration: 294 | Classification loss: 0.16682 | Regression loss: 0.41463 | Running loss: 0.86539\n",
      "Epoch: 5 | Iteration: 295 | Classification loss: 0.29876 | Regression loss: 0.64178 | Running loss: 0.86570\n",
      "Epoch: 5 | Iteration: 296 | Classification loss: 0.16858 | Regression loss: 0.51022 | Running loss: 0.86490\n",
      "Epoch: 5 | Iteration: 297 | Classification loss: 0.22725 | Regression loss: 0.60470 | Running loss: 0.86504\n",
      "Epoch: 5 | Iteration: 298 | Classification loss: 0.29680 | Regression loss: 0.49076 | Running loss: 0.86515\n",
      "Epoch: 5 | Iteration: 299 | Classification loss: 0.25174 | Regression loss: 0.64946 | Running loss: 0.86548\n",
      "Epoch: 5 | Iteration: 300 | Classification loss: 0.21227 | Regression loss: 0.60556 | Running loss: 0.86459\n",
      "Epoch: 5 | Iteration: 301 | Classification loss: 0.27401 | Regression loss: 0.59506 | Running loss: 0.86478\n",
      "Epoch: 5 | Iteration: 302 | Classification loss: 0.22903 | Regression loss: 0.60093 | Running loss: 0.86474\n",
      "Epoch: 5 | Iteration: 303 | Classification loss: 0.28738 | Regression loss: 0.71619 | Running loss: 0.86501\n",
      "Epoch: 5 | Iteration: 304 | Classification loss: 0.26398 | Regression loss: 0.54639 | Running loss: 0.86446\n",
      "Epoch: 5 | Iteration: 305 | Classification loss: 0.30210 | Regression loss: 0.58875 | Running loss: 0.86440\n",
      "Epoch: 5 | Iteration: 306 | Classification loss: 0.26533 | Regression loss: 0.57017 | Running loss: 0.86370\n",
      "Epoch: 5 | Iteration: 307 | Classification loss: 0.39511 | Regression loss: 0.56746 | Running loss: 0.86403\n",
      "Epoch: 5 | Iteration: 308 | Classification loss: 0.26104 | Regression loss: 0.63491 | Running loss: 0.86408\n",
      "Epoch: 5 | Iteration: 309 | Classification loss: 0.21653 | Regression loss: 0.46855 | Running loss: 0.86392\n",
      "Epoch: 5 | Iteration: 310 | Classification loss: 0.39669 | Regression loss: 0.54985 | Running loss: 0.86407\n",
      "Epoch: 5 | Iteration: 311 | Classification loss: 0.33803 | Regression loss: 0.68626 | Running loss: 0.86450\n",
      "Epoch: 5 | Iteration: 312 | Classification loss: 0.23215 | Regression loss: 0.42424 | Running loss: 0.86411\n",
      "Epoch: 5 | Iteration: 313 | Classification loss: 0.27529 | Regression loss: 0.66218 | Running loss: 0.86460\n",
      "Epoch: 5 | Iteration: 314 | Classification loss: 0.20723 | Regression loss: 0.43447 | Running loss: 0.86485\n",
      "Epoch: 5 | Iteration: 315 | Classification loss: 0.27631 | Regression loss: 0.53472 | Running loss: 0.86378\n",
      "Epoch: 5 | Iteration: 316 | Classification loss: 0.26126 | Regression loss: 0.56522 | Running loss: 0.86327\n",
      "Epoch: 5 | Iteration: 317 | Classification loss: 0.18443 | Regression loss: 0.51571 | Running loss: 0.86272\n",
      "Epoch: 5 | Iteration: 318 | Classification loss: 0.40169 | Regression loss: 0.73987 | Running loss: 0.86332\n",
      "Epoch: 5 | Iteration: 319 | Classification loss: 0.21994 | Regression loss: 0.56503 | Running loss: 0.86324\n",
      "Epoch: 5 | Iteration: 320 | Classification loss: 0.26691 | Regression loss: 0.71560 | Running loss: 0.86393\n",
      "Epoch: 5 | Iteration: 321 | Classification loss: 0.22355 | Regression loss: 0.51426 | Running loss: 0.86373\n",
      "Epoch: 5 | Iteration: 322 | Classification loss: 0.23717 | Regression loss: 0.63728 | Running loss: 0.86331\n",
      "Epoch: 5 | Iteration: 323 | Classification loss: 0.26136 | Regression loss: 0.55703 | Running loss: 0.86253\n",
      "Epoch: 5 | Iteration: 324 | Classification loss: 0.31687 | Regression loss: 0.65670 | Running loss: 0.86272\n",
      "Epoch: 5 | Iteration: 325 | Classification loss: 0.20349 | Regression loss: 0.55033 | Running loss: 0.86253\n",
      "Epoch: 5 | Iteration: 326 | Classification loss: 0.22007 | Regression loss: 0.48991 | Running loss: 0.86230\n",
      "Epoch: 5 | Iteration: 327 | Classification loss: 0.29640 | Regression loss: 0.44019 | Running loss: 0.86195\n",
      "Epoch: 5 | Iteration: 328 | Classification loss: 0.17598 | Regression loss: 0.49443 | Running loss: 0.86115\n",
      "Epoch: 5 | Iteration: 329 | Classification loss: 0.28917 | Regression loss: 0.67420 | Running loss: 0.86168\n",
      "Epoch: 5 | Iteration: 330 | Classification loss: 0.28557 | Regression loss: 0.57215 | Running loss: 0.86228\n",
      "Epoch: 5 | Iteration: 331 | Classification loss: 0.34785 | Regression loss: 0.62950 | Running loss: 0.86247\n",
      "Epoch: 5 | Iteration: 332 | Classification loss: 0.26045 | Regression loss: 0.55722 | Running loss: 0.86199\n",
      "Epoch: 5 | Iteration: 333 | Classification loss: 0.30235 | Regression loss: 0.53877 | Running loss: 0.86213\n",
      "Epoch: 5 | Iteration: 334 | Classification loss: 0.24107 | Regression loss: 0.57567 | Running loss: 0.86185\n",
      "Epoch: 5 | Iteration: 335 | Classification loss: 0.26248 | Regression loss: 0.59332 | Running loss: 0.86153\n",
      "Epoch: 5 | Iteration: 336 | Classification loss: 0.35493 | Regression loss: 0.57196 | Running loss: 0.86162\n",
      "Epoch: 5 | Iteration: 337 | Classification loss: 0.23838 | Regression loss: 0.54512 | Running loss: 0.86128\n",
      "Epoch: 5 | Iteration: 338 | Classification loss: 0.26966 | Regression loss: 0.45542 | Running loss: 0.86098\n",
      "Epoch: 5 | Iteration: 339 | Classification loss: 0.30912 | Regression loss: 0.66645 | Running loss: 0.86084\n",
      "Epoch: 5 | Iteration: 340 | Classification loss: 0.20873 | Regression loss: 0.54267 | Running loss: 0.86022\n",
      "Epoch: 5 | Iteration: 341 | Classification loss: 0.19705 | Regression loss: 0.41234 | Running loss: 0.85912\n",
      "Epoch: 5 | Iteration: 342 | Classification loss: 0.20292 | Regression loss: 0.31620 | Running loss: 0.85822\n",
      "Epoch: 5 | Iteration: 343 | Classification loss: 0.24857 | Regression loss: 0.55374 | Running loss: 0.85830\n",
      "Epoch: 5 | Iteration: 344 | Classification loss: 0.19410 | Regression loss: 0.47905 | Running loss: 0.85815\n",
      "Epoch: 5 | Iteration: 345 | Classification loss: 0.30061 | Regression loss: 0.65949 | Running loss: 0.85838\n",
      "Epoch: 5 | Iteration: 346 | Classification loss: 0.35518 | Regression loss: 0.65540 | Running loss: 0.85888\n",
      "Epoch: 5 | Iteration: 347 | Classification loss: 0.29764 | Regression loss: 0.50777 | Running loss: 0.85875\n",
      "Epoch: 5 | Iteration: 348 | Classification loss: 0.34371 | Regression loss: 0.58339 | Running loss: 0.85848\n",
      "Epoch: 5 | Iteration: 349 | Classification loss: 0.13967 | Regression loss: 0.35585 | Running loss: 0.85773\n",
      "Epoch: 5 | Iteration: 350 | Classification loss: 0.26750 | Regression loss: 0.61043 | Running loss: 0.85719\n",
      "Epoch: 5 | Iteration: 351 | Classification loss: 0.17775 | Regression loss: 0.39999 | Running loss: 0.85586\n",
      "Epoch: 5 | Iteration: 352 | Classification loss: 0.18447 | Regression loss: 0.46438 | Running loss: 0.85521\n",
      "Epoch: 5 | Iteration: 353 | Classification loss: 0.25747 | Regression loss: 0.55848 | Running loss: 0.85475\n",
      "Epoch: 5 | Iteration: 354 | Classification loss: 0.29673 | Regression loss: 0.52196 | Running loss: 0.85493\n",
      "Epoch: 5 | Iteration: 355 | Classification loss: 0.19965 | Regression loss: 0.41564 | Running loss: 0.85445\n",
      "Epoch: 5 | Iteration: 356 | Classification loss: 0.27360 | Regression loss: 0.67199 | Running loss: 0.85441\n",
      "Epoch: 5 | Iteration: 357 | Classification loss: 0.28756 | Regression loss: 0.59820 | Running loss: 0.85457\n",
      "Epoch: 5 | Iteration: 358 | Classification loss: 0.21138 | Regression loss: 0.56082 | Running loss: 0.85444\n",
      "Epoch: 5 | Iteration: 359 | Classification loss: 0.23103 | Regression loss: 0.62228 | Running loss: 0.85408\n",
      "Epoch: 5 | Iteration: 360 | Classification loss: 0.36065 | Regression loss: 0.67452 | Running loss: 0.85423\n",
      "Epoch: 5 | Iteration: 361 | Classification loss: 0.28580 | Regression loss: 0.70055 | Running loss: 0.85368\n",
      "Epoch: 5 | Iteration: 362 | Classification loss: 0.28030 | Regression loss: 0.53594 | Running loss: 0.85319\n",
      "Epoch: 5 | Iteration: 363 | Classification loss: 0.28913 | Regression loss: 0.61289 | Running loss: 0.85304\n",
      "Epoch: 5 | Iteration: 364 | Classification loss: 0.25869 | Regression loss: 0.57444 | Running loss: 0.85233\n",
      "Epoch: 5 | Iteration: 365 | Classification loss: 0.32005 | Regression loss: 0.60961 | Running loss: 0.85256\n",
      "Epoch: 5 | Iteration: 366 | Classification loss: 0.16411 | Regression loss: 0.53324 | Running loss: 0.85240\n",
      "Epoch: 5 | Iteration: 367 | Classification loss: 0.24958 | Regression loss: 0.57698 | Running loss: 0.85209\n",
      "Epoch: 5 | Iteration: 368 | Classification loss: 0.15622 | Regression loss: 0.34359 | Running loss: 0.85100\n",
      "Epoch: 5 | Iteration: 369 | Classification loss: 0.25094 | Regression loss: 0.54170 | Running loss: 0.85085\n",
      "Epoch: 5 | Iteration: 370 | Classification loss: 0.18096 | Regression loss: 0.39884 | Running loss: 0.85036\n",
      "Epoch: 5 | Iteration: 371 | Classification loss: 0.21230 | Regression loss: 0.50620 | Running loss: 0.84977\n",
      "Epoch: 5 | Iteration: 372 | Classification loss: 0.19329 | Regression loss: 0.45564 | Running loss: 0.84881\n",
      "Epoch: 5 | Iteration: 373 | Classification loss: 0.45730 | Regression loss: 0.63094 | Running loss: 0.84893\n",
      "Epoch: 5 | Iteration: 374 | Classification loss: 0.25868 | Regression loss: 0.63664 | Running loss: 0.84904\n",
      "Epoch: 5 | Iteration: 375 | Classification loss: 0.17872 | Regression loss: 0.40896 | Running loss: 0.84834\n",
      "Epoch: 5 | Iteration: 376 | Classification loss: 0.24224 | Regression loss: 0.50451 | Running loss: 0.84820\n",
      "Epoch: 5 | Iteration: 377 | Classification loss: 0.29428 | Regression loss: 0.62601 | Running loss: 0.84827\n",
      "Epoch: 5 | Iteration: 378 | Classification loss: 0.28238 | Regression loss: 0.58369 | Running loss: 0.84806\n",
      "Epoch: 5 | Iteration: 379 | Classification loss: 0.23823 | Regression loss: 0.62768 | Running loss: 0.84768\n",
      "Epoch: 5 | Iteration: 380 | Classification loss: 0.33245 | Regression loss: 0.60052 | Running loss: 0.84771\n",
      "Epoch: 5 | Iteration: 381 | Classification loss: 0.25318 | Regression loss: 0.62728 | Running loss: 0.84798\n",
      "Epoch: 5 | Iteration: 382 | Classification loss: 0.37448 | Regression loss: 0.37433 | Running loss: 0.84756\n",
      "Epoch: 5 | Iteration: 383 | Classification loss: 0.32174 | Regression loss: 0.65328 | Running loss: 0.84787\n",
      "Epoch: 5 | Iteration: 384 | Classification loss: 0.18610 | Regression loss: 0.53579 | Running loss: 0.84732\n",
      "Epoch: 5 | Iteration: 385 | Classification loss: 0.33234 | Regression loss: 0.61260 | Running loss: 0.84726\n",
      "Epoch: 5 | Iteration: 386 | Classification loss: 0.39335 | Regression loss: 0.77261 | Running loss: 0.84746\n",
      "Epoch: 5 | Iteration: 387 | Classification loss: 0.21625 | Regression loss: 0.55847 | Running loss: 0.84735\n",
      "Epoch: 5 | Iteration: 388 | Classification loss: 0.36217 | Regression loss: 0.72882 | Running loss: 0.84754\n",
      "Epoch: 5 | Iteration: 389 | Classification loss: 0.36872 | Regression loss: 0.66358 | Running loss: 0.84820\n",
      "Epoch: 5 | Iteration: 390 | Classification loss: 0.23994 | Regression loss: 0.65765 | Running loss: 0.84837\n",
      "Epoch: 5 | Iteration: 391 | Classification loss: 0.34575 | Regression loss: 0.55575 | Running loss: 0.84838\n",
      "Epoch: 5 | Iteration: 392 | Classification loss: 0.21848 | Regression loss: 0.46158 | Running loss: 0.84846\n",
      "Epoch: 5 | Iteration: 393 | Classification loss: 0.33562 | Regression loss: 0.58800 | Running loss: 0.84831\n",
      "Epoch: 5 | Iteration: 394 | Classification loss: 0.23924 | Regression loss: 0.70921 | Running loss: 0.84797\n",
      "Epoch: 5 | Iteration: 395 | Classification loss: 0.28534 | Regression loss: 0.59039 | Running loss: 0.84797\n",
      "Epoch: 5 | Iteration: 396 | Classification loss: 0.16870 | Regression loss: 0.39703 | Running loss: 0.84783\n",
      "Epoch: 5 | Iteration: 397 | Classification loss: 0.28732 | Regression loss: 0.59304 | Running loss: 0.84783\n",
      "Epoch: 5 | Iteration: 398 | Classification loss: 0.25989 | Regression loss: 0.52955 | Running loss: 0.84785\n",
      "Epoch: 5 | Iteration: 399 | Classification loss: 0.23657 | Regression loss: 0.57413 | Running loss: 0.84810\n",
      "Epoch: 5 | Iteration: 400 | Classification loss: 0.18054 | Regression loss: 0.47649 | Running loss: 0.84755\n",
      "Epoch: 5 | Iteration: 401 | Classification loss: 0.18084 | Regression loss: 0.54435 | Running loss: 0.84725\n",
      "Epoch: 5 | Iteration: 402 | Classification loss: 0.21136 | Regression loss: 0.51686 | Running loss: 0.84704\n",
      "Epoch: 5 | Iteration: 403 | Classification loss: 0.21988 | Regression loss: 0.51020 | Running loss: 0.84696\n",
      "Epoch: 5 | Iteration: 404 | Classification loss: 0.25002 | Regression loss: 0.64812 | Running loss: 0.84700\n",
      "Epoch: 5 | Iteration: 405 | Classification loss: 0.23678 | Regression loss: 0.64437 | Running loss: 0.84706\n",
      "Epoch: 5 | Iteration: 406 | Classification loss: 0.27621 | Regression loss: 0.61837 | Running loss: 0.84701\n",
      "Epoch: 5 | Iteration: 407 | Classification loss: 0.26639 | Regression loss: 0.51591 | Running loss: 0.84672\n",
      "Epoch: 5 | Iteration: 408 | Classification loss: 0.70192 | Regression loss: 0.55072 | Running loss: 0.84791\n",
      "Epoch: 5 | Iteration: 409 | Classification loss: 0.29284 | Regression loss: 0.70223 | Running loss: 0.84807\n",
      "Epoch: 5 | Iteration: 410 | Classification loss: 0.30752 | Regression loss: 0.60584 | Running loss: 0.84784\n",
      "Epoch: 5 | Iteration: 411 | Classification loss: 0.20756 | Regression loss: 0.58322 | Running loss: 0.84801\n",
      "Epoch: 5 | Iteration: 412 | Classification loss: 0.17502 | Regression loss: 0.38691 | Running loss: 0.84734\n",
      "Epoch: 5 | Iteration: 413 | Classification loss: 0.22475 | Regression loss: 0.56205 | Running loss: 0.84709\n",
      "Epoch: 5 | Iteration: 414 | Classification loss: 0.24979 | Regression loss: 0.65065 | Running loss: 0.84698\n",
      "Epoch: 5 | Iteration: 415 | Classification loss: 0.28867 | Regression loss: 0.68396 | Running loss: 0.84728\n",
      "Epoch: 5 | Iteration: 416 | Classification loss: 0.24709 | Regression loss: 0.64678 | Running loss: 0.84759\n",
      "Epoch: 5 | Iteration: 417 | Classification loss: 0.34402 | Regression loss: 0.68490 | Running loss: 0.84778\n",
      "Epoch: 5 | Iteration: 418 | Classification loss: 0.26956 | Regression loss: 0.59881 | Running loss: 0.84814\n",
      "Epoch: 5 | Iteration: 419 | Classification loss: 0.30485 | Regression loss: 0.40614 | Running loss: 0.84826\n",
      "Epoch: 5 | Iteration: 420 | Classification loss: 0.30222 | Regression loss: 0.57484 | Running loss: 0.84848\n",
      "Epoch: 5 | Iteration: 421 | Classification loss: 0.30700 | Regression loss: 0.53508 | Running loss: 0.84850\n",
      "Epoch: 5 | Iteration: 422 | Classification loss: 0.26013 | Regression loss: 0.56846 | Running loss: 0.84791\n",
      "Epoch: 5 | Iteration: 423 | Classification loss: 0.30992 | Regression loss: 0.61744 | Running loss: 0.84818\n",
      "Epoch: 5 | Iteration: 424 | Classification loss: 0.22822 | Regression loss: 0.41905 | Running loss: 0.84769\n",
      "Epoch: 5 | Iteration: 425 | Classification loss: 0.24932 | Regression loss: 0.60267 | Running loss: 0.84747\n",
      "Epoch: 5 | Iteration: 426 | Classification loss: 0.16741 | Regression loss: 0.48120 | Running loss: 0.84647\n",
      "Epoch: 5 | Iteration: 427 | Classification loss: 0.35547 | Regression loss: 0.64630 | Running loss: 0.84678\n",
      "Epoch: 5 | Iteration: 428 | Classification loss: 0.26283 | Regression loss: 0.58825 | Running loss: 0.84668\n",
      "Epoch: 5 | Iteration: 429 | Classification loss: 0.15149 | Regression loss: 0.42219 | Running loss: 0.84583\n",
      "Epoch: 5 | Iteration: 430 | Classification loss: 0.21180 | Regression loss: 0.56948 | Running loss: 0.84534\n",
      "Epoch: 5 | Iteration: 431 | Classification loss: 0.24208 | Regression loss: 0.46002 | Running loss: 0.84538\n",
      "Epoch: 5 | Iteration: 432 | Classification loss: 0.30954 | Regression loss: 0.73500 | Running loss: 0.84573\n",
      "Epoch: 5 | Iteration: 433 | Classification loss: 0.22637 | Regression loss: 0.59448 | Running loss: 0.84546\n",
      "Epoch: 5 | Iteration: 434 | Classification loss: 0.21757 | Regression loss: 0.52836 | Running loss: 0.84515\n",
      "Epoch: 5 | Iteration: 435 | Classification loss: 0.35803 | Regression loss: 0.74519 | Running loss: 0.84555\n",
      "Epoch: 5 | Iteration: 436 | Classification loss: 0.23591 | Regression loss: 0.59328 | Running loss: 0.84503\n",
      "Epoch: 5 | Iteration: 437 | Classification loss: 0.16389 | Regression loss: 0.43541 | Running loss: 0.84466\n",
      "Epoch: 5 | Iteration: 438 | Classification loss: 0.18905 | Regression loss: 0.50925 | Running loss: 0.84425\n",
      "Epoch: 5 | Iteration: 439 | Classification loss: 0.18999 | Regression loss: 0.48172 | Running loss: 0.84378\n",
      "Epoch: 5 | Iteration: 440 | Classification loss: 0.21045 | Regression loss: 0.49731 | Running loss: 0.84404\n",
      "Epoch: 5 | Iteration: 441 | Classification loss: 0.29981 | Regression loss: 0.63104 | Running loss: 0.84435\n",
      "Epoch: 5 | Iteration: 442 | Classification loss: 0.18812 | Regression loss: 0.41123 | Running loss: 0.84385\n",
      "Epoch: 5 | Iteration: 443 | Classification loss: 0.26561 | Regression loss: 0.63808 | Running loss: 0.84414\n",
      "Epoch: 5 | Iteration: 444 | Classification loss: 0.35458 | Regression loss: 0.67101 | Running loss: 0.84418\n",
      "Epoch: 5 | Iteration: 445 | Classification loss: 0.19859 | Regression loss: 0.61988 | Running loss: 0.84373\n",
      "Epoch: 5 | Iteration: 446 | Classification loss: 0.27897 | Regression loss: 0.49984 | Running loss: 0.84355\n",
      "Epoch: 5 | Iteration: 447 | Classification loss: 0.31132 | Regression loss: 0.60358 | Running loss: 0.84298\n",
      "Epoch: 5 | Iteration: 448 | Classification loss: 0.22336 | Regression loss: 0.51187 | Running loss: 0.84187\n",
      "Epoch: 5 | Iteration: 449 | Classification loss: 0.25038 | Regression loss: 0.48338 | Running loss: 0.84157\n",
      "Epoch: 5 | Iteration: 450 | Classification loss: 0.20914 | Regression loss: 0.52200 | Running loss: 0.84112\n",
      "Epoch: 5 | Iteration: 451 | Classification loss: 0.20097 | Regression loss: 0.44702 | Running loss: 0.84071\n",
      "Epoch: 5 | Iteration: 452 | Classification loss: 0.41363 | Regression loss: 0.67483 | Running loss: 0.84137\n",
      "Epoch: 5 | Iteration: 453 | Classification loss: 0.33360 | Regression loss: 0.70687 | Running loss: 0.84126\n",
      "Epoch: 5 | Iteration: 454 | Classification loss: 0.28928 | Regression loss: 0.48713 | Running loss: 0.84080\n",
      "Epoch: 5 | Iteration: 455 | Classification loss: 0.31719 | Regression loss: 0.73704 | Running loss: 0.84089\n",
      "Epoch: 5 | Iteration: 456 | Classification loss: 0.35920 | Regression loss: 0.71210 | Running loss: 0.84137\n",
      "Epoch: 5 | Iteration: 457 | Classification loss: 0.74087 | Regression loss: 0.70397 | Running loss: 0.84235\n",
      "Epoch: 5 | Iteration: 458 | Classification loss: 0.20915 | Regression loss: 0.48929 | Running loss: 0.84180\n",
      "Epoch: 5 | Iteration: 459 | Classification loss: 0.20329 | Regression loss: 0.45871 | Running loss: 0.84132\n",
      "Epoch: 5 | Iteration: 460 | Classification loss: 0.23069 | Regression loss: 0.42189 | Running loss: 0.84087\n",
      "Epoch: 5 | Iteration: 461 | Classification loss: 0.28646 | Regression loss: 0.58804 | Running loss: 0.84064\n",
      "Epoch: 5 | Iteration: 462 | Classification loss: 0.31752 | Regression loss: 0.70527 | Running loss: 0.84080\n",
      "Epoch: 5 | Iteration: 463 | Classification loss: 0.24878 | Regression loss: 0.48471 | Running loss: 0.84099\n",
      "Epoch: 5 | Iteration: 464 | Classification loss: 0.36718 | Regression loss: 0.71671 | Running loss: 0.84124\n",
      "Epoch: 5 | Iteration: 465 | Classification loss: 0.20111 | Regression loss: 0.49738 | Running loss: 0.84091\n",
      "Epoch: 5 | Iteration: 466 | Classification loss: 0.33304 | Regression loss: 0.60690 | Running loss: 0.84132\n",
      "Epoch: 5 | Iteration: 467 | Classification loss: 0.43257 | Regression loss: 0.55583 | Running loss: 0.84154\n",
      "Epoch: 5 | Iteration: 468 | Classification loss: 0.25033 | Regression loss: 0.58445 | Running loss: 0.84185\n",
      "Epoch: 5 | Iteration: 469 | Classification loss: 0.35240 | Regression loss: 0.79611 | Running loss: 0.84239\n",
      "Epoch: 5 | Iteration: 470 | Classification loss: 0.22584 | Regression loss: 0.54932 | Running loss: 0.84259\n",
      "Epoch: 5 | Iteration: 471 | Classification loss: 0.28233 | Regression loss: 0.52137 | Running loss: 0.84267\n",
      "Epoch: 5 | Iteration: 472 | Classification loss: 0.24321 | Regression loss: 0.40932 | Running loss: 0.84214\n",
      "Epoch: 5 | Iteration: 473 | Classification loss: 0.11856 | Regression loss: 0.37220 | Running loss: 0.84118\n",
      "Epoch: 5 | Iteration: 474 | Classification loss: 0.23374 | Regression loss: 0.41599 | Running loss: 0.84056\n",
      "Epoch: 5 | Iteration: 475 | Classification loss: 0.21990 | Regression loss: 0.45595 | Running loss: 0.84050\n",
      "Epoch: 5 | Iteration: 476 | Classification loss: 0.22680 | Regression loss: 0.55934 | Running loss: 0.84034\n",
      "Epoch: 5 | Iteration: 477 | Classification loss: 0.23797 | Regression loss: 0.48018 | Running loss: 0.83953\n",
      "Epoch: 5 | Iteration: 478 | Classification loss: 0.28637 | Regression loss: 0.57840 | Running loss: 0.83947\n",
      "Epoch: 5 | Iteration: 479 | Classification loss: 0.16008 | Regression loss: 0.38658 | Running loss: 0.83848\n",
      "Epoch: 5 | Iteration: 480 | Classification loss: 0.32881 | Regression loss: 0.69187 | Running loss: 0.83873\n",
      "Epoch: 5 | Iteration: 481 | Classification loss: 0.20388 | Regression loss: 0.45139 | Running loss: 0.83798\n",
      "Epoch: 5 | Iteration: 482 | Classification loss: 0.19482 | Regression loss: 0.53215 | Running loss: 0.83802\n",
      "Epoch: 5 | Iteration: 483 | Classification loss: 0.39592 | Regression loss: 0.59862 | Running loss: 0.83668\n",
      "Epoch: 5 | Iteration: 484 | Classification loss: 0.17347 | Regression loss: 0.47702 | Running loss: 0.83651\n",
      "Epoch: 5 | Iteration: 485 | Classification loss: 0.21719 | Regression loss: 0.46591 | Running loss: 0.83651\n",
      "Epoch: 5 | Iteration: 486 | Classification loss: 0.19782 | Regression loss: 0.57942 | Running loss: 0.83624\n",
      "Epoch: 5 | Iteration: 487 | Classification loss: 0.25224 | Regression loss: 0.51912 | Running loss: 0.83652\n",
      "Epoch: 5 | Iteration: 488 | Classification loss: 0.13525 | Regression loss: 0.35473 | Running loss: 0.83625\n",
      "Epoch: 5 | Iteration: 489 | Classification loss: 0.19581 | Regression loss: 0.54341 | Running loss: 0.83622\n",
      "Epoch: 5 | Iteration: 490 | Classification loss: 0.31830 | Regression loss: 0.65814 | Running loss: 0.83678\n",
      "Epoch: 5 | Iteration: 491 | Classification loss: 0.21119 | Regression loss: 0.48289 | Running loss: 0.83657\n",
      "Epoch: 5 | Iteration: 492 | Classification loss: 0.27568 | Regression loss: 0.61121 | Running loss: 0.83664\n",
      "Epoch: 5 | Iteration: 493 | Classification loss: 0.32618 | Regression loss: 0.62407 | Running loss: 0.83653\n",
      "Epoch: 5 | Iteration: 494 | Classification loss: 0.32515 | Regression loss: 0.65378 | Running loss: 0.83702\n",
      "Epoch: 5 | Iteration: 495 | Classification loss: 0.20422 | Regression loss: 0.48534 | Running loss: 0.83666\n",
      "Epoch: 5 | Iteration: 496 | Classification loss: 0.32072 | Regression loss: 0.58896 | Running loss: 0.83629\n",
      "Epoch: 5 | Iteration: 497 | Classification loss: 0.27209 | Regression loss: 0.53767 | Running loss: 0.83608\n",
      "Epoch: 5 | Iteration: 498 | Classification loss: 0.31253 | Regression loss: 0.48378 | Running loss: 0.83642\n",
      "Epoch: 5 | Iteration: 499 | Classification loss: 0.26456 | Regression loss: 0.57422 | Running loss: 0.83639\n",
      "Epoch: 5 | Iteration: 500 | Classification loss: 0.31230 | Regression loss: 0.53691 | Running loss: 0.83618\n",
      "Epoch: 5 | Iteration: 501 | Classification loss: 0.23013 | Regression loss: 0.51646 | Running loss: 0.83537\n",
      "Epoch: 5 | Iteration: 502 | Classification loss: 0.20036 | Regression loss: 0.50849 | Running loss: 0.83499\n",
      "Epoch: 5 | Iteration: 503 | Classification loss: 0.27552 | Regression loss: 0.70647 | Running loss: 0.83533\n",
      "Epoch: 5 | Iteration: 504 | Classification loss: 0.10098 | Regression loss: 0.22426 | Running loss: 0.83399\n",
      "Epoch: 5 | Iteration: 505 | Classification loss: 0.27831 | Regression loss: 0.54803 | Running loss: 0.83368\n",
      "Epoch: 5 | Iteration: 506 | Classification loss: 0.33217 | Regression loss: 0.71694 | Running loss: 0.83404\n",
      "Epoch: 5 | Iteration: 507 | Classification loss: 0.33546 | Regression loss: 0.80783 | Running loss: 0.83545\n",
      "Epoch: 5 | Iteration: 508 | Classification loss: 0.37009 | Regression loss: 0.65143 | Running loss: 0.83586\n",
      "Epoch: 5 | Iteration: 509 | Classification loss: 0.25432 | Regression loss: 0.66442 | Running loss: 0.83602\n",
      "Epoch: 5 | Iteration: 510 | Classification loss: 0.25561 | Regression loss: 0.62944 | Running loss: 0.83638\n",
      "Epoch: 5 | Iteration: 511 | Classification loss: 0.34478 | Regression loss: 0.68964 | Running loss: 0.83681\n",
      "Epoch: 5 | Iteration: 512 | Classification loss: 0.26439 | Regression loss: 0.68263 | Running loss: 0.83716\n",
      "Epoch: 5 | Iteration: 513 | Classification loss: 0.33153 | Regression loss: 0.60566 | Running loss: 0.83707\n",
      "Epoch: 5 | Iteration: 514 | Classification loss: 0.19745 | Regression loss: 0.58631 | Running loss: 0.83777\n",
      "Epoch: 5 | Iteration: 515 | Classification loss: 0.19189 | Regression loss: 0.51576 | Running loss: 0.83700\n",
      "Epoch: 5 | Iteration: 516 | Classification loss: 0.22438 | Regression loss: 0.57252 | Running loss: 0.83676\n",
      "Epoch: 5 | Iteration: 517 | Classification loss: 0.44689 | Regression loss: 0.75155 | Running loss: 0.83704\n",
      "Epoch: 5 | Iteration: 518 | Classification loss: 0.24100 | Regression loss: 0.44696 | Running loss: 0.83659\n",
      "Epoch: 5 | Iteration: 519 | Classification loss: 0.25565 | Regression loss: 0.63356 | Running loss: 0.83678\n",
      "Epoch: 5 | Iteration: 520 | Classification loss: 0.15568 | Regression loss: 0.44511 | Running loss: 0.83628\n",
      "Epoch: 5 | Iteration: 521 | Classification loss: 0.42999 | Regression loss: 0.46946 | Running loss: 0.83663\n",
      "Epoch: 5 | Iteration: 522 | Classification loss: 0.26764 | Regression loss: 0.62749 | Running loss: 0.83670\n",
      "Epoch: 5 | Iteration: 523 | Classification loss: 0.29097 | Regression loss: 0.58780 | Running loss: 0.83716\n",
      "Epoch: 5 | Iteration: 524 | Classification loss: 0.11668 | Regression loss: 0.37169 | Running loss: 0.83661\n",
      "Epoch: 5 | Iteration: 525 | Classification loss: 0.27162 | Regression loss: 0.58138 | Running loss: 0.83605\n",
      "Epoch: 5 | Iteration: 526 | Classification loss: 0.29079 | Regression loss: 0.47866 | Running loss: 0.83578\n",
      "Epoch: 5 | Iteration: 527 | Classification loss: 0.18333 | Regression loss: 0.56681 | Running loss: 0.83566\n",
      "Epoch: 5 | Iteration: 528 | Classification loss: 0.30681 | Regression loss: 0.58265 | Running loss: 0.83622\n",
      "Epoch: 5 | Iteration: 529 | Classification loss: 0.31013 | Regression loss: 0.66207 | Running loss: 0.83647\n",
      "Epoch: 5 | Iteration: 530 | Classification loss: 0.12808 | Regression loss: 0.29744 | Running loss: 0.83481\n",
      "Epoch: 5 | Iteration: 531 | Classification loss: 0.30341 | Regression loss: 0.64386 | Running loss: 0.83535\n",
      "Epoch: 5 | Iteration: 532 | Classification loss: 0.27700 | Regression loss: 0.65006 | Running loss: 0.83632\n",
      "Epoch: 5 | Iteration: 533 | Classification loss: 0.22426 | Regression loss: 0.51526 | Running loss: 0.83603\n",
      "Epoch: 5 | Iteration: 534 | Classification loss: 0.30795 | Regression loss: 0.65751 | Running loss: 0.83650\n",
      "Epoch: 5 | Iteration: 535 | Classification loss: 0.26049 | Regression loss: 0.64013 | Running loss: 0.83660\n",
      "Epoch: 5 | Iteration: 536 | Classification loss: 0.29209 | Regression loss: 0.53917 | Running loss: 0.83682\n",
      "Epoch: 5 | Iteration: 537 | Classification loss: 0.17680 | Regression loss: 0.49841 | Running loss: 0.83682\n",
      "Epoch: 5 | Iteration: 538 | Classification loss: 0.22464 | Regression loss: 0.54786 | Running loss: 0.83672\n",
      "Epoch: 5 | Iteration: 539 | Classification loss: 0.15314 | Regression loss: 0.40560 | Running loss: 0.83600\n",
      "Epoch: 5 | Iteration: 540 | Classification loss: 0.19369 | Regression loss: 0.51306 | Running loss: 0.83540\n",
      "Epoch: 5 | Iteration: 541 | Classification loss: 0.25129 | Regression loss: 0.57076 | Running loss: 0.83542\n",
      "Epoch: 5 | Iteration: 542 | Classification loss: 0.17281 | Regression loss: 0.44493 | Running loss: 0.83504\n",
      "Epoch: 5 | Iteration: 543 | Classification loss: 0.21239 | Regression loss: 0.40443 | Running loss: 0.83437\n",
      "Epoch: 5 | Iteration: 544 | Classification loss: 0.27447 | Regression loss: 0.56975 | Running loss: 0.83468\n",
      "Epoch: 5 | Iteration: 545 | Classification loss: 0.26393 | Regression loss: 0.64180 | Running loss: 0.83469\n",
      "Epoch: 5 | Iteration: 546 | Classification loss: 0.28457 | Regression loss: 0.73965 | Running loss: 0.83538\n",
      "Epoch: 5 | Iteration: 547 | Classification loss: 0.20317 | Regression loss: 0.56641 | Running loss: 0.83556\n",
      "Epoch: 5 | Iteration: 548 | Classification loss: 0.14733 | Regression loss: 0.33723 | Running loss: 0.83511\n",
      "Epoch: 5 | Iteration: 549 | Classification loss: 0.22437 | Regression loss: 0.45510 | Running loss: 0.83524\n",
      "Epoch: 5 | Iteration: 550 | Classification loss: 0.28902 | Regression loss: 0.64580 | Running loss: 0.83594\n",
      "Epoch: 5 | Iteration: 551 | Classification loss: 0.22726 | Regression loss: 0.60208 | Running loss: 0.83605\n",
      "Epoch: 5 | Iteration: 552 | Classification loss: 0.43493 | Regression loss: 0.78508 | Running loss: 0.83654\n",
      "Epoch: 5 | Iteration: 553 | Classification loss: 0.30228 | Regression loss: 0.63048 | Running loss: 0.83671\n",
      "Epoch: 5 | Iteration: 554 | Classification loss: 0.20210 | Regression loss: 0.58831 | Running loss: 0.83633\n",
      "Epoch: 5 | Iteration: 555 | Classification loss: 0.23172 | Regression loss: 0.54892 | Running loss: 0.83621\n",
      "Epoch: 5 | Iteration: 556 | Classification loss: 0.24279 | Regression loss: 0.62774 | Running loss: 0.83638\n",
      "Epoch: 5 | Iteration: 557 | Classification loss: 0.29642 | Regression loss: 0.47157 | Running loss: 0.83594\n",
      "Epoch: 5 | Iteration: 558 | Classification loss: 0.25206 | Regression loss: 0.56243 | Running loss: 0.83556\n",
      "Epoch: 5 | Iteration: 559 | Classification loss: 0.52271 | Regression loss: 0.58005 | Running loss: 0.83577\n",
      "Epoch: 5 | Iteration: 560 | Classification loss: 0.20909 | Regression loss: 0.54561 | Running loss: 0.83623\n",
      "Epoch: 5 | Iteration: 561 | Classification loss: 0.19280 | Regression loss: 0.42966 | Running loss: 0.83591\n",
      "Epoch: 5 | Iteration: 562 | Classification loss: 0.19172 | Regression loss: 0.42777 | Running loss: 0.83523\n",
      "Epoch: 5 | Iteration: 563 | Classification loss: 0.28436 | Regression loss: 0.54018 | Running loss: 0.83526\n",
      "Epoch: 5 | Iteration: 564 | Classification loss: 0.31863 | Regression loss: 0.67229 | Running loss: 0.83555\n",
      "Epoch: 5 | Iteration: 565 | Classification loss: 0.22906 | Regression loss: 0.43555 | Running loss: 0.83509\n",
      "Epoch: 5 | Iteration: 566 | Classification loss: 0.36915 | Regression loss: 0.75385 | Running loss: 0.83525\n",
      "Epoch: 5 | Iteration: 567 | Classification loss: 0.28242 | Regression loss: 0.60182 | Running loss: 0.83487\n",
      "Epoch: 5 | Iteration: 568 | Classification loss: 0.31402 | Regression loss: 0.53778 | Running loss: 0.83490\n",
      "Epoch: 5 | Iteration: 569 | Classification loss: 0.20379 | Regression loss: 0.45627 | Running loss: 0.83442\n",
      "Epoch: 5 | Iteration: 570 | Classification loss: 0.14886 | Regression loss: 0.41526 | Running loss: 0.83447\n",
      "Epoch: 5 | Iteration: 571 | Classification loss: 0.25981 | Regression loss: 0.59371 | Running loss: 0.83445\n",
      "Epoch: 5 | Iteration: 572 | Classification loss: 0.22076 | Regression loss: 0.56394 | Running loss: 0.83415\n",
      "Epoch: 5 | Iteration: 573 | Classification loss: 0.23427 | Regression loss: 0.63037 | Running loss: 0.83438\n",
      "Epoch: 5 | Iteration: 574 | Classification loss: 0.25692 | Regression loss: 0.68493 | Running loss: 0.83429\n",
      "Epoch: 5 | Iteration: 575 | Classification loss: 0.18793 | Regression loss: 0.62183 | Running loss: 0.83420\n",
      "Epoch: 5 | Iteration: 576 | Classification loss: 0.23175 | Regression loss: 0.57475 | Running loss: 0.83421\n",
      "Epoch: 5 | Iteration: 577 | Classification loss: 0.27251 | Regression loss: 0.56635 | Running loss: 0.83397\n",
      "Epoch: 5 | Iteration: 578 | Classification loss: 0.28579 | Regression loss: 0.66039 | Running loss: 0.83415\n",
      "Epoch: 5 | Iteration: 579 | Classification loss: 0.22756 | Regression loss: 0.50956 | Running loss: 0.83355\n",
      "Epoch: 5 | Iteration: 580 | Classification loss: 0.12846 | Regression loss: 0.29909 | Running loss: 0.83275\n",
      "Epoch: 5 | Iteration: 581 | Classification loss: 0.19191 | Regression loss: 0.47955 | Running loss: 0.83249\n",
      "Epoch: 5 | Iteration: 582 | Classification loss: 0.31606 | Regression loss: 0.63233 | Running loss: 0.83271\n",
      "Epoch: 5 | Iteration: 583 | Classification loss: 0.26200 | Regression loss: 0.49369 | Running loss: 0.83259\n",
      "Epoch: 5 | Iteration: 584 | Classification loss: 0.26960 | Regression loss: 0.55569 | Running loss: 0.83236\n",
      "Epoch: 5 | Iteration: 585 | Classification loss: 0.37996 | Regression loss: 0.76690 | Running loss: 0.83272\n",
      "Epoch: 5 | Iteration: 586 | Classification loss: 0.29170 | Regression loss: 0.59492 | Running loss: 0.83273\n",
      "Epoch: 5 | Iteration: 587 | Classification loss: 0.26002 | Regression loss: 0.63482 | Running loss: 0.83275\n",
      "Epoch: 5 | Iteration: 588 | Classification loss: 0.29849 | Regression loss: 0.56500 | Running loss: 0.83321\n",
      "Epoch: 5 | Iteration: 589 | Classification loss: 0.28382 | Regression loss: 0.61382 | Running loss: 0.83301\n",
      "Epoch: 5 | Iteration: 590 | Classification loss: 0.20717 | Regression loss: 0.57574 | Running loss: 0.83277\n",
      "Epoch: 5 | Iteration: 591 | Classification loss: 0.19898 | Regression loss: 0.45717 | Running loss: 0.83273\n",
      "Epoch: 5 | Iteration: 592 | Classification loss: 0.25654 | Regression loss: 0.65994 | Running loss: 0.83292\n",
      "Epoch: 5 | Iteration: 593 | Classification loss: 0.29623 | Regression loss: 0.57870 | Running loss: 0.83327\n",
      "Epoch: 5 | Iteration: 594 | Classification loss: 0.28095 | Regression loss: 0.67626 | Running loss: 0.83316\n",
      "Epoch: 5 | Iteration: 595 | Classification loss: 0.30342 | Regression loss: 0.67209 | Running loss: 0.83319\n",
      "Epoch: 5 | Iteration: 596 | Classification loss: 0.24298 | Regression loss: 0.59204 | Running loss: 0.83325\n",
      "Epoch: 5 | Iteration: 597 | Classification loss: 0.13502 | Regression loss: 0.41078 | Running loss: 0.83286\n",
      "Epoch: 5 | Iteration: 598 | Classification loss: 0.21734 | Regression loss: 0.53837 | Running loss: 0.83273\n",
      "Epoch: 5 | Iteration: 599 | Classification loss: 0.24917 | Regression loss: 0.64800 | Running loss: 0.83305\n",
      "Epoch: 5 | Iteration: 600 | Classification loss: 0.30205 | Regression loss: 0.63997 | Running loss: 0.83352\n",
      "Epoch: 5 | Iteration: 601 | Classification loss: 0.18300 | Regression loss: 0.56353 | Running loss: 0.83309\n",
      "Epoch: 5 | Iteration: 602 | Classification loss: 0.28444 | Regression loss: 0.57262 | Running loss: 0.83352\n",
      "Epoch: 5 | Iteration: 603 | Classification loss: 0.32095 | Regression loss: 0.63457 | Running loss: 0.83352\n",
      "Epoch: 5 | Iteration: 604 | Classification loss: 0.55611 | Regression loss: 0.61459 | Running loss: 0.83415\n",
      "Epoch: 5 | Iteration: 605 | Classification loss: 0.16948 | Regression loss: 0.42968 | Running loss: 0.83374\n",
      "Epoch: 5 | Iteration: 606 | Classification loss: 0.17558 | Regression loss: 0.43611 | Running loss: 0.83347\n",
      "Epoch: 5 | Iteration: 607 | Classification loss: 0.48340 | Regression loss: 0.30176 | Running loss: 0.83355\n",
      "Epoch: 5 | Iteration: 608 | Classification loss: 0.14422 | Regression loss: 0.42489 | Running loss: 0.83334\n",
      "Epoch: 5 | Iteration: 609 | Classification loss: 0.24066 | Regression loss: 0.54602 | Running loss: 0.83294\n",
      "Epoch: 5 | Iteration: 610 | Classification loss: 0.25826 | Regression loss: 0.51337 | Running loss: 0.83287\n",
      "Epoch: 5 | Iteration: 611 | Classification loss: 0.34744 | Regression loss: 0.51379 | Running loss: 0.83264\n",
      "Epoch: 5 | Iteration: 612 | Classification loss: 0.31888 | Regression loss: 0.58276 | Running loss: 0.83213\n",
      "Epoch: 5 | Iteration: 613 | Classification loss: 0.25128 | Regression loss: 0.58264 | Running loss: 0.83207\n",
      "Epoch: 5 | Iteration: 614 | Classification loss: 0.29062 | Regression loss: 0.62551 | Running loss: 0.83227\n",
      "Epoch: 5 | Iteration: 615 | Classification loss: 0.28225 | Regression loss: 0.65085 | Running loss: 0.83258\n",
      "Epoch: 5 | Iteration: 616 | Classification loss: 0.30165 | Regression loss: 0.64418 | Running loss: 0.83320\n",
      "Epoch: 5 | Iteration: 617 | Classification loss: 0.30464 | Regression loss: 0.68605 | Running loss: 0.83369\n",
      "Epoch: 5 | Iteration: 618 | Classification loss: 0.23169 | Regression loss: 0.39673 | Running loss: 0.83284\n",
      "Epoch: 5 | Iteration: 619 | Classification loss: 0.33933 | Regression loss: 0.69498 | Running loss: 0.83316\n",
      "Epoch: 5 | Iteration: 620 | Classification loss: 0.28418 | Regression loss: 0.60494 | Running loss: 0.83294\n",
      "Epoch: 5 | Iteration: 621 | Classification loss: 0.31802 | Regression loss: 0.62956 | Running loss: 0.83304\n",
      "Epoch: 5 | Iteration: 622 | Classification loss: 0.24203 | Regression loss: 0.51165 | Running loss: 0.83325\n",
      "Epoch: 5 | Iteration: 623 | Classification loss: 0.29171 | Regression loss: 0.57395 | Running loss: 0.83330\n",
      "Epoch: 5 | Iteration: 624 | Classification loss: 0.31439 | Regression loss: 0.66423 | Running loss: 0.83384\n",
      "Epoch: 5 | Iteration: 625 | Classification loss: 0.27591 | Regression loss: 0.65365 | Running loss: 0.83397\n",
      "Epoch: 5 | Iteration: 626 | Classification loss: 0.22147 | Regression loss: 0.45407 | Running loss: 0.83313\n",
      "Epoch: 5 | Iteration: 627 | Classification loss: 0.15934 | Regression loss: 0.53198 | Running loss: 0.83226\n",
      "Epoch: 5 | Iteration: 628 | Classification loss: 0.21126 | Regression loss: 0.50865 | Running loss: 0.83131\n",
      "Epoch: 5 | Iteration: 629 | Classification loss: 0.30862 | Regression loss: 0.61574 | Running loss: 0.83181\n",
      "Epoch: 5 | Iteration: 630 | Classification loss: 0.27993 | Regression loss: 0.62126 | Running loss: 0.83229\n",
      "Epoch: 5 | Iteration: 631 | Classification loss: 0.23714 | Regression loss: 0.61800 | Running loss: 0.83257\n",
      "Epoch: 5 | Iteration: 632 | Classification loss: 0.33473 | Regression loss: 0.70026 | Running loss: 0.83300\n",
      "Epoch: 5 | Iteration: 633 | Classification loss: 0.37126 | Regression loss: 0.77469 | Running loss: 0.83359\n",
      "Epoch: 5 | Iteration: 634 | Classification loss: 0.37624 | Regression loss: 0.72218 | Running loss: 0.83377\n",
      "Epoch: 5 | Iteration: 635 | Classification loss: 0.22419 | Regression loss: 0.41794 | Running loss: 0.83348\n",
      "Epoch: 5 | Iteration: 636 | Classification loss: 0.24166 | Regression loss: 0.59168 | Running loss: 0.83319\n",
      "Epoch: 5 | Iteration: 637 | Classification loss: 0.23213 | Regression loss: 0.56697 | Running loss: 0.83305\n",
      "Epoch: 5 | Iteration: 638 | Classification loss: 0.27023 | Regression loss: 0.69144 | Running loss: 0.83379\n",
      "Epoch: 5 | Iteration: 639 | Classification loss: 0.26969 | Regression loss: 0.59306 | Running loss: 0.83393\n",
      "Epoch: 5 | Iteration: 640 | Classification loss: 0.41786 | Regression loss: 0.66531 | Running loss: 0.83469\n",
      "Epoch: 5 | Iteration: 641 | Classification loss: 0.18446 | Regression loss: 0.45185 | Running loss: 0.83427\n",
      "Epoch: 5 | Iteration: 642 | Classification loss: 0.22542 | Regression loss: 0.46163 | Running loss: 0.83423\n",
      "Epoch: 5 | Iteration: 643 | Classification loss: 0.28033 | Regression loss: 0.67839 | Running loss: 0.83449\n",
      "Epoch: 5 | Iteration: 644 | Classification loss: 0.22452 | Regression loss: 0.45004 | Running loss: 0.83400\n",
      "Epoch: 5 | Iteration: 645 | Classification loss: 0.16670 | Regression loss: 0.45648 | Running loss: 0.83383\n",
      "Epoch: 5 | Iteration: 646 | Classification loss: 0.22556 | Regression loss: 0.58939 | Running loss: 0.83415\n",
      "Epoch: 5 | Iteration: 647 | Classification loss: 0.30974 | Regression loss: 0.61047 | Running loss: 0.83405\n",
      "Epoch: 5 | Iteration: 648 | Classification loss: 0.23539 | Regression loss: 0.59246 | Running loss: 0.83400\n",
      "Epoch: 5 | Iteration: 649 | Classification loss: 0.20011 | Regression loss: 0.50869 | Running loss: 0.83415\n",
      "Epoch: 5 | Iteration: 650 | Classification loss: 0.21161 | Regression loss: 0.54563 | Running loss: 0.83434\n",
      "Epoch: 5 | Iteration: 651 | Classification loss: 0.15641 | Regression loss: 0.54822 | Running loss: 0.83385\n",
      "Epoch: 5 | Iteration: 652 | Classification loss: 0.26029 | Regression loss: 0.61959 | Running loss: 0.83419\n",
      "Epoch: 5 | Iteration: 653 | Classification loss: 0.22071 | Regression loss: 0.53784 | Running loss: 0.83399\n",
      "Epoch: 5 | Iteration: 654 | Classification loss: 0.37495 | Regression loss: 0.86035 | Running loss: 0.83477\n",
      "Epoch: 5 | Iteration: 655 | Classification loss: 0.24287 | Regression loss: 0.55298 | Running loss: 0.83510\n",
      "Epoch: 5 | Iteration: 656 | Classification loss: 0.37610 | Regression loss: 0.63734 | Running loss: 0.83527\n",
      "Epoch: 5 | Iteration: 657 | Classification loss: 0.25304 | Regression loss: 0.62935 | Running loss: 0.83550\n",
      "Epoch: 5 | Iteration: 658 | Classification loss: 0.26333 | Regression loss: 0.55235 | Running loss: 0.83568\n",
      "Epoch: 5 | Iteration: 659 | Classification loss: 0.23555 | Regression loss: 0.47698 | Running loss: 0.83556\n",
      "Epoch: 5 | Iteration: 660 | Classification loss: 0.28851 | Regression loss: 0.58984 | Running loss: 0.83576\n",
      "Epoch: 5 | Iteration: 661 | Classification loss: 0.20239 | Regression loss: 0.55187 | Running loss: 0.83552\n",
      "Epoch: 5 | Iteration: 662 | Classification loss: 0.28381 | Regression loss: 0.60716 | Running loss: 0.83588\n",
      "Epoch: 5 | Iteration: 663 | Classification loss: 0.23752 | Regression loss: 0.55304 | Running loss: 0.83562\n",
      "Epoch: 5 | Iteration: 664 | Classification loss: 0.33261 | Regression loss: 0.59499 | Running loss: 0.83577\n",
      "Epoch: 5 | Iteration: 665 | Classification loss: 0.30368 | Regression loss: 0.71558 | Running loss: 0.83615\n",
      "Epoch: 5 | Iteration: 666 | Classification loss: 0.24208 | Regression loss: 0.51182 | Running loss: 0.83604\n",
      "Epoch: 5 | Iteration: 667 | Classification loss: 0.22134 | Regression loss: 0.54097 | Running loss: 0.83660\n",
      "Epoch: 5 | Iteration: 668 | Classification loss: 0.32178 | Regression loss: 0.66320 | Running loss: 0.83719\n",
      "Epoch: 5 | Iteration: 669 | Classification loss: 0.30278 | Regression loss: 0.52184 | Running loss: 0.83698\n",
      "Epoch: 5 | Iteration: 670 | Classification loss: 0.21989 | Regression loss: 0.49028 | Running loss: 0.83705\n",
      "Epoch: 5 | Iteration: 671 | Classification loss: 0.34059 | Regression loss: 0.62024 | Running loss: 0.83722\n",
      "Epoch: 5 | Iteration: 672 | Classification loss: 0.19114 | Regression loss: 0.55610 | Running loss: 0.83692\n",
      "Epoch: 5 | Iteration: 673 | Classification loss: 0.26569 | Regression loss: 0.63903 | Running loss: 0.83714\n",
      "Epoch: 5 | Iteration: 674 | Classification loss: 0.26555 | Regression loss: 0.52980 | Running loss: 0.83690\n",
      "Epoch: 5 | Iteration: 675 | Classification loss: 0.20932 | Regression loss: 0.42705 | Running loss: 0.83665\n",
      "Epoch: 5 | Iteration: 676 | Classification loss: 0.25585 | Regression loss: 0.54255 | Running loss: 0.83655\n",
      "Epoch: 5 | Iteration: 677 | Classification loss: 0.28377 | Regression loss: 0.58894 | Running loss: 0.83667\n",
      "Epoch: 5 | Iteration: 678 | Classification loss: 0.31334 | Regression loss: 0.56170 | Running loss: 0.83702\n",
      "Epoch: 5 | Iteration: 679 | Classification loss: 0.26200 | Regression loss: 0.43381 | Running loss: 0.83685\n",
      "Epoch: 5 | Iteration: 680 | Classification loss: 0.25086 | Regression loss: 0.54788 | Running loss: 0.83673\n",
      "Epoch: 5 | Iteration: 681 | Classification loss: 0.26675 | Regression loss: 0.50404 | Running loss: 0.83693\n",
      "Epoch: 5 | Iteration: 682 | Classification loss: 0.26585 | Regression loss: 0.47021 | Running loss: 0.83702\n",
      "Epoch: 5 | Iteration: 683 | Classification loss: 0.18970 | Regression loss: 0.48073 | Running loss: 0.83672\n",
      "Epoch: 5 | Iteration: 684 | Classification loss: 0.27933 | Regression loss: 0.63084 | Running loss: 0.83558\n",
      "Epoch: 5 | Iteration: 685 | Classification loss: 0.26482 | Regression loss: 0.50987 | Running loss: 0.83530\n",
      "Epoch: 5 | Iteration: 686 | Classification loss: 0.23864 | Regression loss: 0.53656 | Running loss: 0.83509\n",
      "Epoch: 5 | Iteration: 687 | Classification loss: 0.33867 | Regression loss: 0.67566 | Running loss: 0.83560\n",
      "Epoch: 5 | Iteration: 688 | Classification loss: 0.17900 | Regression loss: 0.49592 | Running loss: 0.83521\n",
      "Epoch: 5 | Iteration: 689 | Classification loss: 0.29536 | Regression loss: 0.65113 | Running loss: 0.83558\n",
      "Epoch: 5 | Iteration: 690 | Classification loss: 0.15928 | Regression loss: 0.52109 | Running loss: 0.83471\n",
      "Epoch: 5 | Iteration: 691 | Classification loss: 0.30084 | Regression loss: 0.56894 | Running loss: 0.83478\n",
      "Epoch: 5 | Iteration: 692 | Classification loss: 0.17781 | Regression loss: 0.52615 | Running loss: 0.83435\n",
      "Epoch: 5 | Iteration: 693 | Classification loss: 0.33339 | Regression loss: 0.53301 | Running loss: 0.83431\n",
      "Epoch: 5 | Iteration: 694 | Classification loss: 0.19147 | Regression loss: 0.42967 | Running loss: 0.83402\n",
      "Epoch: 5 | Iteration: 695 | Classification loss: 0.29529 | Regression loss: 0.71459 | Running loss: 0.83446\n",
      "Epoch: 5 | Iteration: 696 | Classification loss: 0.31386 | Regression loss: 0.61378 | Running loss: 0.83498\n",
      "Epoch: 5 | Iteration: 697 | Classification loss: 0.19276 | Regression loss: 0.55860 | Running loss: 0.83479\n",
      "Epoch: 5 | Iteration: 698 | Classification loss: 0.26870 | Regression loss: 0.64092 | Running loss: 0.83511\n",
      "Epoch: 5 | Iteration: 699 | Classification loss: 0.25389 | Regression loss: 0.55133 | Running loss: 0.83532\n",
      "Epoch: 5 | Iteration: 700 | Classification loss: 0.17483 | Regression loss: 0.33113 | Running loss: 0.83441\n",
      "Epoch: 5 | Iteration: 701 | Classification loss: 0.36341 | Regression loss: 0.78376 | Running loss: 0.83551\n",
      "Epoch: 5 | Iteration: 702 | Classification loss: 0.22150 | Regression loss: 0.54576 | Running loss: 0.83535\n",
      "Epoch: 5 | Iteration: 703 | Classification loss: 0.22770 | Regression loss: 0.51676 | Running loss: 0.83596\n",
      "Epoch: 5 | Iteration: 704 | Classification loss: 0.16255 | Regression loss: 0.43604 | Running loss: 0.83548\n",
      "Epoch: 5 | Iteration: 705 | Classification loss: 0.32315 | Regression loss: 0.69138 | Running loss: 0.83562\n",
      "Epoch: 5 | Iteration: 706 | Classification loss: 0.31825 | Regression loss: 0.70638 | Running loss: 0.83574\n",
      "Epoch: 5 | Iteration: 707 | Classification loss: 0.26328 | Regression loss: 0.54859 | Running loss: 0.83531\n",
      "Epoch: 5 | Iteration: 708 | Classification loss: 0.24792 | Regression loss: 0.51939 | Running loss: 0.83553\n",
      "Epoch: 5 | Iteration: 709 | Classification loss: 0.44265 | Regression loss: 0.50323 | Running loss: 0.83556\n",
      "Epoch: 5 | Iteration: 710 | Classification loss: 0.19907 | Regression loss: 0.42731 | Running loss: 0.83516\n",
      "Epoch: 5 | Iteration: 711 | Classification loss: 0.32678 | Regression loss: 0.56817 | Running loss: 0.83537\n",
      "Epoch: 5 | Iteration: 712 | Classification loss: 0.23432 | Regression loss: 0.54937 | Running loss: 0.83527\n",
      "Epoch: 5 | Iteration: 713 | Classification loss: 0.22781 | Regression loss: 0.52339 | Running loss: 0.83511\n",
      "Epoch: 5 | Iteration: 714 | Classification loss: 0.39724 | Regression loss: 0.61779 | Running loss: 0.83557\n",
      "Epoch: 5 | Iteration: 715 | Classification loss: 0.38567 | Regression loss: 0.68953 | Running loss: 0.83626\n",
      "Epoch: 5 | Iteration: 716 | Classification loss: 0.26887 | Regression loss: 0.65363 | Running loss: 0.83593\n",
      "Epoch: 5 | Iteration: 717 | Classification loss: 0.38063 | Regression loss: 0.72461 | Running loss: 0.83683\n",
      "Epoch: 5 | Iteration: 718 | Classification loss: 0.20434 | Regression loss: 0.52077 | Running loss: 0.83670\n",
      "Epoch: 5 | Iteration: 719 | Classification loss: 0.28592 | Regression loss: 0.59877 | Running loss: 0.83641\n",
      "Epoch: 5 | Iteration: 720 | Classification loss: 0.32962 | Regression loss: 0.75239 | Running loss: 0.83681\n",
      "Epoch: 5 | Iteration: 721 | Classification loss: 0.31613 | Regression loss: 0.56557 | Running loss: 0.83698\n",
      "Epoch: 5 | Iteration: 722 | Classification loss: 0.25791 | Regression loss: 0.65967 | Running loss: 0.83738\n",
      "Epoch: 5 | Iteration: 723 | Classification loss: 0.23406 | Regression loss: 0.58371 | Running loss: 0.83703\n",
      "Epoch: 5 | Iteration: 724 | Classification loss: 0.23911 | Regression loss: 0.56692 | Running loss: 0.83679\n",
      "Epoch: 5 | Iteration: 725 | Classification loss: 0.24479 | Regression loss: 0.58123 | Running loss: 0.83686\n",
      "Epoch: 5 | Iteration: 726 | Classification loss: 0.22415 | Regression loss: 0.49647 | Running loss: 0.83645\n",
      "Epoch: 5 | Iteration: 727 | Classification loss: 0.27277 | Regression loss: 0.59957 | Running loss: 0.83612\n",
      "Epoch: 5 | Iteration: 728 | Classification loss: 0.19007 | Regression loss: 0.53450 | Running loss: 0.83557\n",
      "Epoch: 5 | Iteration: 729 | Classification loss: 0.33825 | Regression loss: 0.46156 | Running loss: 0.83519\n",
      "Epoch: 5 | Iteration: 730 | Classification loss: 0.24184 | Regression loss: 0.49879 | Running loss: 0.83441\n",
      "Epoch: 5 | Iteration: 731 | Classification loss: 0.17471 | Regression loss: 0.42483 | Running loss: 0.83368\n",
      "Epoch: 5 | Iteration: 732 | Classification loss: 0.29604 | Regression loss: 0.56231 | Running loss: 0.83381\n",
      "Epoch: 5 | Iteration: 733 | Classification loss: 0.24013 | Regression loss: 0.57027 | Running loss: 0.83309\n",
      "Epoch: 5 | Iteration: 734 | Classification loss: 0.27636 | Regression loss: 0.60756 | Running loss: 0.83305\n",
      "Epoch: 5 | Iteration: 735 | Classification loss: 0.22287 | Regression loss: 0.50557 | Running loss: 0.83282\n",
      "Epoch: 5 | Iteration: 736 | Classification loss: 0.19231 | Regression loss: 0.49808 | Running loss: 0.83226\n",
      "Epoch: 5 | Iteration: 737 | Classification loss: 0.20666 | Regression loss: 0.38607 | Running loss: 0.83179\n",
      "Epoch: 5 | Iteration: 738 | Classification loss: 0.26716 | Regression loss: 0.65793 | Running loss: 0.83156\n",
      "Epoch: 5 | Iteration: 739 | Classification loss: 0.33900 | Regression loss: 0.67545 | Running loss: 0.83180\n",
      "Epoch: 5 | Iteration: 740 | Classification loss: 0.23404 | Regression loss: 0.58811 | Running loss: 0.83167\n",
      "Epoch: 5 | Iteration: 741 | Classification loss: 0.17362 | Regression loss: 0.49289 | Running loss: 0.83117\n",
      "Epoch: 5 | Iteration: 742 | Classification loss: 0.27379 | Regression loss: 0.33857 | Running loss: 0.83042\n",
      "Epoch: 5 | Iteration: 743 | Classification loss: 0.26780 | Regression loss: 0.49683 | Running loss: 0.83026\n",
      "Epoch: 5 | Iteration: 744 | Classification loss: 0.31431 | Regression loss: 0.72546 | Running loss: 0.83051\n",
      "Epoch: 5 | Iteration: 745 | Classification loss: 0.34147 | Regression loss: 0.71526 | Running loss: 0.83109\n",
      "Epoch: 5 | Iteration: 746 | Classification loss: 0.21102 | Regression loss: 0.45708 | Running loss: 0.83066\n",
      "Epoch: 5 | Iteration: 747 | Classification loss: 0.26385 | Regression loss: 0.67516 | Running loss: 0.83101\n",
      "Epoch: 5 | Iteration: 748 | Classification loss: 0.36181 | Regression loss: 0.71078 | Running loss: 0.83133\n",
      "Epoch: 5 | Iteration: 749 | Classification loss: 0.23326 | Regression loss: 0.56757 | Running loss: 0.83157\n",
      "Epoch: 5 | Iteration: 750 | Classification loss: 0.41886 | Regression loss: 0.54037 | Running loss: 0.83131\n",
      "Epoch: 5 | Iteration: 751 | Classification loss: 0.12228 | Regression loss: 0.40323 | Running loss: 0.83101\n",
      "Epoch: 5 | Iteration: 752 | Classification loss: 0.24694 | Regression loss: 0.46567 | Running loss: 0.83074\n",
      "Epoch: 5 | Iteration: 753 | Classification loss: 0.18985 | Regression loss: 0.46563 | Running loss: 0.82954\n",
      "Epoch: 5 | Iteration: 754 | Classification loss: 0.29104 | Regression loss: 0.51394 | Running loss: 0.82916\n",
      "Epoch: 5 | Iteration: 755 | Classification loss: 0.13839 | Regression loss: 0.38818 | Running loss: 0.82841\n",
      "Epoch: 5 | Iteration: 756 | Classification loss: 0.24019 | Regression loss: 0.60352 | Running loss: 0.82848\n",
      "Epoch: 5 | Iteration: 757 | Classification loss: 0.27938 | Regression loss: 0.62353 | Running loss: 0.82861\n",
      "Epoch: 5 | Iteration: 758 | Classification loss: 0.25244 | Regression loss: 0.54854 | Running loss: 0.82826\n",
      "Epoch: 5 | Iteration: 759 | Classification loss: 0.27877 | Regression loss: 0.64133 | Running loss: 0.82829\n",
      "Epoch: 5 | Iteration: 760 | Classification loss: 0.19760 | Regression loss: 0.51640 | Running loss: 0.82797\n",
      "Epoch: 5 | Iteration: 761 | Classification loss: 0.29089 | Regression loss: 0.62754 | Running loss: 0.82803\n",
      "Epoch: 5 | Iteration: 762 | Classification loss: 0.23543 | Regression loss: 0.54112 | Running loss: 0.82803\n",
      "Epoch: 5 | Iteration: 763 | Classification loss: 0.27409 | Regression loss: 0.65353 | Running loss: 0.82805\n",
      "Epoch: 5 | Iteration: 764 | Classification loss: 0.27898 | Regression loss: 0.64529 | Running loss: 0.82782\n",
      "Epoch: 5 | Iteration: 765 | Classification loss: 0.34917 | Regression loss: 0.65434 | Running loss: 0.82822\n",
      "Epoch: 5 | Iteration: 766 | Classification loss: 0.29494 | Regression loss: 0.62231 | Running loss: 0.82846\n",
      "Epoch: 5 | Iteration: 767 | Classification loss: 0.26039 | Regression loss: 0.67388 | Running loss: 0.82886\n",
      "Epoch: 5 | Iteration: 768 | Classification loss: 0.20456 | Regression loss: 0.56062 | Running loss: 0.82819\n",
      "Epoch: 5 | Iteration: 769 | Classification loss: 0.32140 | Regression loss: 0.61134 | Running loss: 0.82805\n",
      "Epoch: 5 | Iteration: 770 | Classification loss: 0.23493 | Regression loss: 0.65475 | Running loss: 0.82811\n",
      "Epoch: 5 | Iteration: 771 | Classification loss: 0.26247 | Regression loss: 0.70445 | Running loss: 0.82791\n",
      "Epoch: 5 | Iteration: 772 | Classification loss: 0.21858 | Regression loss: 0.55703 | Running loss: 0.82817\n",
      "Epoch: 5 | Iteration: 773 | Classification loss: 0.28367 | Regression loss: 0.67603 | Running loss: 0.82857\n",
      "Epoch: 5 | Iteration: 774 | Classification loss: 0.38187 | Regression loss: 0.69182 | Running loss: 0.82942\n",
      "Epoch: 5 | Iteration: 775 | Classification loss: 0.35300 | Regression loss: 0.51879 | Running loss: 0.82953\n",
      "Epoch: 5 | Iteration: 776 | Classification loss: 0.22501 | Regression loss: 0.49713 | Running loss: 0.82909\n",
      "Epoch: 5 | Iteration: 777 | Classification loss: 0.29970 | Regression loss: 0.62373 | Running loss: 0.82930\n",
      "Epoch: 5 | Iteration: 778 | Classification loss: 0.31888 | Regression loss: 0.72747 | Running loss: 0.83012\n",
      "Epoch: 5 | Iteration: 779 | Classification loss: 0.25247 | Regression loss: 0.51764 | Running loss: 0.83000\n",
      "Epoch: 5 | Iteration: 780 | Classification loss: 0.22512 | Regression loss: 0.50370 | Running loss: 0.82999\n",
      "Epoch: 5 | Iteration: 781 | Classification loss: 0.17079 | Regression loss: 0.43533 | Running loss: 0.82949\n",
      "Epoch: 5 | Iteration: 782 | Classification loss: 0.31863 | Regression loss: 0.65845 | Running loss: 0.82931\n",
      "Epoch: 5 | Iteration: 783 | Classification loss: 0.34318 | Regression loss: 0.63432 | Running loss: 0.82955\n",
      "Evaluating dataset\n",
      "\n",
      "mAP:\n",
      "person: 0.4213609440663836\n",
      "Precision:  0.04384751487855879\n",
      "Recall:  0.7739920499716071\n",
      "car: 0.513704979330476\n",
      "Precision:  0.04384751487855879\n",
      "Recall:  0.7739920499716071\n",
      "Epoch: 6 | Iteration: 0 | Classification loss: 0.14291 | Regression loss: 0.40889 | Running loss: 0.82913\n",
      "Epoch: 6 | Iteration: 1 | Classification loss: 0.26685 | Regression loss: 0.59743 | Running loss: 0.82893\n",
      "Epoch: 6 | Iteration: 2 | Classification loss: 0.22118 | Regression loss: 0.63109 | Running loss: 0.82859\n",
      "Epoch: 6 | Iteration: 3 | Classification loss: 0.23026 | Regression loss: 0.54428 | Running loss: 0.82910\n",
      "Epoch: 6 | Iteration: 4 | Classification loss: 0.34756 | Regression loss: 0.61756 | Running loss: 0.82926\n",
      "Epoch: 6 | Iteration: 5 | Classification loss: 0.21879 | Regression loss: 0.53625 | Running loss: 0.82965\n",
      "Epoch: 6 | Iteration: 6 | Classification loss: 0.24524 | Regression loss: 0.43467 | Running loss: 0.82938\n",
      "Epoch: 6 | Iteration: 7 | Classification loss: 0.29400 | Regression loss: 0.65135 | Running loss: 0.82932\n",
      "Epoch: 6 | Iteration: 8 | Classification loss: 0.24897 | Regression loss: 0.49434 | Running loss: 0.82950\n",
      "Epoch: 6 | Iteration: 9 | Classification loss: 0.34134 | Regression loss: 0.47089 | Running loss: 0.82927\n",
      "Epoch: 6 | Iteration: 10 | Classification loss: 0.22918 | Regression loss: 0.51424 | Running loss: 0.82959\n",
      "Epoch: 6 | Iteration: 11 | Classification loss: 0.26688 | Regression loss: 0.68446 | Running loss: 0.82962\n",
      "Epoch: 6 | Iteration: 12 | Classification loss: 0.24627 | Regression loss: 0.52302 | Running loss: 0.82980\n",
      "Epoch: 6 | Iteration: 13 | Classification loss: 0.17044 | Regression loss: 0.42482 | Running loss: 0.82932\n",
      "Epoch: 6 | Iteration: 14 | Classification loss: 0.27290 | Regression loss: 0.55612 | Running loss: 0.82941\n",
      "Epoch: 6 | Iteration: 15 | Classification loss: 0.23502 | Regression loss: 0.64087 | Running loss: 0.82936\n",
      "Epoch: 6 | Iteration: 16 | Classification loss: 0.22688 | Regression loss: 0.58079 | Running loss: 0.82933\n",
      "Epoch: 6 | Iteration: 17 | Classification loss: 0.23645 | Regression loss: 0.53727 | Running loss: 0.82914\n",
      "Epoch: 6 | Iteration: 18 | Classification loss: 0.16326 | Regression loss: 0.47574 | Running loss: 0.82876\n",
      "Epoch: 6 | Iteration: 19 | Classification loss: 0.26749 | Regression loss: 0.71789 | Running loss: 0.82873\n",
      "Epoch: 6 | Iteration: 20 | Classification loss: 0.20223 | Regression loss: 0.48177 | Running loss: 0.82847\n",
      "Epoch: 6 | Iteration: 21 | Classification loss: 0.20583 | Regression loss: 0.47948 | Running loss: 0.82806\n",
      "Epoch: 6 | Iteration: 22 | Classification loss: 0.27293 | Regression loss: 0.59351 | Running loss: 0.82812\n",
      "Epoch: 6 | Iteration: 23 | Classification loss: 0.64329 | Regression loss: 0.70502 | Running loss: 0.82890\n",
      "Epoch: 6 | Iteration: 24 | Classification loss: 0.13122 | Regression loss: 0.39024 | Running loss: 0.82815\n",
      "Epoch: 6 | Iteration: 25 | Classification loss: 0.27539 | Regression loss: 0.61072 | Running loss: 0.82855\n",
      "Epoch: 6 | Iteration: 26 | Classification loss: 0.23743 | Regression loss: 0.49368 | Running loss: 0.82812\n",
      "Epoch: 6 | Iteration: 27 | Classification loss: 0.22860 | Regression loss: 0.50988 | Running loss: 0.82755\n",
      "Epoch: 6 | Iteration: 28 | Classification loss: 0.27686 | Regression loss: 0.64896 | Running loss: 0.82808\n",
      "Epoch: 6 | Iteration: 29 | Classification loss: 0.30358 | Regression loss: 0.62176 | Running loss: 0.82806\n",
      "Epoch: 6 | Iteration: 30 | Classification loss: 0.24169 | Regression loss: 0.53982 | Running loss: 0.82834\n",
      "Epoch: 6 | Iteration: 31 | Classification loss: 0.25942 | Regression loss: 0.54704 | Running loss: 0.82833\n",
      "Epoch: 6 | Iteration: 32 | Classification loss: 0.30908 | Regression loss: 0.65151 | Running loss: 0.82860\n",
      "Epoch: 6 | Iteration: 33 | Classification loss: 0.22186 | Regression loss: 0.57709 | Running loss: 0.82880\n",
      "Epoch: 6 | Iteration: 34 | Classification loss: 0.23381 | Regression loss: 0.52286 | Running loss: 0.82803\n",
      "Epoch: 6 | Iteration: 35 | Classification loss: 0.17232 | Regression loss: 0.51384 | Running loss: 0.82783\n",
      "Epoch: 6 | Iteration: 36 | Classification loss: 0.16768 | Regression loss: 0.47226 | Running loss: 0.82714\n",
      "Epoch: 6 | Iteration: 37 | Classification loss: 0.23157 | Regression loss: 0.43738 | Running loss: 0.82701\n",
      "Epoch: 6 | Iteration: 38 | Classification loss: 0.16417 | Regression loss: 0.38499 | Running loss: 0.82636\n",
      "Epoch: 6 | Iteration: 39 | Classification loss: 0.13140 | Regression loss: 0.40698 | Running loss: 0.82580\n",
      "Epoch: 6 | Iteration: 40 | Classification loss: 0.33111 | Regression loss: 0.56184 | Running loss: 0.82563\n",
      "Epoch: 6 | Iteration: 41 | Classification loss: 0.29738 | Regression loss: 0.58964 | Running loss: 0.82590\n",
      "Epoch: 6 | Iteration: 42 | Classification loss: 0.29949 | Regression loss: 0.55907 | Running loss: 0.82620\n",
      "Epoch: 6 | Iteration: 43 | Classification loss: 0.13182 | Regression loss: 0.32584 | Running loss: 0.82564\n",
      "Epoch: 6 | Iteration: 44 | Classification loss: 0.28859 | Regression loss: 0.64799 | Running loss: 0.82617\n",
      "Epoch: 6 | Iteration: 45 | Classification loss: 0.20699 | Regression loss: 0.57593 | Running loss: 0.82581\n",
      "Epoch: 6 | Iteration: 46 | Classification loss: 0.24245 | Regression loss: 0.50300 | Running loss: 0.82559\n",
      "Epoch: 6 | Iteration: 47 | Classification loss: 0.26962 | Regression loss: 0.50993 | Running loss: 0.82519\n",
      "Epoch: 6 | Iteration: 48 | Classification loss: 0.13687 | Regression loss: 0.40311 | Running loss: 0.82464\n",
      "Epoch: 6 | Iteration: 49 | Classification loss: 0.25787 | Regression loss: 0.60428 | Running loss: 0.82468\n",
      "Epoch: 6 | Iteration: 50 | Classification loss: 0.21969 | Regression loss: 0.50225 | Running loss: 0.82449\n",
      "Epoch: 6 | Iteration: 51 | Classification loss: 0.21462 | Regression loss: 0.48945 | Running loss: 0.82419\n",
      "Epoch: 6 | Iteration: 52 | Classification loss: 0.23235 | Regression loss: 0.48623 | Running loss: 0.82377\n",
      "Epoch: 6 | Iteration: 53 | Classification loss: 0.35905 | Regression loss: 0.62265 | Running loss: 0.82417\n",
      "Epoch: 6 | Iteration: 54 | Classification loss: 0.33223 | Regression loss: 0.73397 | Running loss: 0.82485\n",
      "Epoch: 6 | Iteration: 55 | Classification loss: 0.12564 | Regression loss: 0.31552 | Running loss: 0.82378\n",
      "Epoch: 6 | Iteration: 56 | Classification loss: 0.21887 | Regression loss: 0.52108 | Running loss: 0.82376\n",
      "Epoch: 6 | Iteration: 57 | Classification loss: 0.21911 | Regression loss: 0.56632 | Running loss: 0.82411\n",
      "Epoch: 6 | Iteration: 58 | Classification loss: 0.32344 | Regression loss: 0.58964 | Running loss: 0.82490\n",
      "Epoch: 6 | Iteration: 59 | Classification loss: 0.22679 | Regression loss: 0.50954 | Running loss: 0.82476\n",
      "Epoch: 6 | Iteration: 60 | Classification loss: 0.25532 | Regression loss: 0.51376 | Running loss: 0.82496\n",
      "Epoch: 6 | Iteration: 61 | Classification loss: 0.24329 | Regression loss: 0.64104 | Running loss: 0.82480\n",
      "Epoch: 6 | Iteration: 62 | Classification loss: 0.21968 | Regression loss: 0.45717 | Running loss: 0.82414\n",
      "Epoch: 6 | Iteration: 63 | Classification loss: 0.18679 | Regression loss: 0.38725 | Running loss: 0.82367\n",
      "Epoch: 6 | Iteration: 64 | Classification loss: 0.35920 | Regression loss: 0.53187 | Running loss: 0.82360\n",
      "Epoch: 6 | Iteration: 65 | Classification loss: 0.21602 | Regression loss: 0.45309 | Running loss: 0.82395\n",
      "Epoch: 6 | Iteration: 66 | Classification loss: 0.28867 | Regression loss: 0.66247 | Running loss: 0.82410\n",
      "Epoch: 6 | Iteration: 67 | Classification loss: 0.21572 | Regression loss: 0.51274 | Running loss: 0.82440\n",
      "Epoch: 6 | Iteration: 68 | Classification loss: 0.22686 | Regression loss: 0.62330 | Running loss: 0.82480\n",
      "Epoch: 6 | Iteration: 69 | Classification loss: 0.20126 | Regression loss: 0.43042 | Running loss: 0.82443\n",
      "Epoch: 6 | Iteration: 70 | Classification loss: 0.21761 | Regression loss: 0.54755 | Running loss: 0.82432\n",
      "Epoch: 6 | Iteration: 71 | Classification loss: 0.10273 | Regression loss: 0.35172 | Running loss: 0.82400\n",
      "Epoch: 6 | Iteration: 72 | Classification loss: 0.33692 | Regression loss: 0.70151 | Running loss: 0.82419\n",
      "Epoch: 6 | Iteration: 73 | Classification loss: 0.11967 | Regression loss: 0.36244 | Running loss: 0.82338\n",
      "Epoch: 6 | Iteration: 74 | Classification loss: 0.32020 | Regression loss: 0.64468 | Running loss: 0.82377\n",
      "Epoch: 6 | Iteration: 75 | Classification loss: 0.39322 | Regression loss: 0.75050 | Running loss: 0.82435\n",
      "Epoch: 6 | Iteration: 76 | Classification loss: 0.24851 | Regression loss: 0.62149 | Running loss: 0.82402\n",
      "Epoch: 6 | Iteration: 77 | Classification loss: 0.32378 | Regression loss: 0.73779 | Running loss: 0.82417\n",
      "Epoch: 6 | Iteration: 78 | Classification loss: 0.20685 | Regression loss: 0.50503 | Running loss: 0.82396\n",
      "Epoch: 6 | Iteration: 79 | Classification loss: 0.24716 | Regression loss: 0.48443 | Running loss: 0.82362\n",
      "Epoch: 6 | Iteration: 80 | Classification loss: 0.20872 | Regression loss: 0.41992 | Running loss: 0.82321\n",
      "Epoch: 6 | Iteration: 81 | Classification loss: 0.27860 | Regression loss: 0.58622 | Running loss: 0.82308\n",
      "Epoch: 6 | Iteration: 82 | Classification loss: 0.20906 | Regression loss: 0.57519 | Running loss: 0.82325\n",
      "Epoch: 6 | Iteration: 83 | Classification loss: 0.29503 | Regression loss: 0.66613 | Running loss: 0.82352\n",
      "Epoch: 6 | Iteration: 84 | Classification loss: 0.14832 | Regression loss: 0.33291 | Running loss: 0.82348\n",
      "Epoch: 6 | Iteration: 85 | Classification loss: 0.15574 | Regression loss: 0.53207 | Running loss: 0.82327\n",
      "Epoch: 6 | Iteration: 86 | Classification loss: 0.29029 | Regression loss: 0.59016 | Running loss: 0.82388\n",
      "Epoch: 6 | Iteration: 87 | Classification loss: 0.26105 | Regression loss: 0.57202 | Running loss: 0.82411\n",
      "Epoch: 6 | Iteration: 88 | Classification loss: 0.30645 | Regression loss: 0.60872 | Running loss: 0.82464\n",
      "Epoch: 6 | Iteration: 89 | Classification loss: 0.20478 | Regression loss: 0.50166 | Running loss: 0.82387\n",
      "Epoch: 6 | Iteration: 90 | Classification loss: 0.23621 | Regression loss: 0.59652 | Running loss: 0.82375\n",
      "Epoch: 6 | Iteration: 91 | Classification loss: 0.35054 | Regression loss: 0.64607 | Running loss: 0.82457\n",
      "Epoch: 6 | Iteration: 92 | Classification loss: 0.25805 | Regression loss: 0.63284 | Running loss: 0.82486\n",
      "Epoch: 6 | Iteration: 93 | Classification loss: 0.22321 | Regression loss: 0.55062 | Running loss: 0.82456\n",
      "Epoch: 6 | Iteration: 94 | Classification loss: 0.14828 | Regression loss: 0.40071 | Running loss: 0.82393\n",
      "Epoch: 6 | Iteration: 95 | Classification loss: 0.19720 | Regression loss: 0.54555 | Running loss: 0.82368\n",
      "Epoch: 6 | Iteration: 96 | Classification loss: 0.25326 | Regression loss: 0.61108 | Running loss: 0.82354\n",
      "Epoch: 6 | Iteration: 97 | Classification loss: 0.27339 | Regression loss: 0.59855 | Running loss: 0.82353\n",
      "Epoch: 6 | Iteration: 98 | Classification loss: 0.28347 | Regression loss: 0.56381 | Running loss: 0.82372\n",
      "Epoch: 6 | Iteration: 99 | Classification loss: 0.37263 | Regression loss: 0.58926 | Running loss: 0.82370\n",
      "Epoch: 6 | Iteration: 100 | Classification loss: 0.25523 | Regression loss: 0.54372 | Running loss: 0.82385\n",
      "Epoch: 6 | Iteration: 101 | Classification loss: 0.27350 | Regression loss: 0.49490 | Running loss: 0.82350\n",
      "Epoch: 6 | Iteration: 102 | Classification loss: 0.18666 | Regression loss: 0.39360 | Running loss: 0.82233\n",
      "Epoch: 6 | Iteration: 103 | Classification loss: 0.25217 | Regression loss: 0.55387 | Running loss: 0.82239\n",
      "Epoch: 6 | Iteration: 104 | Classification loss: 0.21386 | Regression loss: 0.47738 | Running loss: 0.82159\n",
      "Epoch: 6 | Iteration: 105 | Classification loss: 0.21758 | Regression loss: 0.52101 | Running loss: 0.82100\n",
      "Epoch: 6 | Iteration: 106 | Classification loss: 0.13430 | Regression loss: 0.40704 | Running loss: 0.82029\n",
      "Epoch: 6 | Iteration: 107 | Classification loss: 0.24231 | Regression loss: 0.55762 | Running loss: 0.82009\n",
      "Epoch: 6 | Iteration: 108 | Classification loss: 0.16724 | Regression loss: 0.37331 | Running loss: 0.81981\n",
      "Epoch: 6 | Iteration: 109 | Classification loss: 0.27567 | Regression loss: 0.62841 | Running loss: 0.81977\n",
      "Epoch: 6 | Iteration: 110 | Classification loss: 0.21659 | Regression loss: 0.54773 | Running loss: 0.81940\n",
      "Epoch: 6 | Iteration: 111 | Classification loss: 0.29222 | Regression loss: 0.54287 | Running loss: 0.81932\n",
      "Epoch: 6 | Iteration: 112 | Classification loss: 0.31019 | Regression loss: 0.69920 | Running loss: 0.82021\n",
      "Epoch: 6 | Iteration: 113 | Classification loss: 0.14953 | Regression loss: 0.40610 | Running loss: 0.81956\n",
      "Epoch: 6 | Iteration: 114 | Classification loss: 0.32343 | Regression loss: 0.71563 | Running loss: 0.82006\n",
      "Epoch: 6 | Iteration: 115 | Classification loss: 0.18949 | Regression loss: 0.41166 | Running loss: 0.81964\n",
      "Epoch: 6 | Iteration: 116 | Classification loss: 0.27327 | Regression loss: 0.51451 | Running loss: 0.81990\n",
      "Epoch: 6 | Iteration: 117 | Classification loss: 0.23703 | Regression loss: 0.59788 | Running loss: 0.82012\n",
      "Epoch: 6 | Iteration: 118 | Classification loss: 0.23540 | Regression loss: 0.54225 | Running loss: 0.82022\n",
      "Epoch: 6 | Iteration: 119 | Classification loss: 0.26250 | Regression loss: 0.59418 | Running loss: 0.82047\n",
      "Epoch: 6 | Iteration: 120 | Classification loss: 0.22657 | Regression loss: 0.45282 | Running loss: 0.82003\n",
      "Epoch: 6 | Iteration: 121 | Classification loss: 0.16012 | Regression loss: 0.42227 | Running loss: 0.81944\n",
      "Epoch: 6 | Iteration: 122 | Classification loss: 0.13318 | Regression loss: 0.34528 | Running loss: 0.81860\n",
      "Epoch: 6 | Iteration: 123 | Classification loss: 0.17892 | Regression loss: 0.48410 | Running loss: 0.81837\n",
      "Epoch: 6 | Iteration: 124 | Classification loss: 0.32024 | Regression loss: 0.67709 | Running loss: 0.81785\n",
      "Epoch: 6 | Iteration: 125 | Classification loss: 0.39129 | Regression loss: 0.66026 | Running loss: 0.81797\n",
      "Epoch: 6 | Iteration: 126 | Classification loss: 0.15952 | Regression loss: 0.43284 | Running loss: 0.81733\n",
      "Epoch: 6 | Iteration: 127 | Classification loss: 0.27537 | Regression loss: 0.57966 | Running loss: 0.81745\n",
      "Epoch: 6 | Iteration: 128 | Classification loss: 0.30036 | Regression loss: 0.67689 | Running loss: 0.81828\n",
      "Epoch: 6 | Iteration: 129 | Classification loss: 0.21275 | Regression loss: 0.47685 | Running loss: 0.81809\n",
      "Epoch: 6 | Iteration: 130 | Classification loss: 0.16817 | Regression loss: 0.37451 | Running loss: 0.81737\n",
      "Epoch: 6 | Iteration: 131 | Classification loss: 0.28547 | Regression loss: 0.59443 | Running loss: 0.81719\n",
      "Epoch: 6 | Iteration: 132 | Classification loss: 0.26721 | Regression loss: 0.52632 | Running loss: 0.81699\n",
      "Epoch: 6 | Iteration: 133 | Classification loss: 0.21440 | Regression loss: 0.49567 | Running loss: 0.81635\n",
      "Epoch: 6 | Iteration: 134 | Classification loss: 0.25840 | Regression loss: 0.56606 | Running loss: 0.81626\n",
      "Epoch: 6 | Iteration: 135 | Classification loss: 0.19100 | Regression loss: 0.44115 | Running loss: 0.81611\n",
      "Epoch: 6 | Iteration: 136 | Classification loss: 0.27406 | Regression loss: 0.50223 | Running loss: 0.81590\n",
      "Epoch: 6 | Iteration: 137 | Classification loss: 0.36536 | Regression loss: 0.79156 | Running loss: 0.81653\n",
      "Epoch: 6 | Iteration: 138 | Classification loss: 0.32251 | Regression loss: 0.59814 | Running loss: 0.81672\n",
      "Epoch: 6 | Iteration: 139 | Classification loss: 0.23597 | Regression loss: 0.52000 | Running loss: 0.81637\n",
      "Epoch: 6 | Iteration: 140 | Classification loss: 0.18435 | Regression loss: 0.50136 | Running loss: 0.81645\n",
      "Epoch: 6 | Iteration: 141 | Classification loss: 0.27056 | Regression loss: 0.60041 | Running loss: 0.81649\n",
      "Epoch: 6 | Iteration: 142 | Classification loss: 0.23079 | Regression loss: 0.51213 | Running loss: 0.81668\n",
      "Epoch: 6 | Iteration: 143 | Classification loss: 0.30479 | Regression loss: 0.64306 | Running loss: 0.81657\n",
      "Epoch: 6 | Iteration: 144 | Classification loss: 0.14131 | Regression loss: 0.37608 | Running loss: 0.81590\n",
      "Epoch: 6 | Iteration: 145 | Classification loss: 0.20719 | Regression loss: 0.44131 | Running loss: 0.81605\n",
      "Epoch: 6 | Iteration: 146 | Classification loss: 0.22269 | Regression loss: 0.55185 | Running loss: 0.81604\n",
      "Epoch: 6 | Iteration: 147 | Classification loss: 0.16419 | Regression loss: 0.37988 | Running loss: 0.81572\n",
      "Epoch: 6 | Iteration: 148 | Classification loss: 0.22317 | Regression loss: 0.49215 | Running loss: 0.81506\n",
      "Epoch: 6 | Iteration: 149 | Classification loss: 0.24283 | Regression loss: 0.55578 | Running loss: 0.81502\n",
      "Epoch: 6 | Iteration: 150 | Classification loss: 0.22119 | Regression loss: 0.42934 | Running loss: 0.81483\n",
      "Epoch: 6 | Iteration: 151 | Classification loss: 0.17524 | Regression loss: 0.45807 | Running loss: 0.81389\n",
      "Epoch: 6 | Iteration: 152 | Classification loss: 0.22307 | Regression loss: 0.61386 | Running loss: 0.81391\n",
      "Epoch: 6 | Iteration: 153 | Classification loss: 0.15287 | Regression loss: 0.44509 | Running loss: 0.81390\n",
      "Epoch: 6 | Iteration: 154 | Classification loss: 0.26693 | Regression loss: 0.66097 | Running loss: 0.81436\n",
      "Epoch: 6 | Iteration: 155 | Classification loss: 0.22540 | Regression loss: 0.60208 | Running loss: 0.81467\n",
      "Epoch: 6 | Iteration: 156 | Classification loss: 0.23790 | Regression loss: 0.56569 | Running loss: 0.81486\n",
      "Epoch: 6 | Iteration: 157 | Classification loss: 0.18917 | Regression loss: 0.40222 | Running loss: 0.81419\n",
      "Epoch: 6 | Iteration: 158 | Classification loss: 0.22794 | Regression loss: 0.66348 | Running loss: 0.81477\n",
      "Epoch: 6 | Iteration: 159 | Classification loss: 0.28641 | Regression loss: 0.65423 | Running loss: 0.81484\n",
      "Epoch: 6 | Iteration: 160 | Classification loss: 0.36273 | Regression loss: 0.59344 | Running loss: 0.81471\n",
      "Epoch: 6 | Iteration: 161 | Classification loss: 0.28736 | Regression loss: 0.57978 | Running loss: 0.81480\n",
      "Epoch: 6 | Iteration: 162 | Classification loss: 0.21725 | Regression loss: 0.50433 | Running loss: 0.81469\n",
      "Epoch: 6 | Iteration: 163 | Classification loss: 0.24280 | Regression loss: 0.54628 | Running loss: 0.81444\n",
      "Epoch: 6 | Iteration: 164 | Classification loss: 0.22727 | Regression loss: 0.55301 | Running loss: 0.81453\n",
      "Epoch: 6 | Iteration: 165 | Classification loss: 0.19045 | Regression loss: 0.50482 | Running loss: 0.81445\n",
      "Epoch: 6 | Iteration: 166 | Classification loss: 0.28251 | Regression loss: 0.55115 | Running loss: 0.81465\n",
      "Epoch: 6 | Iteration: 167 | Classification loss: 0.21566 | Regression loss: 0.51044 | Running loss: 0.81481\n",
      "Epoch: 6 | Iteration: 168 | Classification loss: 0.22761 | Regression loss: 0.51715 | Running loss: 0.81412\n",
      "Epoch: 6 | Iteration: 169 | Classification loss: 0.25453 | Regression loss: 0.55617 | Running loss: 0.81366\n",
      "Epoch: 6 | Iteration: 170 | Classification loss: 0.21845 | Regression loss: 0.51230 | Running loss: 0.81357\n",
      "Epoch: 6 | Iteration: 171 | Classification loss: 0.23400 | Regression loss: 0.61094 | Running loss: 0.81315\n",
      "Epoch: 6 | Iteration: 172 | Classification loss: 0.31605 | Regression loss: 0.62827 | Running loss: 0.81290\n",
      "Epoch: 6 | Iteration: 173 | Classification loss: 0.31895 | Regression loss: 0.63436 | Running loss: 0.81192\n",
      "Epoch: 6 | Iteration: 174 | Classification loss: 0.28953 | Regression loss: 0.63158 | Running loss: 0.81236\n",
      "Epoch: 6 | Iteration: 175 | Classification loss: 0.39484 | Regression loss: 0.76602 | Running loss: 0.81336\n",
      "Epoch: 6 | Iteration: 176 | Classification loss: 0.22644 | Regression loss: 0.48813 | Running loss: 0.81348\n",
      "Epoch: 6 | Iteration: 177 | Classification loss: 0.26608 | Regression loss: 0.62550 | Running loss: 0.81352\n",
      "Epoch: 6 | Iteration: 178 | Classification loss: 0.29367 | Regression loss: 0.72454 | Running loss: 0.81351\n",
      "Epoch: 6 | Iteration: 179 | Classification loss: 0.29783 | Regression loss: 0.54515 | Running loss: 0.81373\n",
      "Epoch: 6 | Iteration: 180 | Classification loss: 0.15486 | Regression loss: 0.40719 | Running loss: 0.81268\n",
      "Epoch: 6 | Iteration: 181 | Classification loss: 0.20397 | Regression loss: 0.54526 | Running loss: 0.81279\n",
      "Epoch: 6 | Iteration: 182 | Classification loss: 0.23327 | Regression loss: 0.61322 | Running loss: 0.81260\n",
      "Epoch: 6 | Iteration: 183 | Classification loss: 0.17976 | Regression loss: 0.41616 | Running loss: 0.81181\n",
      "Epoch: 6 | Iteration: 184 | Classification loss: 0.20009 | Regression loss: 0.52832 | Running loss: 0.81160\n",
      "Epoch: 6 | Iteration: 185 | Classification loss: 0.22355 | Regression loss: 0.64322 | Running loss: 0.81104\n",
      "Epoch: 6 | Iteration: 186 | Classification loss: 0.23694 | Regression loss: 0.54867 | Running loss: 0.81106\n",
      "Epoch: 6 | Iteration: 187 | Classification loss: 0.25914 | Regression loss: 0.53210 | Running loss: 0.81103\n",
      "Epoch: 6 | Iteration: 188 | Classification loss: 0.13775 | Regression loss: 0.44123 | Running loss: 0.81089\n",
      "Epoch: 6 | Iteration: 189 | Classification loss: 0.32080 | Regression loss: 0.76493 | Running loss: 0.81208\n",
      "Epoch: 6 | Iteration: 190 | Classification loss: 0.28289 | Regression loss: 0.63832 | Running loss: 0.81262\n",
      "Epoch: 6 | Iteration: 191 | Classification loss: 0.26484 | Regression loss: 0.52842 | Running loss: 0.81285\n",
      "Epoch: 6 | Iteration: 192 | Classification loss: 0.34067 | Regression loss: 0.69657 | Running loss: 0.81336\n",
      "Epoch: 6 | Iteration: 193 | Classification loss: 0.28733 | Regression loss: 0.60287 | Running loss: 0.81370\n",
      "Epoch: 6 | Iteration: 194 | Classification loss: 0.29666 | Regression loss: 0.55869 | Running loss: 0.81368\n",
      "Epoch: 6 | Iteration: 195 | Classification loss: 0.28366 | Regression loss: 0.58232 | Running loss: 0.81432\n",
      "Epoch: 6 | Iteration: 196 | Classification loss: 0.25721 | Regression loss: 0.62516 | Running loss: 0.81404\n",
      "Epoch: 6 | Iteration: 197 | Classification loss: 0.27713 | Regression loss: 0.51339 | Running loss: 0.81431\n",
      "Epoch: 6 | Iteration: 198 | Classification loss: 0.26316 | Regression loss: 0.57458 | Running loss: 0.81454\n",
      "Epoch: 6 | Iteration: 199 | Classification loss: 0.23117 | Regression loss: 0.60527 | Running loss: 0.81422\n",
      "Epoch: 6 | Iteration: 200 | Classification loss: 0.20064 | Regression loss: 0.46846 | Running loss: 0.81426\n",
      "Epoch: 6 | Iteration: 201 | Classification loss: 0.22563 | Regression loss: 0.59048 | Running loss: 0.81452\n",
      "Epoch: 6 | Iteration: 202 | Classification loss: 0.25699 | Regression loss: 0.52597 | Running loss: 0.81453\n",
      "Epoch: 6 | Iteration: 203 | Classification loss: 0.30534 | Regression loss: 0.58341 | Running loss: 0.81477\n",
      "Epoch: 6 | Iteration: 204 | Classification loss: 0.27271 | Regression loss: 0.72858 | Running loss: 0.81579\n",
      "Epoch: 6 | Iteration: 205 | Classification loss: 0.17305 | Regression loss: 0.52848 | Running loss: 0.81572\n",
      "Epoch: 6 | Iteration: 206 | Classification loss: 0.23547 | Regression loss: 0.54132 | Running loss: 0.81532\n",
      "Epoch: 6 | Iteration: 207 | Classification loss: 0.17253 | Regression loss: 0.53310 | Running loss: 0.81534\n",
      "Epoch: 6 | Iteration: 208 | Classification loss: 0.20059 | Regression loss: 0.49729 | Running loss: 0.81496\n",
      "Epoch: 6 | Iteration: 209 | Classification loss: 0.17940 | Regression loss: 0.44543 | Running loss: 0.81431\n",
      "Epoch: 6 | Iteration: 210 | Classification loss: 0.28218 | Regression loss: 0.59224 | Running loss: 0.81410\n",
      "Epoch: 6 | Iteration: 211 | Classification loss: 0.32696 | Regression loss: 0.70498 | Running loss: 0.81479\n",
      "Epoch: 6 | Iteration: 212 | Classification loss: 0.15264 | Regression loss: 0.41270 | Running loss: 0.81410\n",
      "Epoch: 6 | Iteration: 213 | Classification loss: 0.29101 | Regression loss: 0.60234 | Running loss: 0.81427\n",
      "Epoch: 6 | Iteration: 214 | Classification loss: 0.19428 | Regression loss: 0.49657 | Running loss: 0.81405\n",
      "Epoch: 6 | Iteration: 215 | Classification loss: 0.18949 | Regression loss: 0.52437 | Running loss: 0.81380\n",
      "Epoch: 6 | Iteration: 216 | Classification loss: 0.30901 | Regression loss: 0.60343 | Running loss: 0.81393\n",
      "Epoch: 6 | Iteration: 217 | Classification loss: 0.22441 | Regression loss: 0.50175 | Running loss: 0.81389\n",
      "Epoch: 6 | Iteration: 218 | Classification loss: 0.24764 | Regression loss: 0.60529 | Running loss: 0.81418\n",
      "Epoch: 6 | Iteration: 219 | Classification loss: 0.16350 | Regression loss: 0.46821 | Running loss: 0.81348\n",
      "Epoch: 6 | Iteration: 220 | Classification loss: 0.25143 | Regression loss: 0.69698 | Running loss: 0.81472\n",
      "Epoch: 6 | Iteration: 221 | Classification loss: 0.13725 | Regression loss: 0.39496 | Running loss: 0.81414\n",
      "Epoch: 6 | Iteration: 222 | Classification loss: 0.19440 | Regression loss: 0.55836 | Running loss: 0.81354\n",
      "Epoch: 6 | Iteration: 223 | Classification loss: 0.31271 | Regression loss: 0.69565 | Running loss: 0.81327\n",
      "Epoch: 6 | Iteration: 224 | Classification loss: 0.10319 | Regression loss: 0.34222 | Running loss: 0.81212\n",
      "Epoch: 6 | Iteration: 225 | Classification loss: 0.27919 | Regression loss: 0.58527 | Running loss: 0.81201\n",
      "Epoch: 6 | Iteration: 226 | Classification loss: 0.19398 | Regression loss: 0.61495 | Running loss: 0.81186\n",
      "Epoch: 6 | Iteration: 227 | Classification loss: 0.20950 | Regression loss: 0.50893 | Running loss: 0.81123\n",
      "Epoch: 6 | Iteration: 228 | Classification loss: 0.22942 | Regression loss: 0.62846 | Running loss: 0.81105\n",
      "Epoch: 6 | Iteration: 229 | Classification loss: 0.20327 | Regression loss: 0.43077 | Running loss: 0.81044\n",
      "Epoch: 6 | Iteration: 230 | Classification loss: 0.27522 | Regression loss: 0.58875 | Running loss: 0.81060\n",
      "Epoch: 6 | Iteration: 231 | Classification loss: 0.24095 | Regression loss: 0.56011 | Running loss: 0.81079\n",
      "Epoch: 6 | Iteration: 232 | Classification loss: 0.30055 | Regression loss: 0.63760 | Running loss: 0.81107\n",
      "Epoch: 6 | Iteration: 233 | Classification loss: 0.17002 | Regression loss: 0.53516 | Running loss: 0.81009\n",
      "Epoch: 6 | Iteration: 234 | Classification loss: 0.25582 | Regression loss: 0.60103 | Running loss: 0.81042\n",
      "Epoch: 6 | Iteration: 235 | Classification loss: 0.22002 | Regression loss: 0.46091 | Running loss: 0.81001\n",
      "Epoch: 6 | Iteration: 236 | Classification loss: 0.21145 | Regression loss: 0.48539 | Running loss: 0.81020\n",
      "Epoch: 6 | Iteration: 237 | Classification loss: 0.35156 | Regression loss: 0.34887 | Running loss: 0.80980\n",
      "Epoch: 6 | Iteration: 238 | Classification loss: 0.20210 | Regression loss: 0.55308 | Running loss: 0.80952\n",
      "Epoch: 6 | Iteration: 239 | Classification loss: 0.21282 | Regression loss: 0.53272 | Running loss: 0.80926\n",
      "Epoch: 6 | Iteration: 240 | Classification loss: 0.18781 | Regression loss: 0.33173 | Running loss: 0.80932\n",
      "Epoch: 6 | Iteration: 241 | Classification loss: 0.17303 | Regression loss: 0.51791 | Running loss: 0.80899\n",
      "Epoch: 6 | Iteration: 242 | Classification loss: 0.29101 | Regression loss: 0.52286 | Running loss: 0.80908\n",
      "Epoch: 6 | Iteration: 243 | Classification loss: 0.25685 | Regression loss: 0.57257 | Running loss: 0.80924\n",
      "Epoch: 6 | Iteration: 244 | Classification loss: 0.26691 | Regression loss: 0.45339 | Running loss: 0.80890\n",
      "Epoch: 6 | Iteration: 245 | Classification loss: 0.26361 | Regression loss: 0.55762 | Running loss: 0.80860\n",
      "Epoch: 6 | Iteration: 246 | Classification loss: 0.25573 | Regression loss: 0.50221 | Running loss: 0.80927\n",
      "Epoch: 6 | Iteration: 247 | Classification loss: 0.21545 | Regression loss: 0.44274 | Running loss: 0.80869\n",
      "Epoch: 6 | Iteration: 248 | Classification loss: 0.21744 | Regression loss: 0.56428 | Running loss: 0.80840\n",
      "Epoch: 6 | Iteration: 249 | Classification loss: 0.13265 | Regression loss: 0.34579 | Running loss: 0.80788\n",
      "Epoch: 6 | Iteration: 250 | Classification loss: 0.25317 | Regression loss: 0.53750 | Running loss: 0.80753\n",
      "Epoch: 6 | Iteration: 251 | Classification loss: 0.23247 | Regression loss: 0.51863 | Running loss: 0.80723\n",
      "Epoch: 6 | Iteration: 252 | Classification loss: 0.34235 | Regression loss: 0.74263 | Running loss: 0.80773\n",
      "Epoch: 6 | Iteration: 253 | Classification loss: 0.23708 | Regression loss: 0.50804 | Running loss: 0.80787\n",
      "Epoch: 6 | Iteration: 254 | Classification loss: 0.23968 | Regression loss: 0.52291 | Running loss: 0.80785\n",
      "Epoch: 6 | Iteration: 255 | Classification loss: 0.28641 | Regression loss: 0.59494 | Running loss: 0.80850\n",
      "Epoch: 6 | Iteration: 256 | Classification loss: 0.24691 | Regression loss: 0.39335 | Running loss: 0.80837\n",
      "Epoch: 6 | Iteration: 257 | Classification loss: 0.20446 | Regression loss: 0.53553 | Running loss: 0.80820\n",
      "Epoch: 6 | Iteration: 258 | Classification loss: 0.21836 | Regression loss: 0.49282 | Running loss: 0.80839\n",
      "Epoch: 6 | Iteration: 259 | Classification loss: 0.16112 | Regression loss: 0.34927 | Running loss: 0.80818\n",
      "Epoch: 6 | Iteration: 260 | Classification loss: 0.23120 | Regression loss: 0.59590 | Running loss: 0.80814\n",
      "Epoch: 6 | Iteration: 261 | Classification loss: 0.30815 | Regression loss: 0.64587 | Running loss: 0.80824\n",
      "Epoch: 6 | Iteration: 262 | Classification loss: 0.28090 | Regression loss: 0.51395 | Running loss: 0.80778\n",
      "Epoch: 6 | Iteration: 263 | Classification loss: 0.24325 | Regression loss: 0.56021 | Running loss: 0.80785\n",
      "Epoch: 6 | Iteration: 264 | Classification loss: 0.25836 | Regression loss: 0.56451 | Running loss: 0.80852\n",
      "Epoch: 6 | Iteration: 265 | Classification loss: 0.21288 | Regression loss: 0.48080 | Running loss: 0.80855\n",
      "Epoch: 6 | Iteration: 266 | Classification loss: 0.53380 | Regression loss: 0.31072 | Running loss: 0.80837\n",
      "Epoch: 6 | Iteration: 267 | Classification loss: 0.24903 | Regression loss: 0.56844 | Running loss: 0.80835\n",
      "Epoch: 6 | Iteration: 268 | Classification loss: 0.20910 | Regression loss: 0.52680 | Running loss: 0.80738\n",
      "Epoch: 6 | Iteration: 269 | Classification loss: 0.21939 | Regression loss: 0.48257 | Running loss: 0.80692\n",
      "Epoch: 6 | Iteration: 270 | Classification loss: 0.21622 | Regression loss: 0.72442 | Running loss: 0.80722\n",
      "Epoch: 6 | Iteration: 271 | Classification loss: 0.26807 | Regression loss: 0.62281 | Running loss: 0.80744\n",
      "Epoch: 6 | Iteration: 272 | Classification loss: 0.26913 | Regression loss: 0.58532 | Running loss: 0.80741\n",
      "Epoch: 6 | Iteration: 273 | Classification loss: 0.25056 | Regression loss: 0.48967 | Running loss: 0.80735\n",
      "Epoch: 6 | Iteration: 274 | Classification loss: 0.25091 | Regression loss: 0.62567 | Running loss: 0.80748\n",
      "Epoch: 6 | Iteration: 275 | Classification loss: 0.31626 | Regression loss: 0.66692 | Running loss: 0.80724\n",
      "Epoch: 6 | Iteration: 276 | Classification loss: 0.28605 | Regression loss: 0.61531 | Running loss: 0.80753\n",
      "Epoch: 6 | Iteration: 277 | Classification loss: 0.12068 | Regression loss: 0.31990 | Running loss: 0.80717\n",
      "Epoch: 6 | Iteration: 278 | Classification loss: 0.21033 | Regression loss: 0.42989 | Running loss: 0.80721\n",
      "Epoch: 6 | Iteration: 279 | Classification loss: 0.30199 | Regression loss: 0.58796 | Running loss: 0.80734\n",
      "Epoch: 6 | Iteration: 280 | Classification loss: 0.20111 | Regression loss: 0.54818 | Running loss: 0.80686\n",
      "Epoch: 6 | Iteration: 281 | Classification loss: 0.20382 | Regression loss: 0.44961 | Running loss: 0.80683\n",
      "Epoch: 6 | Iteration: 282 | Classification loss: 0.26596 | Regression loss: 0.58611 | Running loss: 0.80629\n",
      "Epoch: 6 | Iteration: 283 | Classification loss: 0.39746 | Regression loss: 0.62773 | Running loss: 0.80657\n",
      "Epoch: 6 | Iteration: 284 | Classification loss: 0.32233 | Regression loss: 0.75723 | Running loss: 0.80703\n",
      "Epoch: 6 | Iteration: 285 | Classification loss: 0.18330 | Regression loss: 0.37937 | Running loss: 0.80683\n",
      "Epoch: 6 | Iteration: 286 | Classification loss: 0.28966 | Regression loss: 0.26157 | Running loss: 0.80681\n",
      "Epoch: 6 | Iteration: 287 | Classification loss: 0.20837 | Regression loss: 0.53241 | Running loss: 0.80658\n",
      "Epoch: 6 | Iteration: 288 | Classification loss: 0.17772 | Regression loss: 0.54274 | Running loss: 0.80645\n",
      "Epoch: 6 | Iteration: 289 | Classification loss: 0.35129 | Regression loss: 0.80026 | Running loss: 0.80703\n",
      "Epoch: 6 | Iteration: 290 | Classification loss: 0.21700 | Regression loss: 0.39677 | Running loss: 0.80637\n",
      "Epoch: 6 | Iteration: 291 | Classification loss: 0.26222 | Regression loss: 0.45971 | Running loss: 0.80620\n",
      "Epoch: 6 | Iteration: 292 | Classification loss: 0.16454 | Regression loss: 0.41762 | Running loss: 0.80575\n",
      "Epoch: 6 | Iteration: 293 | Classification loss: 0.15385 | Regression loss: 0.43827 | Running loss: 0.80525\n",
      "Epoch: 6 | Iteration: 294 | Classification loss: 0.32140 | Regression loss: 0.76326 | Running loss: 0.80553\n",
      "Epoch: 6 | Iteration: 295 | Classification loss: 0.17412 | Regression loss: 0.49924 | Running loss: 0.80540\n",
      "Epoch: 6 | Iteration: 296 | Classification loss: 0.15189 | Regression loss: 0.44264 | Running loss: 0.80574\n",
      "Epoch: 6 | Iteration: 297 | Classification loss: 0.24012 | Regression loss: 0.49730 | Running loss: 0.80587\n",
      "Epoch: 6 | Iteration: 298 | Classification loss: 0.20643 | Regression loss: 0.51471 | Running loss: 0.80541\n",
      "Epoch: 6 | Iteration: 299 | Classification loss: 0.22131 | Regression loss: 0.61725 | Running loss: 0.80558\n",
      "Epoch: 6 | Iteration: 300 | Classification loss: 0.26059 | Regression loss: 0.63987 | Running loss: 0.80573\n",
      "Epoch: 6 | Iteration: 301 | Classification loss: 0.19217 | Regression loss: 0.50052 | Running loss: 0.80482\n",
      "Epoch: 6 | Iteration: 302 | Classification loss: 0.28395 | Regression loss: 0.58974 | Running loss: 0.80480\n",
      "Epoch: 6 | Iteration: 303 | Classification loss: 0.22690 | Regression loss: 0.47941 | Running loss: 0.80442\n",
      "Epoch: 6 | Iteration: 304 | Classification loss: 0.24018 | Regression loss: 0.67674 | Running loss: 0.80453\n",
      "Epoch: 6 | Iteration: 305 | Classification loss: 0.22597 | Regression loss: 0.49142 | Running loss: 0.80417\n",
      "Epoch: 6 | Iteration: 306 | Classification loss: 0.22194 | Regression loss: 0.48243 | Running loss: 0.80401\n",
      "Epoch: 6 | Iteration: 307 | Classification loss: 0.19785 | Regression loss: 0.50896 | Running loss: 0.80411\n",
      "Epoch: 6 | Iteration: 308 | Classification loss: 0.16201 | Regression loss: 0.42964 | Running loss: 0.80346\n",
      "Epoch: 6 | Iteration: 309 | Classification loss: 0.25816 | Regression loss: 0.62950 | Running loss: 0.80349\n",
      "Epoch: 6 | Iteration: 310 | Classification loss: 0.21574 | Regression loss: 0.53764 | Running loss: 0.80308\n",
      "Epoch: 6 | Iteration: 311 | Classification loss: 0.21202 | Regression loss: 0.53329 | Running loss: 0.80262\n",
      "Epoch: 6 | Iteration: 312 | Classification loss: 0.28132 | Regression loss: 0.56666 | Running loss: 0.80264\n",
      "Epoch: 6 | Iteration: 313 | Classification loss: 0.13054 | Regression loss: 0.45829 | Running loss: 0.80273\n",
      "Epoch: 6 | Iteration: 314 | Classification loss: 0.38877 | Regression loss: 0.70958 | Running loss: 0.80341\n",
      "Epoch: 6 | Iteration: 315 | Classification loss: 0.30455 | Regression loss: 0.50003 | Running loss: 0.80323\n",
      "Epoch: 6 | Iteration: 316 | Classification loss: 0.21965 | Regression loss: 0.47909 | Running loss: 0.80274\n",
      "Epoch: 6 | Iteration: 317 | Classification loss: 0.32599 | Regression loss: 0.57049 | Running loss: 0.80304\n",
      "Epoch: 6 | Iteration: 318 | Classification loss: 0.15025 | Regression loss: 0.45248 | Running loss: 0.80253\n",
      "Epoch: 6 | Iteration: 319 | Classification loss: 0.24368 | Regression loss: 0.59642 | Running loss: 0.80230\n",
      "Epoch: 6 | Iteration: 320 | Classification loss: 0.31459 | Regression loss: 0.60356 | Running loss: 0.80180\n",
      "Epoch: 6 | Iteration: 321 | Classification loss: 0.32704 | Regression loss: 0.62170 | Running loss: 0.80250\n",
      "Epoch: 6 | Iteration: 322 | Classification loss: 0.25790 | Regression loss: 0.66516 | Running loss: 0.80312\n",
      "Epoch: 6 | Iteration: 323 | Classification loss: 0.23945 | Regression loss: 0.55932 | Running loss: 0.80315\n",
      "Epoch: 6 | Iteration: 324 | Classification loss: 0.25748 | Regression loss: 0.40910 | Running loss: 0.80334\n",
      "Epoch: 6 | Iteration: 325 | Classification loss: 0.23858 | Regression loss: 0.57666 | Running loss: 0.80340\n",
      "Epoch: 6 | Iteration: 326 | Classification loss: 0.22242 | Regression loss: 0.62880 | Running loss: 0.80356\n",
      "Epoch: 6 | Iteration: 327 | Classification loss: 0.22378 | Regression loss: 0.53864 | Running loss: 0.80336\n",
      "Epoch: 6 | Iteration: 328 | Classification loss: 0.28479 | Regression loss: 0.47680 | Running loss: 0.80308\n",
      "Epoch: 6 | Iteration: 329 | Classification loss: 0.34604 | Regression loss: 0.64728 | Running loss: 0.80340\n",
      "Epoch: 6 | Iteration: 330 | Classification loss: 0.17310 | Regression loss: 0.44795 | Running loss: 0.80281\n",
      "Epoch: 6 | Iteration: 331 | Classification loss: 0.36350 | Regression loss: 0.70082 | Running loss: 0.80307\n",
      "Epoch: 6 | Iteration: 332 | Classification loss: 0.34473 | Regression loss: 0.68562 | Running loss: 0.80324\n",
      "Epoch: 6 | Iteration: 333 | Classification loss: 0.23438 | Regression loss: 0.50736 | Running loss: 0.80274\n",
      "Epoch: 6 | Iteration: 334 | Classification loss: 0.30669 | Regression loss: 0.57142 | Running loss: 0.80324\n",
      "Epoch: 6 | Iteration: 335 | Classification loss: 0.18881 | Regression loss: 0.46958 | Running loss: 0.80249\n",
      "Epoch: 6 | Iteration: 336 | Classification loss: 0.17263 | Regression loss: 0.41324 | Running loss: 0.80188\n",
      "Epoch: 6 | Iteration: 337 | Classification loss: 0.18367 | Regression loss: 0.43348 | Running loss: 0.80122\n",
      "Epoch: 6 | Iteration: 338 | Classification loss: 0.24683 | Regression loss: 0.64109 | Running loss: 0.80149\n",
      "Epoch: 6 | Iteration: 339 | Classification loss: 0.18790 | Regression loss: 0.53316 | Running loss: 0.80120\n",
      "Epoch: 6 | Iteration: 340 | Classification loss: 0.34233 | Regression loss: 0.67963 | Running loss: 0.80129\n",
      "Epoch: 6 | Iteration: 341 | Classification loss: 0.22699 | Regression loss: 0.42886 | Running loss: 0.80074\n",
      "Epoch: 6 | Iteration: 342 | Classification loss: 0.19207 | Regression loss: 0.40235 | Running loss: 0.80058\n",
      "Epoch: 6 | Iteration: 343 | Classification loss: 0.27969 | Regression loss: 0.56870 | Running loss: 0.80089\n",
      "Epoch: 6 | Iteration: 344 | Classification loss: 0.23102 | Regression loss: 0.54237 | Running loss: 0.80100\n",
      "Epoch: 6 | Iteration: 345 | Classification loss: 0.27110 | Regression loss: 0.62089 | Running loss: 0.80094\n",
      "Epoch: 6 | Iteration: 346 | Classification loss: 0.26839 | Regression loss: 0.55541 | Running loss: 0.80078\n",
      "Epoch: 6 | Iteration: 347 | Classification loss: 0.27736 | Regression loss: 0.57127 | Running loss: 0.80077\n",
      "Epoch: 6 | Iteration: 348 | Classification loss: 0.27131 | Regression loss: 0.60134 | Running loss: 0.80044\n",
      "Epoch: 6 | Iteration: 349 | Classification loss: 0.23394 | Regression loss: 0.56862 | Running loss: 0.79976\n",
      "Epoch: 6 | Iteration: 350 | Classification loss: 0.25949 | Regression loss: 0.62039 | Running loss: 0.79932\n",
      "Epoch: 6 | Iteration: 351 | Classification loss: 0.27833 | Regression loss: 0.64934 | Running loss: 0.79989\n",
      "Epoch: 6 | Iteration: 352 | Classification loss: 0.21454 | Regression loss: 0.48108 | Running loss: 0.79962\n",
      "Epoch: 6 | Iteration: 353 | Classification loss: 0.17014 | Regression loss: 0.42513 | Running loss: 0.79921\n",
      "Epoch: 6 | Iteration: 354 | Classification loss: 0.19314 | Regression loss: 0.48689 | Running loss: 0.79864\n",
      "Epoch: 6 | Iteration: 355 | Classification loss: 0.32073 | Regression loss: 0.51380 | Running loss: 0.79859\n",
      "Epoch: 6 | Iteration: 356 | Classification loss: 0.25858 | Regression loss: 0.59480 | Running loss: 0.79813\n",
      "Epoch: 6 | Iteration: 357 | Classification loss: 0.27946 | Regression loss: 0.56806 | Running loss: 0.79855\n",
      "Epoch: 6 | Iteration: 358 | Classification loss: 0.21319 | Regression loss: 0.45031 | Running loss: 0.79850\n",
      "Epoch: 6 | Iteration: 359 | Classification loss: 0.28768 | Regression loss: 0.73691 | Running loss: 0.79864\n",
      "Epoch: 6 | Iteration: 360 | Classification loss: 0.20223 | Regression loss: 0.55539 | Running loss: 0.79880\n",
      "Epoch: 6 | Iteration: 361 | Classification loss: 0.12784 | Regression loss: 0.28256 | Running loss: 0.79838\n",
      "Epoch: 6 | Iteration: 362 | Classification loss: 0.25974 | Regression loss: 0.35531 | Running loss: 0.79798\n",
      "Epoch: 6 | Iteration: 363 | Classification loss: 0.28245 | Regression loss: 0.55954 | Running loss: 0.79782\n",
      "Epoch: 6 | Iteration: 364 | Classification loss: 0.28474 | Regression loss: 0.62331 | Running loss: 0.79798\n",
      "Epoch: 6 | Iteration: 365 | Classification loss: 0.34414 | Regression loss: 0.49060 | Running loss: 0.79823\n",
      "Epoch: 6 | Iteration: 366 | Classification loss: 0.34014 | Regression loss: 0.60770 | Running loss: 0.79861\n",
      "Epoch: 6 | Iteration: 367 | Classification loss: 0.19122 | Regression loss: 0.45308 | Running loss: 0.79849\n",
      "Epoch: 6 | Iteration: 368 | Classification loss: 0.25889 | Regression loss: 0.57542 | Running loss: 0.79840\n",
      "Epoch: 6 | Iteration: 369 | Classification loss: 0.20852 | Regression loss: 0.57507 | Running loss: 0.79845\n",
      "Epoch: 6 | Iteration: 370 | Classification loss: 0.22612 | Regression loss: 0.45805 | Running loss: 0.79735\n",
      "Epoch: 6 | Iteration: 371 | Classification loss: 0.25345 | Regression loss: 0.60316 | Running loss: 0.79747\n",
      "Epoch: 6 | Iteration: 372 | Classification loss: 0.27945 | Regression loss: 0.70868 | Running loss: 0.79742\n",
      "Epoch: 6 | Iteration: 373 | Classification loss: 0.26821 | Regression loss: 0.51825 | Running loss: 0.79723\n",
      "Epoch: 6 | Iteration: 374 | Classification loss: 0.26326 | Regression loss: 0.53274 | Running loss: 0.79719\n",
      "Epoch: 6 | Iteration: 375 | Classification loss: 0.15384 | Regression loss: 0.56158 | Running loss: 0.79719\n",
      "Epoch: 6 | Iteration: 376 | Classification loss: 0.29208 | Regression loss: 0.57737 | Running loss: 0.79718\n",
      "Epoch: 6 | Iteration: 377 | Classification loss: 0.25582 | Regression loss: 0.49594 | Running loss: 0.79717\n",
      "Epoch: 6 | Iteration: 378 | Classification loss: 0.24641 | Regression loss: 0.55837 | Running loss: 0.79700\n",
      "Epoch: 6 | Iteration: 379 | Classification loss: 0.24240 | Regression loss: 0.59288 | Running loss: 0.79709\n",
      "Epoch: 6 | Iteration: 380 | Classification loss: 0.19348 | Regression loss: 0.47289 | Running loss: 0.79657\n",
      "Epoch: 6 | Iteration: 381 | Classification loss: 0.28201 | Regression loss: 0.62337 | Running loss: 0.79634\n",
      "Epoch: 6 | Iteration: 382 | Classification loss: 0.21257 | Regression loss: 0.59427 | Running loss: 0.79644\n",
      "Epoch: 6 | Iteration: 383 | Classification loss: 0.14967 | Regression loss: 0.36023 | Running loss: 0.79594\n",
      "Epoch: 6 | Iteration: 384 | Classification loss: 0.17831 | Regression loss: 0.50593 | Running loss: 0.79534\n",
      "Epoch: 6 | Iteration: 385 | Classification loss: 0.27009 | Regression loss: 0.58928 | Running loss: 0.79541\n",
      "Epoch: 6 | Iteration: 386 | Classification loss: 0.29063 | Regression loss: 0.72579 | Running loss: 0.79602\n",
      "Epoch: 6 | Iteration: 387 | Classification loss: 0.27778 | Regression loss: 0.54651 | Running loss: 0.79575\n",
      "Epoch: 6 | Iteration: 388 | Classification loss: 0.14051 | Regression loss: 0.35005 | Running loss: 0.79523\n",
      "Epoch: 6 | Iteration: 389 | Classification loss: 0.21682 | Regression loss: 0.58643 | Running loss: 0.79503\n",
      "Epoch: 6 | Iteration: 390 | Classification loss: 0.25196 | Regression loss: 0.52835 | Running loss: 0.79500\n",
      "Epoch: 6 | Iteration: 391 | Classification loss: 0.16396 | Regression loss: 0.41794 | Running loss: 0.79489\n",
      "Epoch: 6 | Iteration: 392 | Classification loss: 0.11968 | Regression loss: 0.35207 | Running loss: 0.79424\n",
      "Epoch: 6 | Iteration: 393 | Classification loss: 0.26434 | Regression loss: 0.62051 | Running loss: 0.79426\n",
      "Epoch: 6 | Iteration: 394 | Classification loss: 0.21876 | Regression loss: 0.45070 | Running loss: 0.79385\n",
      "Epoch: 6 | Iteration: 395 | Classification loss: 0.44411 | Regression loss: 0.47437 | Running loss: 0.79430\n",
      "Epoch: 6 | Iteration: 396 | Classification loss: 0.18242 | Regression loss: 0.36372 | Running loss: 0.79379\n",
      "Epoch: 6 | Iteration: 397 | Classification loss: 0.30622 | Regression loss: 0.71284 | Running loss: 0.79429\n",
      "Epoch: 6 | Iteration: 398 | Classification loss: 0.22387 | Regression loss: 0.54273 | Running loss: 0.79435\n",
      "Epoch: 6 | Iteration: 399 | Classification loss: 0.17784 | Regression loss: 0.43806 | Running loss: 0.79424\n",
      "Epoch: 6 | Iteration: 400 | Classification loss: 0.32553 | Regression loss: 0.65982 | Running loss: 0.79439\n",
      "Epoch: 6 | Iteration: 401 | Classification loss: 0.25838 | Regression loss: 0.64195 | Running loss: 0.79464\n",
      "Epoch: 6 | Iteration: 402 | Classification loss: 0.26016 | Regression loss: 0.51522 | Running loss: 0.79464\n",
      "Epoch: 6 | Iteration: 403 | Classification loss: 0.13526 | Regression loss: 0.28559 | Running loss: 0.79346\n",
      "Epoch: 6 | Iteration: 404 | Classification loss: 0.24887 | Regression loss: 0.55072 | Running loss: 0.79370\n",
      "Epoch: 6 | Iteration: 405 | Classification loss: 0.20304 | Regression loss: 0.39554 | Running loss: 0.79301\n",
      "Epoch: 6 | Iteration: 406 | Classification loss: 0.19956 | Regression loss: 0.58003 | Running loss: 0.79321\n",
      "Epoch: 6 | Iteration: 407 | Classification loss: 0.20317 | Regression loss: 0.46873 | Running loss: 0.79281\n",
      "Epoch: 6 | Iteration: 408 | Classification loss: 0.22569 | Regression loss: 0.48411 | Running loss: 0.79282\n",
      "Epoch: 6 | Iteration: 409 | Classification loss: 0.16418 | Regression loss: 0.42049 | Running loss: 0.79226\n",
      "Epoch: 6 | Iteration: 410 | Classification loss: 0.25671 | Regression loss: 0.43497 | Running loss: 0.79240\n",
      "Epoch: 6 | Iteration: 411 | Classification loss: 0.29001 | Regression loss: 0.58095 | Running loss: 0.79212\n",
      "Epoch: 6 | Iteration: 412 | Classification loss: 0.25115 | Regression loss: 0.59144 | Running loss: 0.79195\n",
      "Epoch: 6 | Iteration: 413 | Classification loss: 0.13571 | Regression loss: 0.43865 | Running loss: 0.79160\n",
      "Epoch: 6 | Iteration: 414 | Classification loss: 0.23444 | Regression loss: 0.57602 | Running loss: 0.79140\n",
      "Epoch: 6 | Iteration: 415 | Classification loss: 0.30871 | Regression loss: 0.64585 | Running loss: 0.79170\n",
      "Epoch: 6 | Iteration: 416 | Classification loss: 0.21641 | Regression loss: 0.32722 | Running loss: 0.79177\n",
      "Epoch: 6 | Iteration: 417 | Classification loss: 0.21450 | Regression loss: 0.53410 | Running loss: 0.79098\n",
      "Epoch: 6 | Iteration: 418 | Classification loss: 0.23083 | Regression loss: 0.51524 | Running loss: 0.79094\n",
      "Epoch: 6 | Iteration: 419 | Classification loss: 0.28481 | Regression loss: 0.61140 | Running loss: 0.79124\n",
      "Epoch: 6 | Iteration: 420 | Classification loss: 0.32154 | Regression loss: 0.72208 | Running loss: 0.79213\n",
      "Epoch: 6 | Iteration: 421 | Classification loss: 0.20539 | Regression loss: 0.57192 | Running loss: 0.79165\n",
      "Epoch: 6 | Iteration: 422 | Classification loss: 0.18311 | Regression loss: 0.42556 | Running loss: 0.79082\n",
      "Epoch: 6 | Iteration: 423 | Classification loss: 0.16845 | Regression loss: 0.37672 | Running loss: 0.79029\n",
      "Epoch: 6 | Iteration: 424 | Classification loss: 0.57261 | Regression loss: 0.58262 | Running loss: 0.79106\n",
      "Epoch: 6 | Iteration: 425 | Classification loss: 0.16782 | Regression loss: 0.48024 | Running loss: 0.79047\n",
      "Epoch: 6 | Iteration: 426 | Classification loss: 0.28869 | Regression loss: 0.40741 | Running loss: 0.79061\n",
      "Epoch: 6 | Iteration: 427 | Classification loss: 0.18407 | Regression loss: 0.48610 | Running loss: 0.79016\n",
      "Epoch: 6 | Iteration: 428 | Classification loss: 0.18734 | Regression loss: 0.53315 | Running loss: 0.79003\n",
      "Epoch: 6 | Iteration: 429 | Classification loss: 0.14546 | Regression loss: 0.35383 | Running loss: 0.78953\n",
      "Epoch: 6 | Iteration: 430 | Classification loss: 0.28381 | Regression loss: 0.54285 | Running loss: 0.78915\n",
      "Epoch: 6 | Iteration: 431 | Classification loss: 0.18851 | Regression loss: 0.44215 | Running loss: 0.78826\n",
      "Epoch: 6 | Iteration: 432 | Classification loss: 0.25443 | Regression loss: 0.52261 | Running loss: 0.78797\n",
      "Epoch: 6 | Iteration: 433 | Classification loss: 0.09207 | Regression loss: 0.30032 | Running loss: 0.78655\n",
      "Epoch: 6 | Iteration: 434 | Classification loss: 0.20050 | Regression loss: 0.42782 | Running loss: 0.78635\n",
      "Epoch: 6 | Iteration: 435 | Classification loss: 0.13198 | Regression loss: 0.44962 | Running loss: 0.78575\n",
      "Epoch: 6 | Iteration: 436 | Classification loss: 0.22768 | Regression loss: 0.54453 | Running loss: 0.78513\n",
      "Epoch: 6 | Iteration: 437 | Classification loss: 0.19965 | Regression loss: 0.55687 | Running loss: 0.78488\n",
      "Epoch: 6 | Iteration: 438 | Classification loss: 0.24709 | Regression loss: 0.61198 | Running loss: 0.78476\n",
      "Epoch: 6 | Iteration: 439 | Classification loss: 0.23439 | Regression loss: 0.54909 | Running loss: 0.78469\n",
      "Epoch: 6 | Iteration: 440 | Classification loss: 0.27835 | Regression loss: 0.57578 | Running loss: 0.78479\n",
      "Epoch: 6 | Iteration: 441 | Classification loss: 0.27574 | Regression loss: 0.61478 | Running loss: 0.78492\n",
      "Epoch: 6 | Iteration: 442 | Classification loss: 0.30228 | Regression loss: 0.65662 | Running loss: 0.78539\n",
      "Epoch: 6 | Iteration: 443 | Classification loss: 0.32664 | Regression loss: 0.57776 | Running loss: 0.78546\n",
      "Epoch: 6 | Iteration: 444 | Classification loss: 0.25349 | Regression loss: 0.50632 | Running loss: 0.78553\n",
      "Epoch: 6 | Iteration: 445 | Classification loss: 0.15204 | Regression loss: 0.45151 | Running loss: 0.78513\n",
      "Epoch: 6 | Iteration: 446 | Classification loss: 0.18349 | Regression loss: 0.47803 | Running loss: 0.78498\n",
      "Epoch: 6 | Iteration: 447 | Classification loss: 0.19050 | Regression loss: 0.51020 | Running loss: 0.78518\n",
      "Epoch: 6 | Iteration: 448 | Classification loss: 0.27936 | Regression loss: 0.61849 | Running loss: 0.78526\n",
      "Epoch: 6 | Iteration: 449 | Classification loss: 0.30548 | Regression loss: 0.63519 | Running loss: 0.78552\n",
      "Epoch: 6 | Iteration: 450 | Classification loss: 0.27812 | Regression loss: 0.59446 | Running loss: 0.78550\n",
      "Epoch: 6 | Iteration: 451 | Classification loss: 0.20147 | Regression loss: 0.43955 | Running loss: 0.78532\n",
      "Epoch: 6 | Iteration: 452 | Classification loss: 0.19780 | Regression loss: 0.45886 | Running loss: 0.78525\n",
      "Epoch: 6 | Iteration: 453 | Classification loss: 0.33561 | Regression loss: 0.68948 | Running loss: 0.78612\n",
      "Epoch: 6 | Iteration: 454 | Classification loss: 0.26823 | Regression loss: 0.57744 | Running loss: 0.78596\n",
      "Epoch: 6 | Iteration: 455 | Classification loss: 0.22298 | Regression loss: 0.48208 | Running loss: 0.78534\n",
      "Epoch: 6 | Iteration: 456 | Classification loss: 0.17753 | Regression loss: 0.43378 | Running loss: 0.78492\n",
      "Epoch: 6 | Iteration: 457 | Classification loss: 0.23101 | Regression loss: 0.59004 | Running loss: 0.78523\n",
      "Epoch: 6 | Iteration: 458 | Classification loss: 0.17546 | Regression loss: 0.40110 | Running loss: 0.78516\n",
      "Epoch: 6 | Iteration: 459 | Classification loss: 0.21607 | Regression loss: 0.51397 | Running loss: 0.78509\n",
      "Epoch: 6 | Iteration: 460 | Classification loss: 0.15964 | Regression loss: 0.50459 | Running loss: 0.78434\n",
      "Epoch: 6 | Iteration: 461 | Classification loss: 0.14684 | Regression loss: 0.38691 | Running loss: 0.78329\n",
      "Epoch: 6 | Iteration: 462 | Classification loss: 0.17141 | Regression loss: 0.34605 | Running loss: 0.78299\n",
      "Epoch: 6 | Iteration: 463 | Classification loss: 0.22847 | Regression loss: 0.59764 | Running loss: 0.78276\n",
      "Epoch: 6 | Iteration: 464 | Classification loss: 0.20094 | Regression loss: 0.53282 | Running loss: 0.78209\n",
      "Epoch: 6 | Iteration: 465 | Classification loss: 0.23938 | Regression loss: 0.43243 | Running loss: 0.78183\n",
      "Epoch: 6 | Iteration: 466 | Classification loss: 0.24775 | Regression loss: 0.57129 | Running loss: 0.78155\n",
      "Epoch: 6 | Iteration: 467 | Classification loss: 0.23816 | Regression loss: 0.51997 | Running loss: 0.78201\n",
      "Epoch: 6 | Iteration: 468 | Classification loss: 0.26349 | Regression loss: 0.60533 | Running loss: 0.78232\n",
      "Epoch: 6 | Iteration: 469 | Classification loss: 0.30151 | Regression loss: 0.56890 | Running loss: 0.78275\n",
      "Epoch: 6 | Iteration: 470 | Classification loss: 0.22554 | Regression loss: 0.53760 | Running loss: 0.78267\n",
      "Epoch: 6 | Iteration: 471 | Classification loss: 0.21694 | Regression loss: 0.57366 | Running loss: 0.78320\n",
      "Epoch: 6 | Iteration: 472 | Classification loss: 0.26573 | Regression loss: 0.64392 | Running loss: 0.78333\n",
      "Epoch: 6 | Iteration: 473 | Classification loss: 0.19849 | Regression loss: 0.55949 | Running loss: 0.78304\n",
      "Epoch: 6 | Iteration: 474 | Classification loss: 0.22189 | Regression loss: 0.34885 | Running loss: 0.78258\n",
      "Epoch: 6 | Iteration: 475 | Classification loss: 0.17346 | Regression loss: 0.50384 | Running loss: 0.78209\n",
      "Epoch: 6 | Iteration: 476 | Classification loss: 0.21652 | Regression loss: 0.58937 | Running loss: 0.78228\n",
      "Epoch: 6 | Iteration: 477 | Classification loss: 0.17581 | Regression loss: 0.39459 | Running loss: 0.78158\n",
      "Epoch: 6 | Iteration: 478 | Classification loss: 0.18268 | Regression loss: 0.46759 | Running loss: 0.78133\n",
      "Epoch: 6 | Iteration: 479 | Classification loss: 0.28130 | Regression loss: 0.63378 | Running loss: 0.78130\n",
      "Epoch: 6 | Iteration: 480 | Classification loss: 0.30545 | Regression loss: 0.49457 | Running loss: 0.78106\n",
      "Epoch: 6 | Iteration: 481 | Classification loss: 0.26595 | Regression loss: 0.54330 | Running loss: 0.78067\n",
      "Epoch: 6 | Iteration: 482 | Classification loss: 0.50290 | Regression loss: 0.54035 | Running loss: 0.78092\n",
      "Epoch: 6 | Iteration: 483 | Classification loss: 0.19302 | Regression loss: 0.53790 | Running loss: 0.78051\n",
      "Epoch: 6 | Iteration: 484 | Classification loss: 0.13411 | Regression loss: 0.34673 | Running loss: 0.77994\n",
      "Epoch: 6 | Iteration: 485 | Classification loss: 0.24834 | Regression loss: 0.51072 | Running loss: 0.77960\n",
      "Epoch: 6 | Iteration: 486 | Classification loss: 0.23986 | Regression loss: 0.51836 | Running loss: 0.77933\n",
      "Epoch: 6 | Iteration: 487 | Classification loss: 0.22721 | Regression loss: 0.48411 | Running loss: 0.77882\n",
      "Epoch: 6 | Iteration: 488 | Classification loss: 0.24288 | Regression loss: 0.55912 | Running loss: 0.77888\n",
      "Epoch: 6 | Iteration: 489 | Classification loss: 0.27945 | Regression loss: 0.60574 | Running loss: 0.77873\n",
      "Epoch: 6 | Iteration: 490 | Classification loss: 0.22434 | Regression loss: 0.58384 | Running loss: 0.77820\n",
      "Epoch: 6 | Iteration: 491 | Classification loss: 0.24315 | Regression loss: 0.63267 | Running loss: 0.77820\n",
      "Epoch: 6 | Iteration: 492 | Classification loss: 0.28835 | Regression loss: 0.65408 | Running loss: 0.77864\n",
      "Epoch: 6 | Iteration: 493 | Classification loss: 0.29758 | Regression loss: 0.65387 | Running loss: 0.77870\n",
      "Epoch: 6 | Iteration: 494 | Classification loss: 0.20638 | Regression loss: 0.49393 | Running loss: 0.77801\n",
      "Epoch: 6 | Iteration: 495 | Classification loss: 0.48159 | Regression loss: 0.55003 | Running loss: 0.77853\n",
      "Epoch: 6 | Iteration: 496 | Classification loss: 0.22150 | Regression loss: 0.53790 | Running loss: 0.77859\n",
      "Epoch: 6 | Iteration: 497 | Classification loss: 0.23249 | Regression loss: 0.44826 | Running loss: 0.77874\n",
      "Epoch: 6 | Iteration: 498 | Classification loss: 0.18167 | Regression loss: 0.39314 | Running loss: 0.77794\n",
      "Epoch: 6 | Iteration: 499 | Classification loss: 0.23111 | Regression loss: 0.54676 | Running loss: 0.77754\n",
      "Epoch: 6 | Iteration: 500 | Classification loss: 0.23067 | Regression loss: 0.63038 | Running loss: 0.77816\n",
      "Epoch: 6 | Iteration: 501 | Classification loss: 0.36636 | Regression loss: 0.84009 | Running loss: 0.77884\n",
      "Epoch: 6 | Iteration: 502 | Classification loss: 0.20148 | Regression loss: 0.57296 | Running loss: 0.77869\n",
      "Epoch: 6 | Iteration: 503 | Classification loss: 0.29998 | Regression loss: 0.56990 | Running loss: 0.77888\n",
      "Epoch: 6 | Iteration: 504 | Classification loss: 0.14228 | Regression loss: 0.49516 | Running loss: 0.77822\n",
      "Epoch: 6 | Iteration: 505 | Classification loss: 0.38021 | Regression loss: 0.65531 | Running loss: 0.77878\n",
      "Epoch: 6 | Iteration: 506 | Classification loss: 0.17688 | Regression loss: 0.46124 | Running loss: 0.77870\n",
      "Epoch: 6 | Iteration: 507 | Classification loss: 0.18694 | Regression loss: 0.32044 | Running loss: 0.77782\n",
      "Epoch: 6 | Iteration: 508 | Classification loss: 0.31888 | Regression loss: 0.50763 | Running loss: 0.77799\n",
      "Epoch: 6 | Iteration: 509 | Classification loss: 0.20420 | Regression loss: 0.53718 | Running loss: 0.77785\n",
      "Epoch: 6 | Iteration: 510 | Classification loss: 0.27873 | Regression loss: 0.45409 | Running loss: 0.77783\n",
      "Epoch: 6 | Iteration: 511 | Classification loss: 0.28449 | Regression loss: 0.67124 | Running loss: 0.77783\n",
      "Epoch: 6 | Iteration: 512 | Classification loss: 0.18231 | Regression loss: 0.56294 | Running loss: 0.77779\n",
      "Epoch: 6 | Iteration: 513 | Classification loss: 0.27873 | Regression loss: 0.52670 | Running loss: 0.77821\n",
      "Epoch: 6 | Iteration: 514 | Classification loss: 0.22174 | Regression loss: 0.61655 | Running loss: 0.77823\n",
      "Epoch: 6 | Iteration: 515 | Classification loss: 0.19482 | Regression loss: 0.54371 | Running loss: 0.77795\n",
      "Epoch: 6 | Iteration: 516 | Classification loss: 0.31604 | Regression loss: 0.68409 | Running loss: 0.77834\n",
      "Epoch: 6 | Iteration: 517 | Classification loss: 0.21769 | Regression loss: 0.56496 | Running loss: 0.77835\n",
      "Epoch: 6 | Iteration: 518 | Classification loss: 0.29657 | Regression loss: 0.66298 | Running loss: 0.77899\n",
      "Epoch: 6 | Iteration: 519 | Classification loss: 0.21834 | Regression loss: 0.54241 | Running loss: 0.77854\n",
      "Epoch: 6 | Iteration: 520 | Classification loss: 0.20440 | Regression loss: 0.55590 | Running loss: 0.77870\n",
      "Epoch: 6 | Iteration: 521 | Classification loss: 0.27823 | Regression loss: 0.55450 | Running loss: 0.77899\n",
      "Epoch: 6 | Iteration: 522 | Classification loss: 0.26116 | Regression loss: 0.54564 | Running loss: 0.77887\n",
      "Epoch: 6 | Iteration: 523 | Classification loss: 0.23572 | Regression loss: 0.51314 | Running loss: 0.77767\n",
      "Epoch: 6 | Iteration: 524 | Classification loss: 0.20434 | Regression loss: 0.49947 | Running loss: 0.77804\n",
      "Epoch: 6 | Iteration: 525 | Classification loss: 0.19077 | Regression loss: 0.33325 | Running loss: 0.77731\n",
      "Epoch: 6 | Iteration: 526 | Classification loss: 0.20737 | Regression loss: 0.57376 | Running loss: 0.77741\n",
      "Epoch: 6 | Iteration: 527 | Classification loss: 0.23023 | Regression loss: 0.50203 | Running loss: 0.77740\n",
      "Epoch: 6 | Iteration: 528 | Classification loss: 0.18963 | Regression loss: 0.50019 | Running loss: 0.77693\n",
      "Epoch: 6 | Iteration: 529 | Classification loss: 0.18611 | Regression loss: 0.52075 | Running loss: 0.77649\n",
      "Epoch: 6 | Iteration: 530 | Classification loss: 0.19319 | Regression loss: 0.45274 | Running loss: 0.77622\n",
      "Epoch: 6 | Iteration: 531 | Classification loss: 0.23734 | Regression loss: 0.52192 | Running loss: 0.77613\n",
      "Epoch: 6 | Iteration: 532 | Classification loss: 0.26572 | Regression loss: 0.66375 | Running loss: 0.77607\n",
      "Epoch: 6 | Iteration: 533 | Classification loss: 0.22147 | Regression loss: 0.48876 | Running loss: 0.77589\n",
      "Epoch: 6 | Iteration: 534 | Classification loss: 0.32511 | Regression loss: 0.54128 | Running loss: 0.77611\n",
      "Epoch: 6 | Iteration: 535 | Classification loss: 0.28742 | Regression loss: 0.51232 | Running loss: 0.77633\n",
      "Epoch: 6 | Iteration: 536 | Classification loss: 0.19631 | Regression loss: 0.37523 | Running loss: 0.77620\n",
      "Epoch: 6 | Iteration: 537 | Classification loss: 0.19052 | Regression loss: 0.41373 | Running loss: 0.77607\n",
      "Epoch: 6 | Iteration: 538 | Classification loss: 0.32890 | Regression loss: 0.59979 | Running loss: 0.77683\n",
      "Epoch: 6 | Iteration: 539 | Classification loss: 0.23991 | Regression loss: 0.52096 | Running loss: 0.77727\n",
      "Epoch: 6 | Iteration: 540 | Classification loss: 0.22005 | Regression loss: 0.49251 | Running loss: 0.77691\n",
      "Epoch: 6 | Iteration: 541 | Classification loss: 0.18477 | Regression loss: 0.46206 | Running loss: 0.77643\n",
      "Epoch: 6 | Iteration: 542 | Classification loss: 0.15470 | Regression loss: 0.37534 | Running loss: 0.77577\n",
      "Epoch: 6 | Iteration: 543 | Classification loss: 0.31441 | Regression loss: 0.59262 | Running loss: 0.77667\n",
      "Epoch: 6 | Iteration: 544 | Classification loss: 0.21713 | Regression loss: 0.59011 | Running loss: 0.77641\n",
      "Epoch: 6 | Iteration: 545 | Classification loss: 0.20847 | Regression loss: 0.41489 | Running loss: 0.77610\n",
      "Epoch: 6 | Iteration: 546 | Classification loss: 0.26194 | Regression loss: 0.51610 | Running loss: 0.77616\n",
      "Epoch: 6 | Iteration: 547 | Classification loss: 0.17760 | Regression loss: 0.40690 | Running loss: 0.77577\n",
      "Epoch: 6 | Iteration: 548 | Classification loss: 0.27272 | Regression loss: 0.61777 | Running loss: 0.77647\n",
      "Epoch: 6 | Iteration: 549 | Classification loss: 0.18403 | Regression loss: 0.56060 | Running loss: 0.77624\n",
      "Epoch: 6 | Iteration: 550 | Classification loss: 0.21586 | Regression loss: 0.50071 | Running loss: 0.77623\n",
      "Epoch: 6 | Iteration: 551 | Classification loss: 0.27526 | Regression loss: 0.52708 | Running loss: 0.77642\n",
      "Epoch: 6 | Iteration: 552 | Classification loss: 0.23620 | Regression loss: 0.53132 | Running loss: 0.77652\n",
      "Epoch: 6 | Iteration: 553 | Classification loss: 0.25752 | Regression loss: 0.53468 | Running loss: 0.77614\n",
      "Epoch: 6 | Iteration: 554 | Classification loss: 0.22998 | Regression loss: 0.51739 | Running loss: 0.77550\n",
      "Epoch: 6 | Iteration: 555 | Classification loss: 0.26675 | Regression loss: 0.58866 | Running loss: 0.77633\n",
      "Epoch: 6 | Iteration: 556 | Classification loss: 0.40941 | Regression loss: 0.61945 | Running loss: 0.77691\n",
      "Epoch: 6 | Iteration: 557 | Classification loss: 0.19214 | Regression loss: 0.53575 | Running loss: 0.77679\n",
      "Epoch: 6 | Iteration: 558 | Classification loss: 0.20059 | Regression loss: 0.51208 | Running loss: 0.77639\n",
      "Epoch: 6 | Iteration: 559 | Classification loss: 0.23140 | Regression loss: 0.58302 | Running loss: 0.77655\n",
      "Epoch: 6 | Iteration: 560 | Classification loss: 0.23162 | Regression loss: 0.59171 | Running loss: 0.77666\n",
      "Epoch: 6 | Iteration: 561 | Classification loss: 0.23238 | Regression loss: 0.41303 | Running loss: 0.77618\n",
      "Epoch: 6 | Iteration: 562 | Classification loss: 0.14996 | Regression loss: 0.45269 | Running loss: 0.77603\n",
      "Epoch: 6 | Iteration: 563 | Classification loss: 0.23271 | Regression loss: 0.57400 | Running loss: 0.77650\n",
      "Epoch: 6 | Iteration: 564 | Classification loss: 0.16265 | Regression loss: 0.41884 | Running loss: 0.77588\n",
      "Epoch: 6 | Iteration: 565 | Classification loss: 0.18380 | Regression loss: 0.51711 | Running loss: 0.77594\n",
      "Epoch: 6 | Iteration: 566 | Classification loss: 0.26069 | Regression loss: 0.60539 | Running loss: 0.77577\n",
      "Epoch: 6 | Iteration: 567 | Classification loss: 0.31771 | Regression loss: 0.59258 | Running loss: 0.77614\n",
      "Epoch: 6 | Iteration: 568 | Classification loss: 0.31168 | Regression loss: 0.58946 | Running loss: 0.77624\n",
      "Epoch: 6 | Iteration: 569 | Classification loss: 0.19664 | Regression loss: 0.45216 | Running loss: 0.77627\n",
      "Epoch: 6 | Iteration: 570 | Classification loss: 0.15946 | Regression loss: 0.36595 | Running loss: 0.77579\n",
      "Epoch: 6 | Iteration: 571 | Classification loss: 0.31127 | Regression loss: 0.62398 | Running loss: 0.77675\n",
      "Epoch: 6 | Iteration: 572 | Classification loss: 0.37028 | Regression loss: 0.55462 | Running loss: 0.77653\n",
      "Epoch: 6 | Iteration: 573 | Classification loss: 0.44537 | Regression loss: 0.51981 | Running loss: 0.77749\n",
      "Epoch: 6 | Iteration: 574 | Classification loss: 0.22690 | Regression loss: 0.61417 | Running loss: 0.77725\n",
      "Epoch: 6 | Iteration: 575 | Classification loss: 0.60426 | Regression loss: 0.73182 | Running loss: 0.77763\n",
      "Epoch: 6 | Iteration: 576 | Classification loss: 0.20336 | Regression loss: 0.28663 | Running loss: 0.77687\n",
      "Epoch: 6 | Iteration: 577 | Classification loss: 0.22278 | Regression loss: 0.46459 | Running loss: 0.77612\n",
      "Epoch: 6 | Iteration: 578 | Classification loss: 0.25699 | Regression loss: 0.57808 | Running loss: 0.77637\n",
      "Epoch: 6 | Iteration: 579 | Classification loss: 0.27037 | Regression loss: 0.50843 | Running loss: 0.77646\n",
      "Epoch: 6 | Iteration: 580 | Classification loss: 0.20365 | Regression loss: 0.54401 | Running loss: 0.77670\n",
      "Epoch: 6 | Iteration: 581 | Classification loss: 0.37552 | Regression loss: 0.68274 | Running loss: 0.77709\n",
      "Epoch: 6 | Iteration: 582 | Classification loss: 0.27801 | Regression loss: 0.71093 | Running loss: 0.77750\n",
      "Epoch: 6 | Iteration: 583 | Classification loss: 0.27448 | Regression loss: 0.59878 | Running loss: 0.77732\n",
      "Epoch: 6 | Iteration: 584 | Classification loss: 0.30270 | Regression loss: 0.54837 | Running loss: 0.77806\n",
      "Epoch: 6 | Iteration: 585 | Classification loss: 0.23643 | Regression loss: 0.49690 | Running loss: 0.77815\n",
      "Epoch: 6 | Iteration: 586 | Classification loss: 0.20628 | Regression loss: 0.41677 | Running loss: 0.77764\n",
      "Epoch: 6 | Iteration: 587 | Classification loss: 0.19864 | Regression loss: 0.51450 | Running loss: 0.77740\n",
      "Epoch: 6 | Iteration: 588 | Classification loss: 0.12950 | Regression loss: 0.34972 | Running loss: 0.77653\n",
      "Epoch: 6 | Iteration: 589 | Classification loss: 0.21054 | Regression loss: 0.50583 | Running loss: 0.77654\n",
      "Epoch: 6 | Iteration: 590 | Classification loss: 0.18857 | Regression loss: 0.45359 | Running loss: 0.77616\n",
      "Epoch: 6 | Iteration: 591 | Classification loss: 0.08737 | Regression loss: 0.22068 | Running loss: 0.77479\n",
      "Epoch: 6 | Iteration: 592 | Classification loss: 0.25178 | Regression loss: 0.48886 | Running loss: 0.77449\n",
      "Epoch: 6 | Iteration: 593 | Classification loss: 0.29053 | Regression loss: 0.53008 | Running loss: 0.77458\n",
      "Epoch: 6 | Iteration: 594 | Classification loss: 0.21318 | Regression loss: 0.51062 | Running loss: 0.77493\n",
      "Epoch: 6 | Iteration: 595 | Classification loss: 0.20306 | Regression loss: 0.47844 | Running loss: 0.77481\n",
      "Epoch: 6 | Iteration: 596 | Classification loss: 0.30249 | Regression loss: 0.59664 | Running loss: 0.77488\n",
      "Epoch: 6 | Iteration: 597 | Classification loss: 0.35059 | Regression loss: 0.67542 | Running loss: 0.77518\n",
      "Epoch: 6 | Iteration: 598 | Classification loss: 0.17371 | Regression loss: 0.44323 | Running loss: 0.77472\n",
      "Epoch: 6 | Iteration: 599 | Classification loss: 0.32675 | Regression loss: 0.74755 | Running loss: 0.77495\n",
      "Epoch: 6 | Iteration: 600 | Classification loss: 0.19528 | Regression loss: 0.65306 | Running loss: 0.77505\n",
      "Epoch: 6 | Iteration: 601 | Classification loss: 0.33649 | Regression loss: 0.52427 | Running loss: 0.77523\n",
      "Epoch: 6 | Iteration: 602 | Classification loss: 0.30993 | Regression loss: 0.56970 | Running loss: 0.77583\n",
      "Epoch: 6 | Iteration: 603 | Classification loss: 0.24805 | Regression loss: 0.56948 | Running loss: 0.77585\n",
      "Epoch: 6 | Iteration: 604 | Classification loss: 0.23781 | Regression loss: 0.62464 | Running loss: 0.77620\n",
      "Epoch: 6 | Iteration: 605 | Classification loss: 0.28524 | Regression loss: 0.67001 | Running loss: 0.77663\n",
      "Epoch: 6 | Iteration: 606 | Classification loss: 0.13188 | Regression loss: 0.38798 | Running loss: 0.77659\n",
      "Epoch: 6 | Iteration: 607 | Classification loss: 0.22270 | Regression loss: 0.50437 | Running loss: 0.77644\n",
      "Epoch: 6 | Iteration: 608 | Classification loss: 0.21478 | Regression loss: 0.53147 | Running loss: 0.77685\n",
      "Epoch: 6 | Iteration: 609 | Classification loss: 0.21829 | Regression loss: 0.57110 | Running loss: 0.77662\n",
      "Epoch: 6 | Iteration: 610 | Classification loss: 0.09764 | Regression loss: 0.41892 | Running loss: 0.77613\n",
      "Epoch: 6 | Iteration: 611 | Classification loss: 0.25240 | Regression loss: 0.53678 | Running loss: 0.77604\n",
      "Epoch: 6 | Iteration: 612 | Classification loss: 0.31600 | Regression loss: 0.79039 | Running loss: 0.77623\n",
      "Epoch: 6 | Iteration: 613 | Classification loss: 0.22248 | Regression loss: 0.37255 | Running loss: 0.77631\n",
      "Epoch: 6 | Iteration: 614 | Classification loss: 0.23480 | Regression loss: 0.61541 | Running loss: 0.77593\n",
      "Epoch: 6 | Iteration: 615 | Classification loss: 0.38327 | Regression loss: 0.68170 | Running loss: 0.77686\n",
      "Epoch: 6 | Iteration: 616 | Classification loss: 0.36002 | Regression loss: 0.58870 | Running loss: 0.77718\n",
      "Epoch: 6 | Iteration: 617 | Classification loss: 0.24066 | Regression loss: 0.54992 | Running loss: 0.77709\n",
      "Epoch: 6 | Iteration: 618 | Classification loss: 0.20705 | Regression loss: 0.41820 | Running loss: 0.77679\n",
      "Epoch: 6 | Iteration: 619 | Classification loss: 0.33872 | Regression loss: 0.71397 | Running loss: 0.77718\n",
      "Epoch: 6 | Iteration: 620 | Classification loss: 0.20198 | Regression loss: 0.52452 | Running loss: 0.77727\n",
      "Epoch: 6 | Iteration: 621 | Classification loss: 0.18537 | Regression loss: 0.51519 | Running loss: 0.77751\n",
      "Epoch: 6 | Iteration: 622 | Classification loss: 0.23642 | Regression loss: 0.50732 | Running loss: 0.77804\n",
      "Epoch: 6 | Iteration: 623 | Classification loss: 0.25372 | Regression loss: 0.57985 | Running loss: 0.77838\n",
      "Epoch: 6 | Iteration: 624 | Classification loss: 0.27430 | Regression loss: 0.58163 | Running loss: 0.77810\n",
      "Epoch: 6 | Iteration: 625 | Classification loss: 0.29579 | Regression loss: 0.66745 | Running loss: 0.77792\n",
      "Epoch: 6 | Iteration: 626 | Classification loss: 0.37465 | Regression loss: 0.59005 | Running loss: 0.77867\n",
      "Epoch: 6 | Iteration: 627 | Classification loss: 0.28725 | Regression loss: 0.60592 | Running loss: 0.77874\n",
      "Epoch: 6 | Iteration: 628 | Classification loss: 0.25061 | Regression loss: 0.50022 | Running loss: 0.77829\n",
      "Epoch: 6 | Iteration: 629 | Classification loss: 0.12413 | Regression loss: 0.26488 | Running loss: 0.77769\n",
      "Epoch: 6 | Iteration: 630 | Classification loss: 0.21766 | Regression loss: 0.56821 | Running loss: 0.77817\n",
      "Epoch: 6 | Iteration: 631 | Classification loss: 0.28884 | Regression loss: 0.57139 | Running loss: 0.77814\n",
      "Epoch: 6 | Iteration: 632 | Classification loss: 0.18278 | Regression loss: 0.44691 | Running loss: 0.77781\n",
      "Epoch: 6 | Iteration: 633 | Classification loss: 0.31276 | Regression loss: 0.59840 | Running loss: 0.77821\n",
      "Epoch: 6 | Iteration: 634 | Classification loss: 0.25387 | Regression loss: 0.56729 | Running loss: 0.77820\n",
      "Epoch: 6 | Iteration: 635 | Classification loss: 0.28076 | Regression loss: 0.57720 | Running loss: 0.77866\n",
      "Epoch: 6 | Iteration: 636 | Classification loss: 0.26480 | Regression loss: 0.57682 | Running loss: 0.77879\n",
      "Epoch: 6 | Iteration: 637 | Classification loss: 0.24584 | Regression loss: 0.60794 | Running loss: 0.77818\n",
      "Epoch: 6 | Iteration: 638 | Classification loss: 0.42066 | Regression loss: 0.62356 | Running loss: 0.77843\n",
      "Epoch: 6 | Iteration: 639 | Classification loss: 0.25745 | Regression loss: 0.51556 | Running loss: 0.77846\n",
      "Epoch: 6 | Iteration: 640 | Classification loss: 0.29341 | Regression loss: 0.72408 | Running loss: 0.77912\n",
      "Epoch: 6 | Iteration: 641 | Classification loss: 0.31039 | Regression loss: 0.73147 | Running loss: 0.77947\n",
      "Epoch: 6 | Iteration: 642 | Classification loss: 0.23709 | Regression loss: 0.54089 | Running loss: 0.77954\n",
      "Epoch: 6 | Iteration: 643 | Classification loss: 0.23011 | Regression loss: 0.55805 | Running loss: 0.77922\n",
      "Epoch: 6 | Iteration: 644 | Classification loss: 0.16435 | Regression loss: 0.46006 | Running loss: 0.77943\n",
      "Epoch: 6 | Iteration: 645 | Classification loss: 0.29412 | Regression loss: 0.68013 | Running loss: 0.78008\n",
      "Epoch: 6 | Iteration: 646 | Classification loss: 0.23740 | Regression loss: 0.45166 | Running loss: 0.77991\n",
      "Epoch: 6 | Iteration: 647 | Classification loss: 0.30748 | Regression loss: 0.49705 | Running loss: 0.78043\n",
      "Epoch: 6 | Iteration: 648 | Classification loss: 0.29731 | Regression loss: 0.66593 | Running loss: 0.78093\n",
      "Epoch: 6 | Iteration: 649 | Classification loss: 0.21481 | Regression loss: 0.49193 | Running loss: 0.78074\n",
      "Epoch: 6 | Iteration: 650 | Classification loss: 0.32185 | Regression loss: 0.58867 | Running loss: 0.78126\n",
      "Epoch: 6 | Iteration: 651 | Classification loss: 0.33562 | Regression loss: 0.79244 | Running loss: 0.78225\n",
      "Epoch: 6 | Iteration: 652 | Classification loss: 0.18534 | Regression loss: 0.42847 | Running loss: 0.78181\n",
      "Epoch: 6 | Iteration: 653 | Classification loss: 0.25073 | Regression loss: 0.51860 | Running loss: 0.78215\n",
      "Epoch: 6 | Iteration: 654 | Classification loss: 0.23190 | Regression loss: 0.61535 | Running loss: 0.78199\n",
      "Epoch: 6 | Iteration: 655 | Classification loss: 0.21900 | Regression loss: 0.37879 | Running loss: 0.78153\n",
      "Epoch: 6 | Iteration: 656 | Classification loss: 0.18054 | Regression loss: 0.46757 | Running loss: 0.78122\n",
      "Epoch: 6 | Iteration: 657 | Classification loss: 0.27956 | Regression loss: 0.69440 | Running loss: 0.78198\n",
      "Epoch: 6 | Iteration: 658 | Classification loss: 0.20769 | Regression loss: 0.48902 | Running loss: 0.78159\n",
      "Epoch: 6 | Iteration: 659 | Classification loss: 0.26339 | Regression loss: 0.52643 | Running loss: 0.78129\n",
      "Epoch: 6 | Iteration: 660 | Classification loss: 0.26236 | Regression loss: 0.55585 | Running loss: 0.78102\n",
      "Epoch: 6 | Iteration: 661 | Classification loss: 0.28229 | Regression loss: 0.45206 | Running loss: 0.78075\n",
      "Epoch: 6 | Iteration: 662 | Classification loss: 0.23950 | Regression loss: 0.58506 | Running loss: 0.78096\n",
      "Epoch: 6 | Iteration: 663 | Classification loss: 0.26096 | Regression loss: 0.60372 | Running loss: 0.78111\n",
      "Epoch: 6 | Iteration: 664 | Classification loss: 0.23016 | Regression loss: 0.49364 | Running loss: 0.78100\n",
      "Epoch: 6 | Iteration: 665 | Classification loss: 0.29004 | Regression loss: 0.51942 | Running loss: 0.78122\n",
      "Epoch: 6 | Iteration: 666 | Classification loss: 0.26301 | Regression loss: 0.49954 | Running loss: 0.78108\n",
      "Epoch: 6 | Iteration: 667 | Classification loss: 0.13246 | Regression loss: 0.33114 | Running loss: 0.78056\n",
      "Epoch: 6 | Iteration: 668 | Classification loss: 0.17334 | Regression loss: 0.49160 | Running loss: 0.78040\n",
      "Epoch: 6 | Iteration: 669 | Classification loss: 0.28370 | Regression loss: 0.62827 | Running loss: 0.78060\n",
      "Epoch: 6 | Iteration: 670 | Classification loss: 0.21632 | Regression loss: 0.53153 | Running loss: 0.78063\n",
      "Epoch: 6 | Iteration: 671 | Classification loss: 0.22131 | Regression loss: 0.52941 | Running loss: 0.78045\n",
      "Epoch: 6 | Iteration: 672 | Classification loss: 0.26786 | Regression loss: 0.51508 | Running loss: 0.78012\n",
      "Epoch: 6 | Iteration: 673 | Classification loss: 0.33322 | Regression loss: 0.62218 | Running loss: 0.78013\n",
      "Epoch: 6 | Iteration: 674 | Classification loss: 0.26360 | Regression loss: 0.61800 | Running loss: 0.78005\n",
      "Epoch: 6 | Iteration: 675 | Classification loss: 0.30690 | Regression loss: 0.56739 | Running loss: 0.77947\n",
      "Epoch: 6 | Iteration: 676 | Classification loss: 0.18195 | Regression loss: 0.62034 | Running loss: 0.77965\n",
      "Epoch: 6 | Iteration: 677 | Classification loss: 0.25457 | Regression loss: 0.54732 | Running loss: 0.77947\n",
      "Epoch: 6 | Iteration: 678 | Classification loss: 0.22565 | Regression loss: 0.53057 | Running loss: 0.77895\n",
      "Epoch: 6 | Iteration: 679 | Classification loss: 0.26866 | Regression loss: 0.56555 | Running loss: 0.77893\n",
      "Epoch: 6 | Iteration: 680 | Classification loss: 0.13198 | Regression loss: 0.35969 | Running loss: 0.77879\n",
      "Epoch: 6 | Iteration: 681 | Classification loss: 0.23908 | Regression loss: 0.52687 | Running loss: 0.77882\n",
      "Epoch: 6 | Iteration: 682 | Classification loss: 0.27168 | Regression loss: 0.59978 | Running loss: 0.77887\n",
      "Epoch: 6 | Iteration: 683 | Classification loss: 0.21774 | Regression loss: 0.54528 | Running loss: 0.77921\n",
      "Epoch: 6 | Iteration: 684 | Classification loss: 0.21727 | Regression loss: 0.50833 | Running loss: 0.77920\n",
      "Epoch: 6 | Iteration: 685 | Classification loss: 0.31655 | Regression loss: 0.57171 | Running loss: 0.77924\n",
      "Epoch: 6 | Iteration: 686 | Classification loss: 0.16277 | Regression loss: 0.48485 | Running loss: 0.77897\n",
      "Epoch: 6 | Iteration: 687 | Classification loss: 0.31143 | Regression loss: 0.58154 | Running loss: 0.77917\n",
      "Epoch: 6 | Iteration: 688 | Classification loss: 0.27338 | Regression loss: 0.44346 | Running loss: 0.77945\n",
      "Epoch: 6 | Iteration: 689 | Classification loss: 0.20476 | Regression loss: 0.35785 | Running loss: 0.77840\n",
      "Epoch: 6 | Iteration: 690 | Classification loss: 0.19009 | Regression loss: 0.47251 | Running loss: 0.77788\n",
      "Epoch: 6 | Iteration: 691 | Classification loss: 0.25334 | Regression loss: 0.62346 | Running loss: 0.77805\n",
      "Epoch: 6 | Iteration: 692 | Classification loss: 0.18682 | Regression loss: 0.57051 | Running loss: 0.77749\n",
      "Epoch: 6 | Iteration: 693 | Classification loss: 0.17747 | Regression loss: 0.54924 | Running loss: 0.77716\n",
      "Epoch: 6 | Iteration: 694 | Classification loss: 0.23308 | Regression loss: 0.58206 | Running loss: 0.77708\n",
      "Epoch: 6 | Iteration: 695 | Classification loss: 0.26887 | Regression loss: 0.68341 | Running loss: 0.77726\n",
      "Epoch: 6 | Iteration: 696 | Classification loss: 0.27324 | Regression loss: 0.70060 | Running loss: 0.77744\n",
      "Epoch: 6 | Iteration: 697 | Classification loss: 0.14983 | Regression loss: 0.42854 | Running loss: 0.77701\n",
      "Epoch: 6 | Iteration: 698 | Classification loss: 0.20676 | Regression loss: 0.49395 | Running loss: 0.77674\n",
      "Epoch: 6 | Iteration: 699 | Classification loss: 0.35703 | Regression loss: 0.68035 | Running loss: 0.77714\n",
      "Epoch: 6 | Iteration: 700 | Classification loss: 0.17570 | Regression loss: 0.40754 | Running loss: 0.77697\n",
      "Epoch: 6 | Iteration: 701 | Classification loss: 0.25188 | Regression loss: 0.58231 | Running loss: 0.77701\n",
      "Epoch: 6 | Iteration: 702 | Classification loss: 0.33234 | Regression loss: 0.53017 | Running loss: 0.77717\n",
      "Epoch: 6 | Iteration: 703 | Classification loss: 0.55506 | Regression loss: 0.65175 | Running loss: 0.77780\n",
      "Epoch: 6 | Iteration: 704 | Classification loss: 0.46911 | Regression loss: 0.60230 | Running loss: 0.77794\n",
      "Epoch: 6 | Iteration: 705 | Classification loss: 0.35129 | Regression loss: 0.67703 | Running loss: 0.77860\n",
      "Epoch: 6 | Iteration: 706 | Classification loss: 0.20292 | Regression loss: 0.39740 | Running loss: 0.77824\n",
      "Epoch: 6 | Iteration: 707 | Classification loss: 0.37299 | Regression loss: 0.72617 | Running loss: 0.77903\n",
      "Epoch: 6 | Iteration: 708 | Classification loss: 0.22572 | Regression loss: 0.36827 | Running loss: 0.77882\n",
      "Epoch: 6 | Iteration: 709 | Classification loss: 0.20024 | Regression loss: 0.44982 | Running loss: 0.77887\n",
      "Epoch: 6 | Iteration: 710 | Classification loss: 0.23550 | Regression loss: 0.52695 | Running loss: 0.77865\n",
      "Epoch: 6 | Iteration: 711 | Classification loss: 0.24150 | Regression loss: 0.60566 | Running loss: 0.77828\n",
      "Epoch: 6 | Iteration: 712 | Classification loss: 0.26179 | Regression loss: 0.67851 | Running loss: 0.77903\n",
      "Epoch: 6 | Iteration: 713 | Classification loss: 0.23280 | Regression loss: 0.47609 | Running loss: 0.77866\n",
      "Epoch: 6 | Iteration: 714 | Classification loss: 0.33553 | Regression loss: 0.73892 | Running loss: 0.77943\n",
      "Epoch: 6 | Iteration: 715 | Classification loss: 0.23933 | Regression loss: 0.45204 | Running loss: 0.77938\n",
      "Epoch: 6 | Iteration: 716 | Classification loss: 0.24896 | Regression loss: 0.61136 | Running loss: 0.77928\n",
      "Epoch: 6 | Iteration: 717 | Classification loss: 0.24027 | Regression loss: 0.59467 | Running loss: 0.77950\n",
      "Epoch: 6 | Iteration: 718 | Classification loss: 0.36011 | Regression loss: 0.66693 | Running loss: 0.77984\n",
      "Epoch: 6 | Iteration: 719 | Classification loss: 0.22736 | Regression loss: 0.54906 | Running loss: 0.78013\n",
      "Epoch: 6 | Iteration: 720 | Classification loss: 0.19362 | Regression loss: 0.56143 | Running loss: 0.77975\n",
      "Epoch: 6 | Iteration: 721 | Classification loss: 0.36971 | Regression loss: 0.65760 | Running loss: 0.78074\n",
      "Epoch: 6 | Iteration: 722 | Classification loss: 0.25043 | Regression loss: 0.58897 | Running loss: 0.78091\n",
      "Epoch: 6 | Iteration: 723 | Classification loss: 0.16730 | Regression loss: 0.51736 | Running loss: 0.78026\n",
      "Epoch: 6 | Iteration: 724 | Classification loss: 0.22839 | Regression loss: 0.55119 | Running loss: 0.78093\n",
      "Epoch: 6 | Iteration: 725 | Classification loss: 0.30330 | Regression loss: 0.76091 | Running loss: 0.78133\n",
      "Epoch: 6 | Iteration: 726 | Classification loss: 0.22486 | Regression loss: 0.51505 | Running loss: 0.78119\n",
      "Epoch: 6 | Iteration: 727 | Classification loss: 0.23020 | Regression loss: 0.79965 | Running loss: 0.78181\n",
      "Epoch: 6 | Iteration: 728 | Classification loss: 0.21257 | Regression loss: 0.51487 | Running loss: 0.78155\n",
      "Epoch: 6 | Iteration: 729 | Classification loss: 0.22857 | Regression loss: 0.55052 | Running loss: 0.78184\n",
      "Epoch: 6 | Iteration: 730 | Classification loss: 0.22421 | Regression loss: 0.50871 | Running loss: 0.78158\n",
      "Epoch: 6 | Iteration: 731 | Classification loss: 0.15486 | Regression loss: 0.47186 | Running loss: 0.78123\n",
      "Epoch: 6 | Iteration: 732 | Classification loss: 0.20024 | Regression loss: 0.44322 | Running loss: 0.78064\n",
      "Epoch: 6 | Iteration: 733 | Classification loss: 0.18146 | Regression loss: 0.44648 | Running loss: 0.78049\n",
      "Epoch: 6 | Iteration: 734 | Classification loss: 0.29199 | Regression loss: 0.54595 | Running loss: 0.78045\n",
      "Epoch: 6 | Iteration: 735 | Classification loss: 0.19899 | Regression loss: 0.51949 | Running loss: 0.78053\n",
      "Epoch: 6 | Iteration: 736 | Classification loss: 0.25382 | Regression loss: 0.59417 | Running loss: 0.78083\n",
      "Epoch: 6 | Iteration: 737 | Classification loss: 0.17001 | Regression loss: 0.37918 | Running loss: 0.78053\n",
      "Epoch: 6 | Iteration: 738 | Classification loss: 0.16506 | Regression loss: 0.44551 | Running loss: 0.78024\n",
      "Epoch: 6 | Iteration: 739 | Classification loss: 0.26829 | Regression loss: 0.64350 | Running loss: 0.78057\n",
      "Epoch: 6 | Iteration: 740 | Classification loss: 0.16722 | Regression loss: 0.46477 | Running loss: 0.78079\n",
      "Epoch: 6 | Iteration: 741 | Classification loss: 0.16265 | Regression loss: 0.54239 | Running loss: 0.78082\n",
      "Epoch: 6 | Iteration: 742 | Classification loss: 0.29539 | Regression loss: 0.60785 | Running loss: 0.78100\n",
      "Epoch: 6 | Iteration: 743 | Classification loss: 0.25525 | Regression loss: 0.50971 | Running loss: 0.78087\n",
      "Epoch: 6 | Iteration: 744 | Classification loss: 0.25855 | Regression loss: 0.60436 | Running loss: 0.78116\n",
      "Epoch: 6 | Iteration: 745 | Classification loss: 0.30628 | Regression loss: 0.56498 | Running loss: 0.78126\n"
     ]
    }
   ],
   "source": [
    "# import time\n",
    "# start = time.time()\n",
    "# !python train.py \\\n",
    "# --dataset csv \\\n",
    "# --csv_train  '/content/drive/MyDrive/object_detection/data/train_annots_v2.csv' \\\n",
    "# --csv_classes '/content/drive/MyDrive/object_detection/data/class_label.csv'  \\\n",
    "# --csv_val '/content/drive/MyDrive/object_detection/data/val_annots_v2.csv' \\\n",
    "# --depth 18 \\\n",
    "# --epochs 10\n",
    "# end = time.time()\n",
    "# print(\"Total time taken in sec \", np.round((end - start)/60, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Metrics after 5 Epochs\n",
    "\n",
    "- Pretrained Weights Used -- Resnet Coco\n",
    "- **IOU Threshold used :- 0.5**\n",
    "- **Score Threshold for Box removal :- 0.5**\n",
    "- **mAP (Person): 0.421**\n",
    "- **mAP (Car): 0.514**\n",
    "\n",
    "\n",
    "- ***mAP (Complete System) : 0.468***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-09T09:33:59.744233Z",
     "start_time": "2021-10-09T09:33:59.736236Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sBurvMA0gqRz"
   },
   "source": [
    "# Visualizing the Predictions from the trained RetinaNet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-09T09:35:18.785278Z",
     "start_time": "2021-10-09T09:35:18.780278Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fwN6xj43g0-0",
    "outputId": "eb7a9086-f3b9-4b85-ceab-99acc14e9466"
   },
   "outputs": [],
   "source": [
    "# !python visualize_single_image.py \\\n",
    "# --image_dir '/content/drive/MyDrive/object_detection/data/trainval/images/' \\\n",
    "# --class_list '/content/drive/MyDrive/object_detection/data/class_label.csv'  \\\n",
    "# --model_path '/content/drive/MyDrive/object_detection/src/pytorch-retinanet/csv_retinanet_5.pt'\n",
    "# # --csv_val '/content/drive/MyDrive/object_detection/data/val_annots_v2.csv' \\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "wd1gs2LBhVSd"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import csv\n",
    "import cv2\n",
    "import argparse\n",
    "\n",
    "\n",
    "def load_classes(csv_reader):\n",
    "    result = {}\n",
    "\n",
    "    for line, row in enumerate(csv_reader):\n",
    "        line += 1\n",
    "\n",
    "        try:\n",
    "            class_name, class_id = row\n",
    "        except ValueError:\n",
    "            raise(ValueError('line {}: format should be \\'class_name,class_id\\''.format(line)))\n",
    "        class_id = int(class_id)\n",
    "\n",
    "        if class_name in result:\n",
    "            raise ValueError('line {}: duplicate class name: \\'{}\\''.format(line, class_name))\n",
    "        result[class_name] = class_id\n",
    "    return result\n",
    "\n",
    "\n",
    "# Draws a caption above the box in an image\n",
    "def draw_caption(image, box, caption):\n",
    "    b = np.array(box).astype(int)\n",
    "    cv2.putText(image, caption, (b[0], b[1] - 10), cv2.FONT_HERSHEY_PLAIN, 1, (0, 0, 0), 2)\n",
    "    cv2.putText(image, caption, (b[0], b[1] - 10), cv2.FONT_HERSHEY_PLAIN, 1, (255, 255, 255), 1)\n",
    "\n",
    "\n",
    "def detect_image(image_path, model_path, class_list):\n",
    "\n",
    "    with open(class_list, 'r') as f:\n",
    "        classes = load_classes(csv.reader(f, delimiter=','))\n",
    "\n",
    "    labels = {}\n",
    "    for key, value in classes.items():\n",
    "        labels[value] = key\n",
    "\n",
    "    model = torch.load(model_path)\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        model = model.cuda()\n",
    "\n",
    "    model.training = False\n",
    "    model.eval()\n",
    "\n",
    "    for img_name in os.listdir(image_path):\n",
    "\n",
    "        image = cv2.imread(os.path.join(image_path, img_name))\n",
    "        if image is None:\n",
    "            continue\n",
    "        image_orig = image.copy()\n",
    "\n",
    "        rows, cols, cns = image.shape\n",
    "\n",
    "        smallest_side = min(rows, cols)\n",
    "\n",
    "        # rescale the image so the smallest side is min_side\n",
    "        min_side = 608\n",
    "        max_side = 1024\n",
    "        scale = min_side / smallest_side\n",
    "\n",
    "        # check if the largest side is now greater than max_side, which can happen\n",
    "        # when images have a large aspect ratio\n",
    "        largest_side = max(rows, cols)\n",
    "\n",
    "        if largest_side * scale > max_side:\n",
    "            scale = max_side / largest_side\n",
    "\n",
    "        # resize the image with the computed scale\n",
    "        image = cv2.resize(image, (int(round(cols * scale)), int(round((rows * scale)))))\n",
    "        rows, cols, cns = image.shape\n",
    "\n",
    "        pad_w = 32 - rows % 32\n",
    "        pad_h = 32 - cols % 32\n",
    "\n",
    "        new_image = np.zeros((rows + pad_w, cols + pad_h, cns)).astype(np.float32)\n",
    "        new_image[:rows, :cols, :] = image.astype(np.float32)\n",
    "        image = new_image.astype(np.float32)\n",
    "        image /= 255\n",
    "        image -= [0.485, 0.456, 0.406]\n",
    "        image /= [0.229, 0.224, 0.225]\n",
    "        image = np.expand_dims(image, 0)\n",
    "        image = np.transpose(image, (0, 3, 1, 2))\n",
    "\n",
    "        with torch.no_grad():\n",
    "\n",
    "            image = torch.from_numpy(image)\n",
    "            if torch.cuda.is_available():\n",
    "                image = image.cuda()\n",
    "\n",
    "            st = time.time()\n",
    "            print(image.shape, image_orig.shape, scale)\n",
    "            scores, classification, transformed_anchors = model(image.cuda().float())\n",
    "            print('Elapsed time: {}'.format(time.time() - st))\n",
    "            idxs = np.where(scores.cpu() > 0.5)\n",
    "\n",
    "            for j in range(idxs[0].shape[0]):\n",
    "                bbox = transformed_anchors[idxs[0][j], :]\n",
    "\n",
    "                x1 = int(bbox[0] / scale)\n",
    "                y1 = int(bbox[1] / scale)\n",
    "                x2 = int(bbox[2] / scale)\n",
    "                y2 = int(bbox[3] / scale)\n",
    "                label_name = labels[int(classification[idxs[0][j]])]\n",
    "                print(bbox, classification.shape)\n",
    "                score = scores[j]\n",
    "                caption = '{} {:.3f}'.format(label_name, score)\n",
    "                # draw_caption(img, (x1, y1, x2, y2), label_name)\n",
    "                draw_caption(image_orig, (x1, y1, x2, y2), caption)\n",
    "                cv2.rectangle(image_orig, (x1, y1), (x2, y2), color=(0, 0, 255), thickness=2)\n",
    "\n",
    "            cv2_imshow(image_orig)\n",
    "            # cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "cWCWKlvelnPl"
   },
   "outputs": [],
   "source": [
    "from google.colab.patches import cv2_imshow\n",
    "image_dir = '/content/drive/MyDrive/object_detection/data/trainval/images/'\n",
    "class_list = '/content/drive/MyDrive/object_detection/data/class_label.csv'\n",
    "model_path = '/content/drive/MyDrive/object_detection/src/pytorch-retinanet/csv_retinanet_5.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sfvDMB29m9V8"
   },
   "outputs": [],
   "source": [
    "val_annots = pd.read_csv('/content/drive/MyDrive/object_detection/data/val_annots_v2.csv', header=None)\n",
    "val_annots.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-09T09:35:45.740786Z",
     "start_time": "2021-10-09T09:35:45.648841Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "tGGxoGkFlukh",
    "outputId": "d8dd42f0-52e6-443f-deaa-232b10530af8"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'detect_image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-a5daf888c434>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdetect_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'detect_image' is not defined"
     ]
    }
   ],
   "source": [
    "detect_image(image_dir, model_path, class_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NToEnxaJl2gh"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "EagleView Task",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
